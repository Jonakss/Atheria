{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Atheria 4: Entrenamiento Sin UI\n",
    "\n",
    "Este notebook permite entrenar modelos de Atheria 4 directamente en Kaggle o Google Colab **sin necesidad de la UI web**.\n",
    "\n",
    "## üìã Caracter√≠sticas\n",
    "\n",
    "- ‚úÖ Entrenamiento completo desde cero o continuar desde checkpoint\n",
    "- ‚úÖ Soporte para todas las arquitecturas: UNet, SNN_UNET, MLP, DEEP_QCA, UNET_CONVLSTM\n",
    "- ‚úÖ Transfer Learning desde experimentos existentes\n",
    "- ‚úÖ Sistema Smart Save (retiene mejores checkpoints autom√°ticamente)\n",
    "- ‚úÖ Visualizaci√≥n b√°sica de m√©tricas durante entrenamiento\n",
    "- ‚úÖ Exportaci√≥n de modelos TorchScript para inferencia\n",
    "\n",
    "## üîß Requisitos\n",
    "\n",
    "- PyTorch (CUDA disponible en Kaggle/Colab)\n",
    "- Dependencias del proyecto Atheria 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Paso 1: Instalaci√≥n de Dependencias\n",
    "\n",
    "Primero, instalamos las dependencias necesarias. Este paso detecta autom√°ticamente si estamos en Kaggle o Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar entorno (Kaggle o Colab)\n",
    "import os\n",
    "IN_KAGGLE = os.path.exists('/kaggle/input')\n",
    "try:\n",
    "    IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(f\"üåç Entorno detectado: {'Kaggle' if IN_KAGGLE else 'Colab' if IN_COLAB else 'Local'}\")\n",
    "\n",
    "# Instalar dependencias b√°sicas\n",
    "!pip install -q snntorch scikit-learn\n",
    "\n",
    "# Para Colab: instalar pybind11 si es necesario (opcional, solo si usas motor nativo)\n",
    "if IN_COLAB:\n",
    "    !pip install -q pybind11\n",
    "\n",
    "print(\"‚úÖ Dependencias instaladas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Paso 2: Configuraci√≥n del Proyecto\n",
    "\n",
    "Aqu√≠ configuramos las rutas del proyecto. En Kaggle/Colab, podemos clonar el repo o usar archivos ya subidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Configurar ruta del proyecto\n",
    "if IN_KAGGLE:\n",
    "    # En Kaggle, asumimos que el proyecto est√° en /kaggle/working\n",
    "    PROJECT_ROOT = Path(\"/kaggle/working/Atheria\")\n",
    "    if not PROJECT_ROOT.exists():\n",
    "        print(\"‚ö†Ô∏è Proyecto no encontrado. Clonando desde GitHub...\")\n",
    "        !git clone https://github.com/Jonakss/Atheria.git /kaggle/working/Atheria\n",
    "elif IN_COLAB:\n",
    "    # En Colab, clonamos el repo\n",
    "    PROJECT_ROOT = Path(\"/content/Atheria\")\n",
    "    if not PROJECT_ROOT.exists():\n",
    "        print(\"üì• Clonando proyecto desde GitHub...\")\n",
    "        !git clone https://github.com/Jonakss/Atheria.git /content/Atheria\n",
    "else:\n",
    "    # Local: usar ruta actual\n",
    "    PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "\n",
    "# Agregar al path de Python\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"üìÅ Proyecto configurado en: {PROJECT_ROOT}\")\n",
    "\n",
    "# Verificar estructura b√°sica\n",
    "src_path = PROJECT_ROOT / \"src\"\n",
    "if src_path.exists():\n",
    "    print(\"‚úÖ Estructura del proyecto verificada\")\n",
    "else:\n",
    "    print(\"‚ùå Error: No se encontr√≥ la carpeta 'src'. Verifica la instalaci√≥n.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Paso 3: Configuraci√≥n del Entrenamiento\n",
    "\n",
    "Configura aqu√≠ los par√°metros de tu experimento. Puedes crear m√∫ltiples configuraciones para diferentes experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import torch\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACI√ìN DEL EXPERIMENTO\n",
    "# ============================================================================\n",
    "# Modifica estos valores seg√∫n tu experimento\n",
    "\n",
    "EXPERIMENT_CONFIG = {\n",
    "    # Nombre del experimento (debe ser √∫nico)\n",
    "    \"EXPERIMENT_NAME\": \"UNET_32ch_D8_Colab\",\n",
    "    \n",
    "    # Arquitectura del modelo\n",
    "    # Opciones: \"UNET\", \"SNN_UNET\", \"MLP\", \"DEEP_QCA\", \"UNET_CONVLSTM\", \"UNET_UNITARY\"\n",
    "    \"MODEL_ARCHITECTURE\": \"UNET\",\n",
    "    \n",
    "    # Par√°metros del modelo\n",
    "    \"MODEL_PARAMS\": {\n",
    "        \"d_state\": 8,           # Dimensi√≥n del estado cu√°ntico\n",
    "        \"hidden_channels\": 32,  # Canales ocultos (m√°s = m√°s capacidad, m√°s lento)\n",
    "        # Para SNN_UNET:\n",
    "        # \"alpha\": 0.9,\n",
    "        # \"beta\": 0.85,\n",
    "    },\n",
    "    \n",
    "    # Par√°metros de entrenamiento\n",
    "    \"GRID_SIZE_TRAINING\": 64,     # Tama√±o del grid (64, 128, 256...)\n",
    "    \"QCA_STEPS_TRAINING\": 100,    # Pasos de simulaci√≥n por episodio\n",
    "    \"LR_RATE_M\": 1e-4,            # Learning rate (0.0001)\n",
    "    \"GAMMA_DECAY\": 0.01,          # T√©rmino Lindbladian (decaimiento)\n",
    "    \n",
    "    # Configuraci√≥n del entrenamiento\n",
    "    \"TOTAL_EPISODES\": 500,        # Total de episodios a entrenar\n",
    "    \"SAVE_EVERY_EPISODES\": 50,    # Guardar checkpoint cada N episodios\n",
    "    \"EPISODES_TO_ADD\": 1,         # Episodios a agregar por lote (usar 1)\n",
    "    \"STEPS_PER_EPISODE\": 100,     # Pasos por episodio (debe coincidir con QCA_STEPS_TRAINING)\n",
    "    \n",
    "    # Opcional: Transfer Learning\n",
    "    # \"LOAD_FROM_EXPERIMENT\": None,  # Nombre del experimento base (None = desde cero)\n",
    "    \n",
    "    # Opcional: Continuar entrenamiento\n",
    "    # \"CONTINUE_TRAINING\": False,     # True = continuar desde √∫ltimo checkpoint\n",
    "}\n",
    "\n",
    "# Convertir a SimpleNamespace para compatibilidad\n",
    "exp_cfg = SimpleNamespace(**EXPERIMENT_CONFIG)\n",
    "exp_cfg.MODEL_PARAMS = SimpleNamespace(**EXPERIMENT_CONFIG[\"MODEL_PARAMS\"])\n",
    "\n",
    "# Detectar dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "exp_cfg.DEVICE = device\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä CONFIGURACI√ìN DEL EXPERIMENTO\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Nombre: {exp_cfg.EXPERIMENT_NAME}\")\n",
    "print(f\"Arquitectura: {exp_cfg.MODEL_ARCHITECTURE}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Grid Size: {exp_cfg.GRID_SIZE_TRAINING}x{exp_cfg.GRID_SIZE_TRAINING}\")\n",
    "print(f\"Total Episodios: {exp_cfg.TOTAL_EPISODES}\")\n",
    "print(f\"Learning Rate: {exp_cfg.LR_RATE_M}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Paso 4: Iniciar Entrenamiento\n",
    "\n",
    "Aqu√≠ ejecutamos el pipeline de entrenamiento. El sistema guardar√° autom√°ticamente:\n",
    "- **Mejores checkpoints** (hasta 5 por defecto)\n",
    "- **√öltimo checkpoint** (siempre)\n",
    "- **Checkpoints peri√≥dicos** (cada `SAVE_EVERY_EPISODES`)\n",
    "- **Log de m√©tricas** en Markdown (`docs/40_Experiments/`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from src.pipelines.pipeline_train import run_training_pipeline\n",
    "from src.utils import get_latest_checkpoint\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Verificar si hay checkpoint previo (continuar entrenamiento)\n",
    "checkpoint_path = None\n",
    "if hasattr(exp_cfg, 'CONTINUE_TRAINING') and exp_cfg.CONTINUE_TRAINING:\n",
    "    checkpoint_path = get_latest_checkpoint(exp_cfg.EXPERIMENT_NAME)\n",
    "    if checkpoint_path:\n",
    "        logger.info(f\"‚úÖ Checkpoint encontrado: {checkpoint_path}\")\n",
    "        logger.info(\"üîÑ Continuando entrenamiento desde checkpoint...\")\n",
    "    else:\n",
    "        logger.warning(\"‚ö†Ô∏è No se encontr√≥ checkpoint. Iniciando desde cero.\")\n",
    "        checkpoint_path = None\n",
    "\n",
    "# Ejecutar entrenamiento\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ INICIANDO ENTRENAMIENTO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    run_training_pipeline(exp_cfg, checkpoint_path=checkpoint_path)\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úÖ ENTRENAMIENTO COMPLETADO EXITOSAMENTE\")\n",
    "    print(\"=\" * 70)\n",
    "except Exception as e:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"‚ùå ERROR DURANTE EL ENTRENAMIENTO: {e}\")\n",
    "    print(\"=\" * 70)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Paso 5: Visualizar Resultados\n",
    "\n",
    "Visualiza las m√©tricas de entrenamiento y el progreso del experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Cargar configuraci√≥n del experimento\n",
    "experiment_dir = PROJECT_ROOT / \"output\" / \"experiments\" / exp_cfg.EXPERIMENT_NAME\n",
    "config_path = experiment_dir / \"config.json\"\n",
    "\n",
    "if config_path.exists():\n",
    "    with open(config_path, 'r') as f:\n",
    "        saved_config = json.load(f)\n",
    "    \n",
    "    print(\"üìã Configuraci√≥n guardada del experimento:\")\n",
    "    print(json.dumps(saved_config, indent=2))\n",
    "    \n",
    "    # Cargar log de resultados si existe\n",
    "    log_path = PROJECT_ROOT / \"docs\" / \"40_Experiments\" / f\"{exp_cfg.EXPERIMENT_NAME}_LOG.md\"\n",
    "    if log_path.exists():\n",
    "        print(f\"\\nüìÑ Log de resultados disponible en: {log_path}\")\n",
    "        with open(log_path, 'r') as f:\n",
    "            log_content = f.read()\n",
    "            # Mostrar √∫ltimas 50 l√≠neas\n",
    "            lines = log_content.split('\\n')\n",
    "            print(\"\\n\".join(lines[-50:]))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se encontr√≥ configuraci√≥n guardada del experimento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar checkpoints guardados\n",
    "from src.utils import get_latest_checkpoint\n",
    "import os\n",
    "\n",
    "checkpoint_dir = PROJECT_ROOT / \"output\" / \"checkpoints\" / exp_cfg.EXPERIMENT_NAME\n",
    "if checkpoint_dir.exists():\n",
    "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pth')]\n",
    "    print(f\"\\nüíæ Checkpoints guardados ({len(checkpoints)}):\")\n",
    "    for cp in sorted(checkpoints):\n",
    "        cp_path = checkpoint_dir / cp\n",
    "        size_mb = cp_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  - {cp} ({size_mb:.2f} MB)\")\n",
    "    \n",
    "    latest = get_latest_checkpoint(exp_cfg.EXPERIMENT_NAME)\n",
    "    if latest:\n",
    "        print(f\"\\n‚úÖ √öltimo checkpoint: {latest}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se encontraron checkpoints.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Paso 6: Exportar Modelo TorchScript (Opcional)\n",
    "\n",
    "Exporta el modelo entrenado a TorchScript para usar en inferencia o el motor nativo C++."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar modelo a TorchScript para inferencia\n",
    "from src.model_loader import load_model\n",
    "import torch\n",
    "\n",
    "checkpoint_path = get_latest_checkpoint(exp_cfg.EXPERIMENT_NAME)\n",
    "if checkpoint_path:\n",
    "    print(f\"üì§ Exportando modelo desde: {checkpoint_path}\")\n",
    "    \n",
    "    # Cargar modelo\n",
    "    model, state_dict = load_model(exp_cfg, checkpoint_path)\n",
    "    if model:\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        \n",
    "        # Crear ejemplo de input\n",
    "        example_input = torch.randn(1, 2 * exp_cfg.MODEL_PARAMS.d_state, \n",
    "                                    exp_cfg.GRID_SIZE_TRAINING, \n",
    "                                    exp_cfg.GRID_SIZE_TRAINING, device=device)\n",
    "        \n",
    "        # Exportar a TorchScript\n",
    "        torchscript_dir = PROJECT_ROOT / \"output\" / \"torchscript_models\" / exp_cfg.EXPERIMENT_NAME\n",
    "        torchscript_dir.mkdir(parents=True, exist_ok=True)\n",
    "        torchscript_path = torchscript_dir / \"model.pt\"\n",
    "        \n",
    "        try:\n",
    "            traced_model = torch.jit.trace(model, example_input, strict=False)\n",
    "            traced_model.save(str(torchscript_path))\n",
    "            print(f\"‚úÖ Modelo exportado a: {torchscript_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error exportando modelo: {e}\")\n",
    "            print(\"   Intentando con torch.jit.script...\")\n",
    "            try:\n",
    "                scripted_model = torch.jit.script(model)\n",
    "                scripted_model.save(str(torchscript_path))\n",
    "                print(f\"‚úÖ Modelo exportado (script) a: {torchscript_path}\")\n",
    "            except Exception as e2:\n",
    "                print(f\"‚ùå Error exportando modelo: {e2}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se encontr√≥ checkpoint para exportar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Paso 7: Descargar Resultados (Colab/Kaggle)\n",
    "\n",
    "Si est√°s en Colab o Kaggle, puedes descargar los resultados del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En Colab: comprimir resultados para descarga\n",
    "if IN_COLAB:\n",
    "    import zipfile\n",
    "    \n",
    "    print(\"üì¶ Comprimiendo resultados...\")\n",
    "    zip_path = f\"/content/{exp_cfg.EXPERIMENT_NAME}_results.zip\"\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # Agregar checkpoints\n",
    "        checkpoint_dir = PROJECT_ROOT / \"output\" / \"checkpoints\" / exp_cfg.EXPERIMENT_NAME\n",
    "        if checkpoint_dir.exists():\n",
    "            for cp_file in checkpoint_dir.glob(\"*.pth\"):\n",
    "                zipf.write(cp_file, f\"checkpoints/{cp_file.name}\")\n",
    "        \n",
    "        # Agregar configuraci√≥n\n",
    "        config_file = PROJECT_ROOT / \"output\" / \"experiments\" / exp_cfg.EXPERIMENT_NAME / \"config.json\"\n",
    "        if config_file.exists():\n",
    "            zipf.write(config_file, f\"experiments/{exp_cfg.EXPERIMENT_NAME}/config.json\")\n",
    "        \n",
    "        # Agregar modelo TorchScript si existe\n",
    "        torchscript_file = PROJECT_ROOT / \"output\" / \"torchscript_models\" / exp_cfg.EXPERIMENT_NAME / \"model.pt\"\n",
    "        if torchscript_file.exists():\n",
    "            zipf.write(torchscript_file, f\"torchscript_models/{exp_cfg.EXPERIMENT_NAME}/model.pt\")\n",
    "    \n",
    "    print(f\"‚úÖ Archivo comprimido creado: {zip_path}\")\n",
    "    print(f\"üì• Descarga el archivo desde el panel de archivos de Colab\")\n",
    "    \n",
    "elif IN_KAGGLE:\n",
    "    print(\"üìÅ En Kaggle, los resultados est√°n en /kaggle/working\")\n",
    "    print(f\"   - Checkpoints: output/checkpoints/{exp_cfg.EXPERIMENT_NAME}/\")\n",
    "    print(f\"   - Config: output/experiments/{exp_cfg.EXPERIMENT_NAME}/config.json\")\n",
    "else:\n",
    "    print(\"üíª En entorno local, los resultados est√°n en:\")\n",
    "    print(f\"   - Checkpoints: output/checkpoints/{exp_cfg.EXPERIMENT_NAME}/\")\n",
    "    print(f\"   - Config: output/experiments/{exp_cfg.EXPERIMENT_NAME}/config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Ejemplos de Configuraci√≥n\n",
    "\n",
    "Aqu√≠ hay algunos ejemplos de configuraciones para diferentes experimentos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 1: U-Net peque√±o (r√°pido, bueno para pruebas)\n",
    "EXAMPLE_UNET_SMALL = {\n",
    "    \"EXPERIMENT_NAME\": \"UNET_16ch_D4_Test\",\n",
    "    \"MODEL_ARCHITECTURE\": \"UNET\",\n",
    "    \"MODEL_PARAMS\": {\"d_state\": 4, \"hidden_channels\": 16},\n",
    "    \"GRID_SIZE_TRAINING\": 32,\n",
    "    \"QCA_STEPS_TRAINING\": 50,\n",
    "    \"LR_RATE_M\": 1e-4,\n",
    "    \"TOTAL_EPISODES\": 100,\n",
    "}\n",
    "\n",
    "# Ejemplo 2: U-Net mediano (balance)\n",
    "EXAMPLE_UNET_MEDIUM = {\n",
    "    \"EXPERIMENT_NAME\": \"UNET_32ch_D8_Colab\",\n",
    "    \"MODEL_ARCHITECTURE\": \"UNET\",\n",
    "    \"MODEL_PARAMS\": {\"d_state\": 8, \"hidden_channels\": 32},\n",
    "    \"GRID_SIZE_TRAINING\": 64,\n",
    "    \"QCA_STEPS_TRAINING\": 100,\n",
    "    \"LR_RATE_M\": 1e-4,\n",
    "    \"TOTAL_EPISODES\": 500,\n",
    "}\n",
    "\n",
    "# Ejemplo 3: SNN U-Net (Spiking Neural Network)\n",
    "EXAMPLE_SNN_UNET = {\n",
    "    \"EXPERIMENT_NAME\": \"SNN_UNET_32ch_D8\",\n",
    "    \"MODEL_ARCHITECTURE\": \"SNN_UNET\",\n",
    "    \"MODEL_PARAMS\": {\"d_state\": 8, \"hidden_channels\": 32, \"alpha\": 0.9, \"beta\": 0.85},\n",
    "    \"GRID_SIZE_TRAINING\": 64,\n",
    "    \"QCA_STEPS_TRAINING\": 100,\n",
    "    \"LR_RATE_M\": 1e-4,\n",
    "    \"TOTAL_EPISODES\": 500,\n",
    "}\n",
    "\n",
    "# Ejemplo 4: Transfer Learning (continuar desde otro experimento)\n",
    "EXAMPLE_TRANSFER_LEARNING = {\n",
    "    \"EXPERIMENT_NAME\": \"UNET_64ch_D16_Transfer\",\n",
    "    \"MODEL_ARCHITECTURE\": \"UNET\",\n",
    "    \"MODEL_PARAMS\": {\"d_state\": 16, \"hidden_channels\": 64},\n",
    "    \"GRID_SIZE_TRAINING\": 128,\n",
    "    \"QCA_STEPS_TRAINING\": 200,\n",
    "    \"LR_RATE_M\": 5e-5,  # Learning rate m√°s bajo para fine-tuning\n",
    "    \"TOTAL_EPISODES\": 300,\n",
    "    \"LOAD_FROM_EXPERIMENT\": \"UNET_32ch_D8_Colab\",  # Experimento base\n",
    "}\n",
    "\n",
    "print(\"üí° Ejemplos de configuraci√≥n definidos.\")\n",
    "print(\"   Copia y pega uno de estos ejemplos en EXPERIMENT_CONFIG para usarlo.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
