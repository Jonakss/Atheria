{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Atheria 4: Entrenamiento Progresivo (Long-Running)\n",
        "\n",
        "Notebook optimizado para **entrenamientos largos** (muchas horas) con aprovechamiento m√°ximo de cuota de GPU.\n",
        "\n",
        "## ‚ú® Caracter√≠sticas\n",
        "\n",
        "- üîÑ **Auto-guardado en Google Drive** - Sincronizaci√≥n configurable\n",
        "- üìä **Monitoreo de recursos** - GPU%, RAM, tiempo de sesi√≥n\n",
        "- ‚ö° **Auto-recuperaci√≥n** - Contin√∫a autom√°ticamente desde checkpoints\n",
        "- ‚è∞ **L√≠mite de tiempo autom√°tico** - Guardado de emergencia antes de timeout\n",
        "- üìà **Visualizaci√≥n en tiempo real** - Progreso, m√©tricas, recursos\n",
        "- üíæ **Smart Checkpointing** - Solo guarda mejores modelos + √∫ltimo\n",
        "\n",
        "## üìã Cuotas de GPU\n",
        "\n",
        "- **Colab Free**: ~12 horas/d√≠a (variable)\n",
        "- **Colab Pro**: ~24 horas continuas\n",
        "- **Kaggle**: 30 horas/semana (T4/P100)\n",
        "\n",
        "## üéØ Workflow Recomendado\n",
        "\n",
        "1. Configurar experimento (Secci√≥n 4)\n",
        "2. Ejecutar todas las celdas autom√°ticamente\n",
        "3. Dejar corriendo sin supervisi√≥n\n",
        "4. Checkpoints se guardan autom√°ticamente en Drive\n",
        "5. Si se desconecta: ejecutar de nuevo, auto-recupera desde Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üì¶ Secci√≥n 1: Setup y Detecci√≥n de Entorno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detectar entorno (Kaggle o Colab)\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# IMPORTANTE: Verificar Kaggle PRIMERO (tiene google.colab instalado pero no funciona)\n",
        "IN_KAGGLE = os.path.exists(\"/kaggle/input\") or os.path.exists(\"/kaggle/working\")\n",
        "\n",
        "# Solo si NO es Kaggle, verificar Colab\n",
        "if not IN_KAGGLE:\n",
        "    try:\n",
        "        import google.colab\n",
        "        # Verificar que realmente estemos en Colab (existe /content)\n",
        "        IN_COLAB = os.path.exists(\"/content\")\n",
        "    except:\n",
        "        IN_COLAB = False\n",
        "else:\n",
        "    IN_COLAB = False\n",
        "\n",
        "ENV_NAME = \"Kaggle\" if IN_KAGGLE else \"Colab\" if IN_COLAB else \"Local\"\n",
        "print(f\"üåç Entorno detectado: {ENV_NAME}\")\n",
        "\n",
        "# Instalar dependencias b√°sicas\n",
        "print(\"üì¶ Instalando dependencias...\")\n",
        "%pip install -q snntorch scikit-learn matplotlib\n",
        "\n",
        "# Para Colab: instalar pybind11 (opcional, solo para motor nativo)\n",
        "if IN_COLAB:\n",
        "    %pip install -q pybind11\n",
        "\n",
        "print(\"‚úÖ Dependencias instaladas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üíæ Secci√≥n 2: Google Drive - Montaje y Configuraci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Montar Google Drive (solo Colab)\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    print(\"üìÅ Montando Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "    DRIVE_ROOT = Path(\"/content/drive/MyDrive/Atheria\")\n",
        "    print(f\"‚úÖ Drive montado en: {DRIVE_ROOT}\")\n",
        "elif IN_KAGGLE:\n",
        "    # En Kaggle, usar /kaggle/working como alternativa\n",
        "    DRIVE_ROOT = Path(\"/kaggle/working/atheria_checkpoints\")\n",
        "    print(f\"üìÅ Usando directorio local: {DRIVE_ROOT}\")\n",
        "else:\n",
        "    DRIVE_ROOT = Path.home() / \"atheria_checkpoints\"\n",
        "    print(f\"üíª Usando directorio local: {DRIVE_ROOT}\")\n",
        "\n",
        "# Crear estructura de carpetas\n",
        "DRIVE_CHECKPOINT_DIR = DRIVE_ROOT / \"checkpoints\"\n",
        "DRIVE_LOGS_DIR = DRIVE_ROOT / \"logs\"\n",
        "DRIVE_EXPORTS_DIR = DRIVE_ROOT / \"exports\"\n",
        "\n",
        "for directory in [DRIVE_CHECKPOINT_DIR, DRIVE_LOGS_DIR, DRIVE_EXPORTS_DIR]:\n",
        "    directory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"\\nüìÇ Estructura de carpetas creada:\")\n",
        "print(f\"  - Checkpoints: {DRIVE_CHECKPOINT_DIR}\")\n",
        "print(f\"  - Logs: {DRIVE_LOGS_DIR}\")\n",
        "print(f\"  - Exports: {DRIVE_EXPORTS_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üîß Secci√≥n 3: Clonar Proyecto Atheria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurar ruta del proyecto\n",
        "if IN_KAGGLE:\n",
        "    PROJECT_ROOT = Path(\"/kaggle/working/Atheria\")\n",
        "    if not PROJECT_ROOT.exists():\n",
        "        print(\"‚ö†Ô∏è Proyecto no encontrado. Clonando desde GitHub...\")\n",
        "        !git clone https://github.com/Jonakss/Atheria.git /kaggle/working/Atheria\n",
        "elif IN_COLAB:\n",
        "    PROJECT_ROOT = Path(\"/content/Atheria\")\n",
        "    if not PROJECT_ROOT.exists():\n",
        "        print(\"üì• Clonando proyecto desde GitHub...\")\n",
        "        !git clone https://github.com/Jonakss/Atheria.git /content/Atheria\n",
        "else:\n",
        "    # Local: asumir que estamos en notebooks/\n",
        "    PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
        "\n",
        "# Agregar al path de Python\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "print(f\"üìÅ Proyecto configurado en: {PROJECT_ROOT}\")\n",
        "\n",
        "# Verificar estructura b√°sica\n",
        "src_path = PROJECT_ROOT / \"src\"\n",
        "if src_path.exists():\n",
        "    print(\"‚úÖ Estructura del proyecto verificada\")\n",
        "else:\n",
        "    print(\"‚ùå Error: No se encontr√≥ la carpeta 'src'. Verifica la instalaci√≥n.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üìä Secci√≥n 4: Utilidades de Monitoreo de Recursos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import psutil\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "from IPython.display import clear_output\n",
        "\n",
        "class ResourceMonitor:\n",
        "    \"\"\"Monitor de recursos GPU/RAM/Tiempo\"\"\"\n",
        "    \n",
        "    def __init__(self, max_training_hours=10):\n",
        "        self.start_time = time.time()\n",
        "        self.max_training_seconds = max_training_hours * 3600\n",
        "        self.max_training_hours = max_training_hours\n",
        "        \n",
        "    def get_gpu_usage(self):\n",
        "        \"\"\"Retorna uso de GPU en %\"\"\"\n",
        "        if not torch.cuda.is_available():\n",
        "            return 0.0\n",
        "        try:\n",
        "            return torch.cuda.utilization()\n",
        "        except:\n",
        "            return 0.0\n",
        "    \n",
        "    def get_gpu_memory(self):\n",
        "        \"\"\"Retorna memoria GPU usada/total en GB\"\"\"\n",
        "        if not torch.cuda.is_available():\n",
        "            return 0.0, 0.0\n",
        "        allocated = torch.cuda.memory_allocated() / 1e9  # GB\n",
        "        reserved = torch.cuda.memory_reserved() / 1e9\n",
        "        return allocated, reserved\n",
        "    \n",
        "    def get_ram_usage(self):\n",
        "        \"\"\"Retorna uso de RAM en GB\"\"\"\n",
        "        mem = psutil.virtual_memory()\n",
        "        return mem.used / 1e9, mem.total / 1e9\n",
        "    \n",
        "    def get_elapsed_time(self):\n",
        "        \"\"\"Retorna tiempo transcurrido y restante\"\"\"\n",
        "        elapsed = time.time() - self.start_time\n",
        "        remaining = max(0, self.max_training_seconds - elapsed)\n",
        "        return elapsed, remaining\n",
        "    \n",
        "    def should_stop(self):\n",
        "        \"\"\"True si se acerca al l√≠mite de tiempo (90%)\"\"\"\n",
        "        elapsed, remaining = self.get_elapsed_time()\n",
        "        return remaining < (self.max_training_seconds * 0.1)  # 10% restante\n",
        "    \n",
        "    def get_status_str(self):\n",
        "        \"\"\"Retorna string con estado de recursos\"\"\"\n",
        "        gpu_usage = self.get_gpu_usage()\n",
        "        gpu_mem_used, gpu_mem_reserved = self.get_gpu_memory()\n",
        "        ram_used, ram_total = self.get_ram_usage()\n",
        "        elapsed, remaining = self.get_elapsed_time()\n",
        "        \n",
        "        elapsed_str = str(timedelta(seconds=int(elapsed)))\n",
        "        remaining_str = str(timedelta(seconds=int(remaining)))\n",
        "        \n",
        "        status = (\n",
        "            f\"üìä RECURSOS:\\n\"\n",
        "            f\"  GPU Utilization: {gpu_usage:.1f}%\\n\"\n",
        "            f\"  GPU Memory: {gpu_mem_used:.2f}GB / {gpu_mem_reserved:.2f}GB\\n\"\n",
        "            f\"  RAM: {ram_used:.2f}GB / {ram_total:.2f}GB ({ram_used/ram_total*100:.1f}%)\\n\"\n",
        "            f\"  \\n\"\n",
        "            f\"‚è∞ TIEMPO:\\n\"\n",
        "            f\"  Transcurrido: {elapsed_str}\\n\"\n",
        "            f\"  Restante: {remaining_str} (de {self.max_training_hours}h m√°ximo)\\n\"\n",
        "        )\n",
        "        return status\n",
        "\n",
        "print(\"‚úÖ ResourceMonitor definido\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ‚öôÔ∏è Secci√≥n 5: Configuraci√≥n del Experimento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from types import SimpleNamespace\n",
        "\n",
        "# ============================================================================\n",
        "# üéØ CONFIGURACI√ìN DEL EXPERIMENTO - MODIFICA AQU√ç\n",
        "# ============================================================================\n",
        "\n",
        "EXPERIMENT_CONFIG = {\n",
        "    # Identificaci√≥n\n",
        "    \"EXPERIMENT_NAME\": \"UNET_64ch_D8_Progressive\",\n",
        "    \n",
        "    # Arquitectura\n",
        "    # Opciones: \"UNET\", \"SNN_UNET\", \"MLP\", \"DEEP_QCA\", \"UNET_CONVLSTM\", \"UNET_UNITARY\"\n",
        "    \"MODEL_ARCHITECTURE\": \"UNET\",\n",
        "    \n",
        "    # Par√°metros del modelo\n",
        "    \"MODEL_PARAMS\": {\n",
        "        \"d_state\": 8,           # Dimensi√≥n del estado cu√°ntico\n",
        "        \"hidden_channels\": 64,  # Canales ocultos (32, 64, 128)\n",
        "    },\n",
        "    \n",
        "    # Entrenamiento\n",
        "    \"GRID_SIZE_TRAINING\": 64,     # Tama√±o del grid\n",
        "    \"QCA_STEPS_TRAINING\": 100,    # Pasos de simulaci√≥n por episodio\n",
        "    \"LR_RATE_M\": 1e-4,            # Learning rate\n",
        "    \"GAMMA_DECAY\": 0.01,          # Decaimiento Lindbladian\n",
        "    \n",
        "    # Configuraci√≥n progresiva\n",
        "    \"TOTAL_EPISODES\": 1000,       # Total de episodios a entrenar\n",
        "    \"SAVE_EVERY_EPISODES\": 10,    # Checkpoint local cada N episodios\n",
        "    \"DRIVE_SYNC_EVERY\": 50,       # Sincronizar a Drive cada N episodios\n",
        "    \"MAX_TRAINING_HOURS\": 10,     # Tiempo m√°ximo de entrenamiento\n",
        "    \n",
        "    # Auto-recuperaci√≥n\n",
        "    \"AUTO_RESUME\": True,          # Continuar autom√°ticamente desde Drive\n",
        "    \n",
        "    # Checkpointing inteligente\n",
        "    \"MAX_CHECKPOINTS_TO_KEEP\": 5, # Mejores N modelos a guardar\n",
        "}\n",
        "\n",
        "# Convertir a SimpleNamespace\n",
        "exp_cfg = SimpleNamespace(**EXPERIMENT_CONFIG)\n",
        "exp_cfg.MODEL_PARAMS = SimpleNamespace(**EXPERIMENT_CONFIG[\"MODEL_PARAMS\"])\n",
        "\n",
        "# Detectar dispositivo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "exp_cfg.DEVICE = device\n",
        "\n",
        "# Directorios espec√≠ficos del experimento\n",
        "EXPERIMENT_CHECKPOINT_DIR = DRIVE_CHECKPOINT_DIR / exp_cfg.EXPERIMENT_NAME\n",
        "EXPERIMENT_LOG_DIR = DRIVE_LOGS_DIR / exp_cfg.EXPERIMENT_NAME\n",
        "EXPERIMENT_CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "EXPERIMENT_LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Tambi√©n crear directorios locales (proyecto)\n",
        "LOCAL_CHECKPOINT_DIR = PROJECT_ROOT / \"output\" / \"checkpoints\" / exp_cfg.EXPERIMENT_NAME\n",
        "LOCAL_CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üìä CONFIGURACI√ìN DEL EXPERIMENTO\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Nombre: {exp_cfg.EXPERIMENT_NAME}\")\n",
        "print(f\"Arquitectura: {exp_cfg.MODEL_ARCHITECTURE}\")\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Grid: {exp_cfg.GRID_SIZE_TRAINING}x{exp_cfg.GRID_SIZE_TRAINING}\")\n",
        "print(f\"Total Episodios: {exp_cfg.TOTAL_EPISODES}\")\n",
        "print(f\"Learning Rate: {exp_cfg.LR_RATE_M}\")\n",
        "print(f\"Tiempo M√°ximo: {exp_cfg.MAX_TRAINING_HOURS}h\")\n",
        "print(f\"\\nüìÅ Checkpoints Drive: {EXPERIMENT_CHECKPOINT_DIR}\")\n",
        "print(f\"üìÅ Checkpoints Local: {LOCAL_CHECKPOINT_DIR}\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üîÑ Secci√≥n 6: Verificar/Cargar Checkpoint Existente (Auto-Resume)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def find_latest_checkpoint(checkpoint_dir):\n",
        "    \"\"\"Encuentra el √∫ltimo checkpoint en un directorio\"\"\"\n",
        "    checkpoints = list(checkpoint_dir.glob(\"*.pth\"))\n",
        "    if not checkpoints:\n",
        "        return None\n",
        "    \n",
        "    # Buscar last_model.pth primero\n",
        "    last_model = checkpoint_dir / \"last_model.pth\"\n",
        "    if last_model.exists():\n",
        "        return str(last_model)\n",
        "    \n",
        "    # Si no, buscar el m√°s reciente\n",
        "    latest = max(checkpoints, key=lambda p: p.stat().st_mtime)\n",
        "    return str(latest)\n",
        "\n",
        "# Buscar checkpoint existente\n",
        "checkpoint_path = None\n",
        "resume_from_episode = 0\n",
        "\n",
        "if exp_cfg.AUTO_RESUME:\n",
        "    print(\"üîç Buscando checkpoint existente...\")\n",
        "    \n",
        "    # Primero buscar en Drive\n",
        "    drive_checkpoint = find_latest_checkpoint(EXPERIMENT_CHECKPOINT_DIR)\n",
        "    if drive_checkpoint:\n",
        "        checkpoint_path = drive_checkpoint\n",
        "        print(f\"‚úÖ Checkpoint encontrado en Drive: {Path(checkpoint_path).name}\")\n",
        "    else:\n",
        "        # Si no hay en Drive, buscar en local\n",
        "        local_checkpoint = find_latest_checkpoint(LOCAL_CHECKPOINT_DIR)\n",
        "        if local_checkpoint:\n",
        "            checkpoint_path = local_checkpoint\n",
        "            print(f\"‚úÖ Checkpoint encontrado localmente: {Path(checkpoint_path).name}\")\n",
        "    \n",
        "    if checkpoint_path:\n",
        "        # Cargar checkpoint para ver en qu√© episodio estamos\n",
        "        try:\n",
        "            ckpt_data = torch.load(checkpoint_path, map_location='cpu')\n",
        "            resume_from_episode = ckpt_data.get('episode', 0)\n",
        "            print(f\"üîÑ Continuando desde episodio {resume_from_episode}\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"‚ö†Ô∏è Error leyendo checkpoint: {e}\")\n",
        "            checkpoint_path = None\n",
        "\n",
        "if checkpoint_path is None:\n",
        "    print(\"üÜï No se encontr√≥ checkpoint previo. Iniciando desde cero.\")\n",
        "\n",
        "# Calcular episodios restantes\n",
        "episodes_remaining = max(0, exp_cfg.TOTAL_EPISODES - resume_from_episode)\n",
        "print(f\"\\nüìà Episodios restantes: {episodes_remaining}/{exp_cfg.TOTAL_EPISODES}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üöÄ Secci√≥n 7: Loop de Entrenamiento Progresivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.trainers.qc_trainer_v4 import QC_Trainer_v4\n",
        "from src.model_loader import instantiate_model, load_weights, load_checkpoint_data\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output, display\n",
        "import json\n",
        "\n",
        "# Inicializar monitor de recursos\n",
        "monitor = ResourceMonitor(max_training_hours=exp_cfg.MAX_TRAINING_HOURS)\n",
        "\n",
        "# Instanciar modelo\n",
        "model = instantiate_model(exp_cfg)\n",
        "\n",
        "# Cargar pesos si hay checkpoint\n",
        "if checkpoint_path:\n",
        "    ckpt_data = load_checkpoint_data(checkpoint_path)\n",
        "    if ckpt_data:\n",
        "        load_weights(model, ckpt_data)\n",
        "\n",
        "# Inicializar trainer\n",
        "trainer = QC_Trainer_v4(\n",
        "    experiment_name=exp_cfg.EXPERIMENT_NAME,\n",
        "    model=model,\n",
        "    device=device,\n",
        "    lr=exp_cfg.LR_RATE_M,\n",
        "    grid_size=exp_cfg.GRID_SIZE_TRAINING,\n",
        "    qca_steps=exp_cfg.QCA_STEPS_TRAINING,\n",
        "    gamma_decay=exp_cfg.GAMMA_DECAY,\n",
        "    max_checkpoints_to_keep=exp_cfg.MAX_CHECKPOINTS_TO_KEEP\n",
        ")\n",
        "\n",
        "# Tracking de m√©tricas\n",
        "training_log = {\n",
        "    \"experiment_name\": exp_cfg.EXPERIMENT_NAME,\n",
        "    \"config\": EXPERIMENT_CONFIG,\n",
        "    \"episodes\": [],\n",
        "    \"losses\": [],\n",
        "    \"metrics\": [],\n",
        "    \"checkpoints_saved\": []\n",
        "}\n",
        "\n",
        "# Funci√≥n auxiliar para guardar en Drive\n",
        "def sync_checkpoint_to_drive(local_path, episode_num):\n",
        "    \"\"\"Copia checkpoint local a Drive\"\"\"\n",
        "    try:\n",
        "        import shutil\n",
        "        filename = Path(local_path).name\n",
        "        drive_path = EXPERIMENT_CHECKPOINT_DIR / filename\n",
        "        shutil.copy2(local_path, drive_path)\n",
        "        logger.info(f\"üíæ Checkpoint sincronizado a Drive: {filename}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logger.error(f\"‚ùå Error sincronizando a Drive: {e}\")\n",
        "        return False\n",
        "\n",
        "# ENTRENAMIENTO PROGRESIVO\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üéØ INICIANDO ENTRENAMIENTO PROGRESIVO\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "try:\n",
        "    for episode in range(resume_from_episode, exp_cfg.TOTAL_EPISODES):\n",
        "        \n",
        "        # Verificar l√≠mite de tiempo ANTES de empezar episodio\n",
        "        if monitor.should_stop():\n",
        "            print(\"\\n‚è∞ ¬°L√çMITE DE TIEMPO ALCANZADO!\")\n",
        "            print(\"üíæ Guardando checkpoint de emergencia...\")\n",
        "            \n",
        "            # Guardar checkpoint de emergencia\n",
        "            trainer.save_checkpoint(episode, is_best=False)\n",
        "            \n",
        "            # Sincronizar a Drive\n",
        "            last_checkpoint = LOCAL_CHECKPOINT_DIR / \"last_model.pth\"\n",
        "            if last_checkpoint.exists():\n",
        "                sync_checkpoint_to_drive(str(last_checkpoint), episode)\n",
        "            \n",
        "            print(f\"‚úÖ Entrenamiento detenido en episodio {episode}\")\n",
        "            print(f\"üìä Progreso: {episode}/{exp_cfg.TOTAL_EPISODES} episodios ({episode/exp_cfg.TOTAL_EPISODES*100:.1f}%)\")\n",
        "            break\n",
        "        \n",
        "        # Entrenar episodio\n",
        "        epoch_result = trainer.train_episode(episode)\n",
        "        \n",
        "        # Registrar m√©tricas\n",
        "        training_log[\"episodes\"].append(episode)\n",
        "        training_log[\"losses\"].append(epoch_result.get(\"loss_total\", 0))\n",
        "        training_log[\"metrics\"].append(epoch_result)\n",
        "        \n",
        "        # Guardar checkpoint peri√≥dicamente\n",
        "        if (episode + 1) % exp_cfg.SAVE_EVERY_EPISODES == 0:\n",
        "            is_best = (episode + 1) % (exp_cfg.SAVE_EVERY_EPISODES * 5) == 0  # Cada 50 eps = best candidate\n",
        "            trainer.save_checkpoint(episode, is_best=is_best)\n",
        "            training_log[\"checkpoints_saved\"].append(episode)\n",
        "        \n",
        "        # Sincronizar a Drive peri√≥dicamente\n",
        "        if (episode + 1) % exp_cfg.DRIVE_SYNC_EVERY == 0:\n",
        "            print(f\"\\nüíæ Sincronizando checkpoint a Drive (episodio {episode})...\")\n",
        "            last_checkpoint = LOCAL_CHECKPOINT_DIR / \"last_model.pth\"\n",
        "            if last_checkpoint.exists():\n",
        "                sync_checkpoint_to_drive(str(last_checkpoint), episode)\n",
        "            \n",
        "            # Tambi√©n sincronizar mejores modelos\n",
        "            best_checkpoint = LOCAL_CHECKPOINT_DIR / \"best_model.pth\"\n",
        "            if best_checkpoint.exists():\n",
        "                sync_checkpoint_to_drive(str(best_checkpoint), episode)\n",
        "        \n",
        "        # Visualizaci√≥n cada 10 episodios\n",
        "        if (episode + 1) % 10 == 0:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print(\"=\" * 70)\n",
        "            print(f\"üìà PROGRESO: Episodio {episode + 1}/{exp_cfg.TOTAL_EPISODES} ({(episode+1)/exp_cfg.TOTAL_EPISODES*100:.1f}%)\")\n",
        "            print(\"=\" * 70)\n",
        "            \n",
        "            # Mostrar recursos\n",
        "            print(monitor.get_status_str())\n",
        "            \n",
        "            # Mostrar √∫ltimas m√©tricas\n",
        "            if len(training_log[\"losses\"]) > 0:\n",
        "                recent_losses = training_log[\"losses\"][-10:]\n",
        "                avg_loss = sum(recent_losses) / len(recent_losses)\n",
        "                print(f\"\\nüìä M√âTRICAS (√∫ltimos 10 episodios):\")\n",
        "                print(f\"  Loss promedio: {avg_loss:.4f}\")\n",
        "                print(f\"  Loss actual: {training_log['losses'][-1]:.4f}\")\n",
        "            \n",
        "            # Gr√°fico de p√©rdida\n",
        "            if len(training_log[\"episodes\"]) > 1:\n",
        "                plt.figure(figsize=(10, 4))\n",
        "                plt.plot(training_log[\"episodes\"], training_log[\"losses\"], 'b-', alpha=0.6)\n",
        "                plt.xlabel('Episodio')\n",
        "                plt.ylabel('Loss')\n",
        "                plt.title(f'{exp_cfg.EXPERIMENT_NAME} - Progreso de Entrenamiento')\n",
        "                plt.grid(True, alpha=0.3)\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"‚úÖ ENTRENAMIENTO COMPLETADO EXITOSAMENTE\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n‚ö†Ô∏è Entrenamiento interrumpido por usuario\")\n",
        "    print(\"üíæ Guardando checkpoint...\")\n",
        "    trainer.save_checkpoint(episode, is_best=False)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå ERROR DURANTE ENTRENAMIENTO: {e}\")\n",
        "    logger.error(f\"Error: {e}\", exc_info=True)\n",
        "    print(\"üíæ Guardando checkpoint de emergencia...\")\n",
        "    try:\n",
        "        trainer.save_checkpoint(episode, is_best=False)\n",
        "    except:\n",
        "        pass\n",
        "    raise\n",
        "\n",
        "finally:\n",
        "    # Guardar log de entrenamiento en Drive\n",
        "    log_file = EXPERIMENT_LOG_DIR / f\"training_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    with open(log_file, 'w') as f:\n",
        "        json.dump(training_log, f, indent=2)\n",
        "    print(f\"\\nüìÑ Log guardado en: {log_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üìä Secci√≥n 8: Visualizaci√≥n de Resultados Finales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "if len(training_log[\"episodes\"]) > 0:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # 1. P√©rdida total\n",
        "    axes[0, 0].plot(training_log[\"episodes\"], training_log[\"losses\"], 'b-', alpha=0.6, label='Loss')\n",
        "    axes[0, 0].set_xlabel('Episodio')\n",
        "    axes[0, 0].set_ylabel('Loss Total')\n",
        "    axes[0, 0].set_title('Evoluci√≥n de la P√©rdida')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    axes[0, 0].legend()\n",
        "    \n",
        "    # 2. M√©tricas individuales (si est√°n disponibles)\n",
        "    if len(training_log[\"metrics\"]) > 0 and \"survival_rate\" in training_log[\"metrics\"][0]:\n",
        "        survival_rates = [m.get(\"survival_rate\", 0) for m in training_log[\"metrics\"]]\n",
        "        axes[0, 1].plot(training_log[\"episodes\"], survival_rates, 'g-', alpha=0.6, label='Survival Rate')\n",
        "        axes[0, 1].set_xlabel('Episodio')\n",
        "        axes[0, 1].set_ylabel('Survival Rate')\n",
        "        axes[0, 1].set_title('Tasa de Supervivencia')\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "        axes[0, 1].legend()\n",
        "    \n",
        "    # 3. Checkpoints guardados\n",
        "    axes[1, 0].scatter(training_log[\"checkpoints_saved\"], \n",
        "                      [1] * len(training_log[\"checkpoints_saved\"]), \n",
        "                      c='red', marker='|', s=100, label='Checkpoint')\n",
        "    axes[1, 0].set_xlabel('Episodio')\n",
        "    axes[1, 0].set_yticks([])\n",
        "    axes[1, 0].set_title('Checkpoints Guardados')\n",
        "    axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
        "    axes[1, 0].legend()\n",
        "    \n",
        "    # 4. Histograma de p√©rdidas\n",
        "    axes[1, 1].hist(training_log[\"losses\"], bins=30, alpha=0.7, color='purple', edgecolor='black')\n",
        "    axes[1, 1].set_xlabel('Loss')\n",
        "    axes[1, 1].set_ylabel('Frecuencia')\n",
        "    axes[1, 1].set_title('Distribuci√≥n de P√©rdidas')\n",
        "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(EXPERIMENT_LOG_DIR / 'training_summary.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nüìä Gr√°ficos guardados en: {EXPERIMENT_LOG_DIR / 'training_summary.png'}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No hay datos de entrenamiento para visualizar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üì¶ Secci√≥n 9: Exportaci√≥n y Finalizaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.model_loader import load_model\n",
        "import shutil\n",
        "\n",
        "print(\"üì§ Exportando modelo final...\\n\")\n",
        "\n",
        "# Encontrar mejor checkpoint\n",
        "best_checkpoint = LOCAL_CHECKPOINT_DIR / \"best_model.pth\"\n",
        "if not best_checkpoint.exists():\n",
        "    best_checkpoint = find_latest_checkpoint(LOCAL_CHECKPOINT_DIR)\n",
        "\n",
        "if best_checkpoint:\n",
        "    print(f\"üì• Cargando modelo desde: {Path(best_checkpoint).name}\")\n",
        "    \n",
        "    # Cargar modelo\n",
        "    model = load_model(exp_cfg, str(best_checkpoint))\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    \n",
        "    # Exportar a TorchScript\n",
        "    example_input = torch.randn(1, 2 * exp_cfg.MODEL_PARAMS.d_state, \n",
        "                                exp_cfg.GRID_SIZE_TRAINING, \n",
        "                                exp_cfg.GRID_SIZE_TRAINING, device=device)\n",
        "    \n",
        "    torchscript_path = DRIVE_EXPORTS_DIR / f\"{exp_cfg.EXPERIMENT_NAME}_model.pt\"\n",
        "    \n",
        "    try:\n",
        "        traced_model = torch.jit.trace(model, example_input, strict=False)\n",
        "        traced_model.save(str(torchscript_path))\n",
        "        print(f\"‚úÖ Modelo TorchScript exportado: {torchscript_path.name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error exportando TorchScript: {e}\")\n",
        "    \n",
        "    # Copiar mejor checkpoint a Drive\n",
        "    drive_best_checkpoint = EXPERIMENT_CHECKPOINT_DIR / \"best_model_FINAL.pth\"\n",
        "    shutil.copy2(best_checkpoint, drive_best_checkpoint)\n",
        "    print(f\"‚úÖ Mejor checkpoint copiado: {drive_best_checkpoint.name}\")\n",
        "    \n",
        "    # Generar reporte de entrenamiento\n",
        "    report_path = EXPERIMENT_LOG_DIR / f\"{exp_cfg.EXPERIMENT_NAME}_REPORT.md\"\n",
        "    \n",
        "    with open(report_path, 'w') as f:\n",
        "        f.write(f\"# Reporte de Entrenamiento: {exp_cfg.EXPERIMENT_NAME}\\n\\n\")\n",
        "        f.write(f\"**Fecha:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
        "        f.write(f\"## Configuraci√≥n\\n\\n\")\n",
        "        f.write(f\"```json\\n{json.dumps(EXPERIMENT_CONFIG, indent=2)}\\n```\\n\\n\")\n",
        "        f.write(f\"## Resultados\\n\\n\")\n",
        "        f.write(f\"- **Total de episodios completados:** {len(training_log['episodes'])}\\n\")\n",
        "        f.write(f\"- **Checkpoints guardados:** {len(training_log['checkpoints_saved'])}\\n\")\n",
        "        \n",
        "        if len(training_log[\"losses\"]) > 0:\n",
        "            f.write(f\"- **Loss final:** {training_log['losses'][-1]:.4f}\\n\")\n",
        "            f.write(f\"- **Loss promedio:** {np.mean(training_log['losses']):.4f}\\n\")\n",
        "            f.write(f\"- **Loss m√≠nimo:** {min(training_log['losses']):.4f}\\n\")\n",
        "        \n",
        "        f.write(f\"\\n## Archivos\\n\\n\")\n",
        "        f.write(f\"- Mejor modelo: `{drive_best_checkpoint.name}`\\n\")\n",
        "        f.write(f\"- TorchScript: `{torchscript_path.name}`\\n\")\n",
        "        f.write(f\"- Logs: `{EXPERIMENT_LOG_DIR.name}`\\n\")\n",
        "    \n",
        "    print(f\"‚úÖ Reporte generado: {report_path.name}\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No se encontr√≥ checkpoint para exportar\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üéâ EXPORTACI√ìN COMPLETADA\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nüìÅ Todos los archivos est√°n en Drive:\")\n",
        "print(f\"  - Checkpoints: {EXPERIMENT_CHECKPOINT_DIR}\")\n",
        "print(f\"  - Logs: {EXPERIMENT_LOG_DIR}\")\n",
        "print(f\"  - Exports: {DRIVE_EXPORTS_DIR}\")\n",
        "print(\"\\n‚úÖ Puedes cerrar el notebook. Todo est√° guardado en Drive.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üìù Notas Finales\n",
        "\n",
        "### ‚úÖ Checklist de Verificaci√≥n\n",
        "\n",
        "- ‚úì Checkpoints guardados en Drive cada 50 episodios\n",
        "- ‚úì Logs de entrenamiento persistidos\n",
        "- ‚úì Modelo final exportado a TorchScript\n",
        "- ‚úì Reporte de entrenamiento generado\n",
        "- ‚úì Auto-recuperaci√≥n configurada para pr√≥xima sesi√≥n\n",
        "\n",
        "### üîÑ Para Continuar Entrenamiento\n",
        "\n",
        "1. Ejecutar este notebook de nuevo\n",
        "2. Mantener `AUTO_RESUME = True`\n",
        "3. Ajustar `TOTAL_EPISODES` si quieres m√°s episodios\n",
        "4. El notebook detectar√° autom√°ticamente el √∫ltimo checkpoint en Drive\n",
        "\n",
        "### üìä Mejores Pr√°cticas\n",
        "\n",
        "- **Colab Free**: Entrenar en sesiones de 6-8 horas\n",
        "- **Colab Pro**: Sesiones de 12-20 horas\n",
        "- **Kaggle**: Aprovechar las 30 horas semanales\n",
        "- Siempre verificar que Drive est√© sincronizando correctamente\n",
        "- Revisar gr√°ficos cada 50-100 episodios para detectar problemas\n",
        "\n",
        "---\n",
        "\n",
        "**¬°Feliz entrenamiento! üöÄ**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}