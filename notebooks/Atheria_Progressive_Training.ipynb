{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Atheria 4: Entrenamiento Progresivo (Long-Running)\n",
    "\n",
    "Notebook optimizado para **entrenamientos largos** (muchas horas) con aprovechamiento m√°ximo de cuota de GPU.\n",
    "\n",
    "## ‚ú® Caracter√≠sticas\n",
    "\n",
    "- üîÑ **Auto-guardado en Google Drive** - Sincronizaci√≥n configurable\n",
    "- üìä **Monitoreo de recursos** - GPU%, RAM, tiempo de sesi√≥n\n",
    "- ‚ö° **Auto-recuperaci√≥n** - Contin√∫a autom√°ticamente desde checkpoints\n",
    "- ‚è∞ **L√≠mite de tiempo autom√°tico** - Guardado de emergencia antes de timeout\n",
    "- üìà **Visualizaci√≥n en tiempo real** - Progreso, m√©tricas, recursos\n",
    "- üíæ **Smart Checkpointing** - Solo guarda mejores modelos + √∫ltimo\n",
    "\n",
    "## üìã Cuotas de GPU\n",
    "\n",
    "- **Colab Free**: ~12 horas/d√≠a (variable)\n",
    "- **Colab Pro**: ~24 horas continuas\n",
    "- **Kaggle**: 30 horas/semana (T4/P100)\n",
    "\n",
    "## üéØ Workflow Recomendado\n",
    "\n",
    "1. Configurar experimento (Secci√≥n 4)\n",
    "2. Ejecutar todas las celdas autom√°ticamente\n",
    "3. Dejar corriendo sin supervisi√≥n\n",
    "4. Checkpoints se guardan autom√°ticamente en Drive\n",
    "5. Si se desconecta: ejecutar de nuevo, auto-recupera desde Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üì¶ Secci√≥n 1: Setup y Detecci√≥n de Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Entorno detectado: Local\n",
      "üì¶ Instalando dependencias...\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/jonathan.correa/Projects/Atheria/ath_venv/lib/python3.10/site-packages/pip/__main__.py\", line 29, in <module>\n",
      "    from pip._internal.cli.main import main as _main\n",
      "  File \"/home/jonathan.correa/Projects/Atheria/ath_venv/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 9, in <module>\n",
      "    from pip._internal.cli.autocompletion import autocomplete\n",
      "  File \"/home/jonathan.correa/Projects/Atheria/ath_venv/lib/python3.10/site-packages/pip/_internal/cli/autocompletion.py\", line 12, in <module>\n",
      "    from pip._internal.metadata import get_default_environment\n",
      "  File \"/home/jonathan.correa/Projects/Atheria/ath_venv/lib/python3.10/site-packages/pip/_internal/metadata/__init__.py\", line 3, in <module>\n",
      "    from .base import BaseDistribution, BaseEnvironment, FilesystemWheel, MemoryWheel, Wheel\n",
      "  File \"/home/jonathan.correa/Projects/Atheria/ath_venv/lib/python3.10/site-packages/pip/_internal/metadata/base.py\", line 21, in <module>\n",
      "    from pip._vendor.packaging.requirements import Requirement\n",
      "  File \"/home/jonathan.correa/Projects/Atheria/ath_venv/lib/python3.10/site-packages/pip/_vendor/packaging/requirements.py\", line 10, in <module>\n",
      "    from pip._vendor.pyparsing import (  # noqa\n",
      "  File \"/home/jonathan.correa/Projects/Atheria/ath_venv/lib/python3.10/site-packages/pip/_vendor/pyparsing/__init__.py\", line 141, in <module>\n",
      "    from .helpers import *\n",
      "  File \"/home/jonathan.correa/Projects/Atheria/ath_venv/lib/python3.10/site-packages/pip/_vendor/pyparsing/helpers.py\", line 688, in <module>\n",
      "    common_html_entity = Regex(\"&(?P<entity>\" + \"|\".join(_htmlEntityMap) + \");\").set_name(\n",
      "  File \"/home/jonathan.correa/Projects/Atheria/ath_venv/lib/python3.10/site-packages/pip/_vendor/pyparsing/core.py\", line 2933, in __init__\n",
      "    self.re = re.compile(self.pattern, self.flags)\n",
      "  File \"/usr/lib/python3.10/re.py\", line 251, in compile\n",
      "    return _compile(pattern, flags)\n",
      "  File \"/usr/lib/python3.10/re.py\", line 303, in _compile\n",
      "    p = sre_compile.compile(pattern, flags)\n",
      "  File \"/usr/lib/python3.10/sre_compile.py\", line 788, in compile\n",
      "    p = sre_parse.parse(p, flags)\n",
      "  File \"/usr/lib/python3.10/sre_parse.py\", line 955, in parse\n",
      "    p = _parse_sub(source, state, flags & SRE_FLAG_VERBOSE, 0)\n",
      "  File \"/usr/lib/python3.10/sre_parse.py\", line 444, in _parse_sub\n",
      "    itemsappend(_parse(source, state, verbose, nested + 1,\n",
      "  File \"/usr/lib/python3.10/sre_parse.py\", line 846, in _parse\n",
      "    state.closegroup(group, p)\n",
      "  File \"/usr/lib/python3.10/sre_parse.py\", line 98, in closegroup\n",
      "    self.groupwidths[gid] = p.getwidth()\n",
      "  File \"/usr/lib/python3.10/sre_parse.py\", line 185, in getwidth\n",
      "    l, h = av.getwidth()\n",
      "  File \"/usr/lib/python3.10/sre_parse.py\", line 221, in getwidth\n",
      "    self.width = min(lo, MAXREPEAT - 1), min(hi, MAXREPEAT)\n",
      "KeyboardInterrupt\n",
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Dependencias instaladas\n"
     ]
    }
   ],
   "source": [
    "# Detectar entorno (Kaggle o Colab)\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# IMPORTANTE: Verificar Kaggle PRIMERO (tiene google.colab instalado pero no funciona)\n",
    "IN_KAGGLE = os.path.exists(\"/kaggle/input\") or os.path.exists(\"/kaggle/working\")\n",
    "\n",
    "# Solo si NO es Kaggle, verificar Colab\n",
    "if not IN_KAGGLE:\n",
    "    try:\n",
    "        import google.colab\n",
    "        # Verificar que realmente estemos en Colab (existe /content)\n",
    "        IN_COLAB = os.path.exists(\"/content\")\n",
    "    except:\n",
    "        IN_COLAB = False\n",
    "else:\n",
    "    IN_COLAB = False\n",
    "\n",
    "ENV_NAME = \"Kaggle\" if IN_KAGGLE else \"Colab\" if IN_COLAB else \"Local\"\n",
    "print(f\"üåç Entorno detectado: {ENV_NAME}\")\n",
    "\n",
    "# Instalar dependencias b√°sicas\n",
    "print(\"üì¶ Instalando dependencias...\")\n",
    "%pip install -q snntorch scikit-learn matplotlib\n",
    "\n",
    "# Para Colab: instalar pybind11 (opcional, solo para motor nativo)\n",
    "if IN_COLAB:\n",
    "    %pip install -q pybind11\n",
    "\n",
    "print(\"‚úÖ Dependencias instaladas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üíæ Secci√≥n 2: Google Drive - Montaje y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª Usando directorio local: /home/jonathan.correa/atheria_checkpoints\n",
      "\n",
      "üìÇ Estructura de carpetas creada:\n",
      "  - Checkpoints: /home/jonathan.correa/atheria_checkpoints/checkpoints\n",
      "  - Logs: /home/jonathan.correa/atheria_checkpoints/logs\n",
      "  - Exports: /home/jonathan.correa/atheria_checkpoints/exports\n"
     ]
    }
   ],
   "source": [
    "# Montar Google Drive (solo Colab)\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    print(\"üìÅ Montando Google Drive...\")\n",
    "    drive.mount('/content/drive')\n",
    "    DRIVE_ROOT = Path(\"/content/drive/MyDrive/Atheria\")\n",
    "    print(f\"‚úÖ Drive montado en: {DRIVE_ROOT}\")\n",
    "elif IN_KAGGLE:\n",
    "    # En Kaggle, usar /kaggle/working como alternativa\n",
    "    DRIVE_ROOT = Path(\"/kaggle/working/atheria_checkpoints\")\n",
    "    print(f\"üìÅ Usando directorio local: {DRIVE_ROOT}\")\n",
    "else:\n",
    "    DRIVE_ROOT = Path.home() / \"atheria_checkpoints\"\n",
    "    print(f\"üíª Usando directorio local: {DRIVE_ROOT}\")\n",
    "\n",
    "# Crear estructura de carpetas\n",
    "DRIVE_CHECKPOINT_DIR = DRIVE_ROOT / \"checkpoints\"\n",
    "DRIVE_LOGS_DIR = DRIVE_ROOT / \"logs\"\n",
    "DRIVE_EXPORTS_DIR = DRIVE_ROOT / \"exports\"\n",
    "\n",
    "for directory in [DRIVE_CHECKPOINT_DIR, DRIVE_LOGS_DIR, DRIVE_EXPORTS_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nüìÇ Estructura de carpetas creada:\")\n",
    "print(f\"  - Checkpoints: {DRIVE_CHECKPOINT_DIR}\")\n",
    "print(f\"  - Logs: {DRIVE_LOGS_DIR}\")\n",
    "print(f\"  - Exports: {DRIVE_EXPORTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîß Secci√≥n 3: Clonar Proyecto Atheria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Proyecto configurado en: /home/jonathan.correa/Projects/Atheria\n",
      "‚úÖ Estructura del proyecto verificada\n"
     ]
    }
   ],
   "source": [
    "# Configurar ruta del proyecto\n",
    "if IN_KAGGLE:\n",
    "    PROJECT_ROOT = Path(\"/kaggle/working/Atheria\")\n",
    "    if not PROJECT_ROOT.exists():\n",
    "        print(\"‚ö†Ô∏è Proyecto no encontrado. Clonando desde GitHub...\")\n",
    "        !git clone https://github.com/Jonakss/Atheria.git /kaggle/working/Atheria\n",
    "elif IN_COLAB:\n",
    "    PROJECT_ROOT = Path(\"/content/Atheria\")\n",
    "    if not PROJECT_ROOT.exists():\n",
    "        print(\"üì• Clonando proyecto desde GitHub...\")\n",
    "        !git clone https://github.com/Jonakss/Atheria.git /content/Atheria\n",
    "else:\n",
    "    # Local: asumir que estamos en notebooks/\n",
    "    PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "\n",
    "# Agregar al path de Python\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"üìÅ Proyecto configurado en: {PROJECT_ROOT}\")\n",
    "\n",
    "# Verificar estructura b√°sica\n",
    "src_path = PROJECT_ROOT / \"src\"\n",
    "if src_path.exists():\n",
    "    print(\"‚úÖ Estructura del proyecto verificada\")\n",
    "else:\n",
    "    print(\"‚ùå Error: No se encontr√≥ la carpeta 'src'. Verifica la instalaci√≥n.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Secci√≥n 4: Utilidades de Monitoreo de Recursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ResourceMonitor definido\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import psutil\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class ResourceMonitor:\n",
    "    \"\"\"Monitor de recursos GPU/RAM/Tiempo\"\"\"\n",
    "    \n",
    "    def __init__(self, max_training_hours=10):\n",
    "        self.start_time = time.time()\n",
    "        self.max_training_seconds = max_training_hours * 3600\n",
    "        self.max_training_hours = max_training_hours\n",
    "        \n",
    "    def get_gpu_usage(self):\n",
    "        \"\"\"Retorna uso de GPU en %\"\"\"\n",
    "        if not torch.cuda.is_available():\n",
    "            return 0.0\n",
    "        try:\n",
    "            return torch.cuda.utilization()\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def get_gpu_memory(self):\n",
    "        \"\"\"Retorna memoria GPU usada/total en GB\"\"\"\n",
    "        if not torch.cuda.is_available():\n",
    "            return 0.0, 0.0\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9  # GB\n",
    "        reserved = torch.cuda.memory_reserved() / 1e9\n",
    "        return allocated, reserved\n",
    "    \n",
    "    def get_ram_usage(self):\n",
    "        \"\"\"Retorna uso de RAM en GB\"\"\"\n",
    "        mem = psutil.virtual_memory()\n",
    "        return mem.used / 1e9, mem.total / 1e9\n",
    "    \n",
    "    def get_elapsed_time(self):\n",
    "        \"\"\"Retorna tiempo transcurrido y restante\"\"\"\n",
    "        elapsed = time.time() - self.start_time\n",
    "        remaining = max(0, self.max_training_seconds - elapsed)\n",
    "        return elapsed, remaining\n",
    "    \n",
    "    def should_stop(self):\n",
    "        \"\"\"True si se acerca al l√≠mite de tiempo (90%)\"\"\"\n",
    "        elapsed, remaining = self.get_elapsed_time()\n",
    "        return remaining < (self.max_training_seconds * 0.1)  # 10% restante\n",
    "    \n",
    "    def get_status_str(self):\n",
    "        \"\"\"Retorna string con estado de recursos\"\"\"\n",
    "        gpu_usage = self.get_gpu_usage()\n",
    "        gpu_mem_used, gpu_mem_reserved = self.get_gpu_memory()\n",
    "        ram_used, ram_total = self.get_ram_usage()\n",
    "        elapsed, remaining = self.get_elapsed_time()\n",
    "        \n",
    "        elapsed_str = str(timedelta(seconds=int(elapsed)))\n",
    "        remaining_str = str(timedelta(seconds=int(remaining)))\n",
    "        \n",
    "        status = (\n",
    "            f\"üìä RECURSOS:\\n\"\n",
    "            f\"  GPU Utilization: {gpu_usage:.1f}%\\n\"\n",
    "            f\"  GPU Memory: {gpu_mem_used:.2f}GB / {gpu_mem_reserved:.2f}GB\\n\"\n",
    "            f\"  RAM: {ram_used:.2f}GB / {ram_total:.2f}GB ({ram_used/ram_total*100:.1f}%)\\n\"\n",
    "            f\"  \\n\"\n",
    "            f\"‚è∞ TIEMPO:\\n\"\n",
    "            f\"  Transcurrido: {elapsed_str}\\n\"\n",
    "            f\"  Restante: {remaining_str} (de {self.max_training_hours}h m√°ximo)\\n\"\n",
    "        )\n",
    "        return status\n",
    "\n",
    "print(\"‚úÖ ResourceMonitor definido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚öôÔ∏è Secci√≥n 5: Configuraci√≥n del Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä CONFIGURACI√ìN DEL CURRICULUM\n",
      "======================================================================\n",
      "Experimento Ra√≠z: MultiPhase_Experiment_v1\n",
      "Total Fases: 2\n",
      "Device: cuda\n",
      "======================================================================\n",
      "\n",
      "üîπ FASE 1: Fase1_Vacuum_Stability\n",
      "   Load From: None\n",
      "   Model: UNET (d=4, ch=32)\n",
      "   Grid: 32x32\n",
      "   Episodes: 500\n",
      "\n",
      "üîπ FASE 2: Fase2_Matter_Emergence\n",
      "   Load From: Fase1_Vacuum_Stability\n",
      "   Model: UNET (d=4, ch=64)\n",
      "   Grid: 64x64\n",
      "   Episodes: 1000\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "import torch\n",
    "\n",
    "# ============================================================================\n",
    "# üéØ CONFIGURACI√ìN DEL CURRICULUM (FASES DE ENTRENAMIENTO)\n",
    "# ============================================================================\n",
    "\n",
    "# Definimos una lista de fases. El sistema ejecutar√° una tras otra.\n",
    "# Si una fase ya est√° completada (existe checkpoint final), pasar√° a la siguiente.\n",
    "\n",
    "TRAINING_PHASES = [\n",
    "    # --- FASE 1: ESTABILIDAD DEL VAC√çO ---\n",
    "    {\n",
    "        \"PHASE_NAME\": \"Fase1_Vacuum_Stability\",\n",
    "        \"LOAD_FROM_PHASE\": None,  # Empezar desde cero\n",
    "        \n",
    "        \"MODEL_ARCHITECTURE\": \"UNET\",\n",
    "        \"MODEL_PARAMS\": {\n",
    "            \"d_state\": 4,           # Dimensi√≥n baja para aprender r√°pido\n",
    "            \"hidden_channels\": 32,\n",
    "        },\n",
    "        \n",
    "        \"GRID_SIZE_TRAINING\": 32,\n",
    "        \"QCA_STEPS_TRAINING\": 50,\n",
    "        \"LR_RATE_M\": 1e-4,\n",
    "        \"GAMMA_DECAY\": 0.001,       # Poco decaimiento\n",
    "        \n",
    "        \"TOTAL_EPISODES\": 500,\n",
    "        \"SAVE_EVERY_EPISODES\": 50,\n",
    "    },\n",
    "    \n",
    "    # --- FASE 2: EMERGENCIA DE MATERIA ---\n",
    "    {\n",
    "        \"PHASE_NAME\": \"Fase2_Matter_Emergence\",\n",
    "        \"LOAD_FROM_PHASE\": \"Fase1_Vacuum_Stability\", # Cargar cerebro de Fase 1\n",
    "        \n",
    "        \"MODEL_ARCHITECTURE\": \"UNET\",\n",
    "        \"MODEL_PARAMS\": {\n",
    "            \"d_state\": 4,           # Misma dimensi√≥n\n",
    "            \"hidden_channels\": 64,  # M√°s capacidad (neuronas)\n",
    "        },\n",
    "        \n",
    "        \"GRID_SIZE_TRAINING\": 64,   # Grid m√°s grande\n",
    "        \"QCA_STEPS_TRAINING\": 100,\n",
    "        \"LR_RATE_M\": 5e-5,          # LR m√°s fino\n",
    "        \"GAMMA_DECAY\": 0.01,        # M√°s presi√≥n evolutiva\n",
    "        \n",
    "        \"TOTAL_EPISODES\": 1000,\n",
    "        \"SAVE_EVERY_EPISODES\": 20,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Configuraci√≥n Global\n",
    "GLOBAL_CONFIG = {\n",
    "    \"DRIVE_SYNC_EVERY\": 50,\n",
    "    \"MAX_TRAINING_HOURS\": 10,     # Tiempo total para TODAS las fases\n",
    "    \"AUTO_RESUME\": True,\n",
    "    \"MAX_CHECKPOINTS_TO_KEEP\": 3,\n",
    "}\n",
    "\n",
    "# Detectar dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Directorios base\n",
    "EXPERIMENT_ROOT_NAME = \"MultiPhase_Experiment_v1\" # Nombre carpeta ra√≠z\n",
    "BASE_CHECKPOINT_DIR = DRIVE_CHECKPOINT_DIR / EXPERIMENT_ROOT_NAME\n",
    "BASE_LOG_DIR = DRIVE_LOGS_DIR / EXPERIMENT_ROOT_NAME\n",
    "BASE_CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "BASE_LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä CONFIGURACI√ìN DEL CURRICULUM\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Experimento Ra√≠z: {EXPERIMENT_ROOT_NAME}\")\n",
    "print(f\"Total Fases: {len(TRAINING_PHASES)}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, phase in enumerate(TRAINING_PHASES):\n",
    "    print(f\"\\nüîπ FASE {i+1}: {phase['PHASE_NAME']}\")\n",
    "    print(f\"   Load From: {phase['LOAD_FROM_PHASE']}\")\n",
    "    print(f\"   Model: {phase['MODEL_ARCHITECTURE']} (d={phase['MODEL_PARAMS']['d_state']}, ch={phase['MODEL_PARAMS']['hidden_channels']})\")\n",
    "    print(f\"   Grid: {phase['GRID_SIZE_TRAINING']}x{phase['GRID_SIZE_TRAINING']}\")\n",
    "    print(f\"   Episodes: {phase['TOTAL_EPISODES']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "üöÄ INICIANDO FASE 1/2: Fase1_Vacuum_Stability\n",
      "######################################################################\n",
      "‚úÖ Fase Fase1_Vacuum_Stability ya completada. Saltando...\n",
      "\n",
      "######################################################################\n",
      "üöÄ INICIANDO FASE 2/2: Fase2_Matter_Emergence\n",
      "######################################################################\n",
      "üõ†Ô∏è Instanciando modelo UNET...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Resumiendo fase actual desde: last_model.pth\n",
      "\n",
      "‚ñ∂Ô∏è Entrenando 961 episodios...\n",
      "Ep 40/1000 | Loss: 3.1667 | üìä RECURSOS:\n",
      "‚òÅÔ∏è Sync Drive Ep 49\n",
      "Ep 50/1000 | Loss: 3.1293 | üìä RECURSOS:\n",
      "Ep 60/1000 | Loss: 3.1106 | üìä RECURSOS:\n",
      "\n",
      "üõë Entrenamiento interrumpido.\n",
      "\n",
      "======================================================================\n",
      "üèÅ ENTRENAMIENTO FINALIZADO\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from src.trainers.qc_trainer_v4 import QC_Trainer_v4\n",
    "from src.model_loader import instantiate_model, load_weights, load_checkpoint_data\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# Inicializar monitor de recursos GLOBAL\n",
    "monitor = ResourceMonitor(max_training_hours=GLOBAL_CONFIG[\"MAX_TRAINING_HOURS\"])\n",
    "\n",
    "\n",
    "def find_latest_checkpoint(checkpoint_dir):\n",
    "    \"\"\"Encuentra el √∫ltimo checkpoint en un directorio\"\"\"\n",
    "    checkpoints = list(checkpoint_dir.glob(\"*.pth\"))\n",
    "    if not checkpoints:\n",
    "        return None\n",
    "    \n",
    "    # Buscar last_model.pth primero\n",
    "    last_model = checkpoint_dir / \"last_model.pth\"\n",
    "    if last_model.exists():\n",
    "        return str(last_model)\n",
    "    \n",
    "    # Si no, buscar el m√°s reciente\n",
    "    latest = max(checkpoints, key=lambda p: p.stat().st_mtime)\n",
    "    return str(latest)\n",
    "\n",
    "# Funci√≥n auxiliar para guardar en Drive\n",
    "def sync_checkpoint_to_drive(local_path, drive_dir, filename=None):\n",
    "    \"\"\"Copia checkpoint local a Drive\"\"\"\n",
    "    try:\n",
    "        if filename is None:\n",
    "            filename = Path(local_path).name\n",
    "        drive_path = drive_dir / filename\n",
    "        shutil.copy2(local_path, drive_path)\n",
    "        # logger.info(f\"üíæ Checkpoint sincronizado a Drive: {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error sincronizando a Drive: {e}\")\n",
    "        return False\n",
    "\n",
    "# ============================================================================\n",
    "# üîÑ LOOP PRINCIPAL DE FASES\n",
    "# ============================================================================\n",
    "\n",
    "for phase_idx, phase_cfg in enumerate(TRAINING_PHASES):\n",
    "    PHASE_NAME = phase_cfg[\"PHASE_NAME\"]\n",
    "    \n",
    "    print(\"\\n\" + \"#\" * 70)\n",
    "    print(f\"üöÄ INICIANDO FASE {phase_idx+1}/{len(TRAINING_PHASES)}: {PHASE_NAME}\")\n",
    "    print(\"#\" * 70)\n",
    "    \n",
    "    # 1. Configuraci√≥n de Directorios para esta Fase\n",
    "    PHASE_CHECKPOINT_DIR = BASE_CHECKPOINT_DIR / PHASE_NAME\n",
    "    PHASE_LOG_DIR = BASE_LOG_DIR / PHASE_NAME\n",
    "    PHASE_CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    PHASE_LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    LOCAL_PHASE_DIR = PROJECT_ROOT / \"output\" / \"checkpoints\" / EXPERIMENT_ROOT_NAME / PHASE_NAME\n",
    "    LOCAL_PHASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 2. Verificar si la fase ya est√° completada\n",
    "    final_marker = PHASE_CHECKPOINT_DIR / \"PHASE_COMPLETED.marker\"\n",
    "    if final_marker.exists() and GLOBAL_CONFIG[\"AUTO_RESUME\"]:\n",
    "        print(f\"‚úÖ Fase {PHASE_NAME} ya completada. Saltando...\")\n",
    "        continue\n",
    "\n",
    "    # 3. Preparar Configuraci√≥n de Fase\n",
    "    current_exp_cfg = SimpleNamespace(**phase_cfg)\n",
    "    current_exp_cfg.MODEL_PARAMS = SimpleNamespace(**phase_cfg[\"MODEL_PARAMS\"])\n",
    "    current_exp_cfg.DEVICE = device\n",
    "    \n",
    "    # 4. Instanciar Modelo\n",
    "    print(f\"üõ†Ô∏è Instanciando modelo {phase_cfg['MODEL_ARCHITECTURE']}...\")\n",
    "    model = instantiate_model(current_exp_cfg)\n",
    "    \n",
    "    # 5. Cargar Pesos (L√≥gica de Transici√≥n)\n",
    "    resume_from_episode = 0\n",
    "    weights_loaded = False\n",
    "    \n",
    "    # A) Intentar resumir la propia fase (si se interrumpi√≥)\n",
    "    if GLOBAL_CONFIG[\"AUTO_RESUME\"]:\n",
    "        latest_ckpt = find_latest_checkpoint(PHASE_CHECKPOINT_DIR)\n",
    "        if not latest_ckpt:\n",
    "            latest_ckpt = find_latest_checkpoint(LOCAL_PHASE_DIR)\n",
    "            \n",
    "        if latest_ckpt:\n",
    "            print(f\"üîÑ Resumiendo fase actual desde: {Path(latest_ckpt).name}\")\n",
    "            ckpt_data = load_checkpoint_data(latest_ckpt)\n",
    "            if ckpt_data:\n",
    "                load_weights(model, ckpt_data) # Strict=True porque es el mismo modelo\n",
    "                resume_from_episode = ckpt_data.get('episode', 0)\n",
    "                weights_loaded = True\n",
    "    \n",
    "    # B) Si no se resume, cargar de fase anterior (Transfer Learning)\n",
    "    if not weights_loaded and phase_cfg[\"LOAD_FROM_PHASE\"]:\n",
    "        prev_phase_name = phase_cfg[\"LOAD_FROM_PHASE\"]\n",
    "        print(f\"üì• Buscando pesos de fase anterior: {prev_phase_name}\")\n",
    "        \n",
    "        prev_dir = BASE_CHECKPOINT_DIR / prev_phase_name\n",
    "        best_prev = prev_dir / \"best_model.pth\"\n",
    "        if not best_prev.exists():\n",
    "             best_prev = find_latest_checkpoint(prev_dir)\n",
    "             \n",
    "        if best_prev and Path(best_prev).exists():\n",
    "            print(f\"‚úÖ Cargando pesos previos de: {Path(best_prev).name}\")\n",
    "            ckpt_data = load_checkpoint_data(str(best_prev))\n",
    "            \n",
    "            # CR√çTICO: strict=False para permitir cambio de arquitectura (ej: d_state 4 -> 8)\n",
    "            # Smart Load: Filter out size mismatches\n",
    "            model_state = model.state_dict()\n",
    "            pretrained_state = ckpt_data['model_state_dict']\n",
    "            filtered_state = {}\n",
    "            ignored_keys = []\n",
    "            \n",
    "            for k, v in pretrained_state.items():\n",
    "                if k in model_state:\n",
    "                    if v.shape == model_state[k].shape:\n",
    "                        filtered_state[k] = v\n",
    "                    else:\n",
    "                        ignored_keys.append(k)\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "            if ignored_keys:\n",
    "                print(f\"‚ö†Ô∏è Ignoring {len(ignored_keys)} layers due to shape mismatch (Transfer Learning).\")\n",
    "            \n",
    "            missing, unexpected = model.load_state_dict(filtered_state, strict=False)\n",
    "            print(f\"‚ÑπÔ∏è Transfer Learning: {len(missing)} capas nuevas inicializadas, {len(unexpected)} capas descartadas.\")\n",
    "            weights_loaded = True\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No se encontraron pesos de la fase anterior. Iniciando desde cero (aleatorio).\")\n",
    "            \n",
    "    if not weights_loaded:\n",
    "        print(\"üÜï Iniciando fase con pesos aleatorios.\")\n",
    "\n",
    "    # 6. Inicializar Trainer\n",
    "    trainer = QC_Trainer_v4(\n",
    "        experiment_name=f\"{EXPERIMENT_ROOT_NAME}/{PHASE_NAME}\", # Subdirectorio en logs internos\n",
    "        model=model,\n",
    "        model_params=phase_cfg['MODEL_PARAMS'], # Fix: Pass model params\n",
    "        device=device,\n",
    "        lr=phase_cfg[\"LR_RATE_M\"],\n",
    "        grid_size=phase_cfg[\"GRID_SIZE_TRAINING\"],\n",
    "        qca_steps=phase_cfg[\"QCA_STEPS_TRAINING\"],\n",
    "        gamma_decay=phase_cfg[\"GAMMA_DECAY\"],\n",
    "        max_checkpoints_to_keep=GLOBAL_CONFIG[\"MAX_CHECKPOINTS_TO_KEEP\"]\n",
    "    )\n",
    "    \n",
    "    # Hack para redirigir checkpoints del trainer a nuestra carpeta de fase local\n",
    "    trainer.checkpoint_dir = str(LOCAL_PHASE_DIR)\n",
    "    \n",
    "    # Tracking local\n",
    "    training_log = {\"episodes\": [], \"losses\": []}\n",
    "    \n",
    "    # 7. Loop de Episodios\n",
    "    print(f\"\\n‚ñ∂Ô∏è Entrenando {phase_cfg['TOTAL_EPISODES'] - resume_from_episode} episodios...\")\n",
    "    \n",
    "    try:\n",
    "        for episode in range(resume_from_episode, phase_cfg[\"TOTAL_EPISODES\"]):\n",
    "            \n",
    "            # Check tiempo global\n",
    "            if monitor.should_stop():\n",
    "                print(f\"\\n‚è∞ TIEMPO GLOBAL AGOTADO en Fase {PHASE_NAME}, Ep {episode}\")\n",
    "                trainer.save_checkpoint(episode, is_best=False)\n",
    "                sync_checkpoint_to_drive(str(LOCAL_PHASE_DIR / f\"checkpoint_ep{episode}.pth\"), PHASE_CHECKPOINT_DIR)\n",
    "                raise KeyboardInterrupt(\"Global Timeout\") # Salir de todo\n",
    "                \n",
    "            # Entrenar\n",
    "            loss, metrics = trainer.train_episode(episode)\n",
    "            # loss = epoch_result.get(\"loss_total\", 0)\n",
    "            \n",
    "            training_log[\"episodes\"].append(episode)\n",
    "            training_log[\"losses\"].append(loss)\n",
    "            \n",
    "            # Guardar/Sync\n",
    "            if (episode + 1) % phase_cfg[\"SAVE_EVERY_EPISODES\"] == 0:\n",
    "                is_best = (episode + 1) % (phase_cfg[\"SAVE_EVERY_EPISODES\"] * 2) == 0\n",
    "                trainer.save_checkpoint(episode, is_best=is_best)\n",
    "                \n",
    "            if (episode + 1) % GLOBAL_CONFIG[\"DRIVE_SYNC_EVERY\"] == 0:\n",
    "                # Sync last & best\n",
    "                sync_checkpoint_to_drive(str(LOCAL_PHASE_DIR / \"last_checkpoint.pth\"), PHASE_CHECKPOINT_DIR, \"last_model.pth\")\n",
    "                if (LOCAL_PHASE_DIR / \"best_model.pth\").exists():\n",
    "                    sync_checkpoint_to_drive(str(LOCAL_PHASE_DIR / \"best_model.pth\"), PHASE_CHECKPOINT_DIR)\n",
    "                print(f\"‚òÅÔ∏è Sync Drive Ep {episode}\")\n",
    "\n",
    "            # Visualizaci√≥n simple\n",
    "            if (episode + 1) % 10 == 0:\n",
    "                print(f\"Ep {episode+1}/{phase_cfg['TOTAL_EPISODES']} | Loss: {loss:.4f} | {monitor.get_status_str().splitlines()[0]}\")\n",
    "        \n",
    "        # Fin de Fase\n",
    "        print(f\"\\n‚úÖ FASE {PHASE_NAME} COMPLETADA\")\n",
    "        \n",
    "        # Guardar marcador de completado\n",
    "        with open(final_marker, 'w') as f:\n",
    "            f.write(f\"Completed at {datetime.now()}\")\n",
    "            \n",
    "        # Sync final\n",
    "        sync_checkpoint_to_drive(str(LOCAL_PHASE_DIR / \"best_model.pth\"), PHASE_CHECKPOINT_DIR)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nüõë Entrenamiento interrumpido.\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error en fase {PHASE_NAME}: {e}\")\n",
    "        raise e\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üèÅ ENTRENAMIENTO FINALIZADO\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainers.qc_trainer_v4 import QC_Trainer_v4\n",
    "from src.model_loader import instantiate_model, load_weights, load_checkpoint_data\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "import json\n",
    "\n",
    "# Inicializar monitor de recursos\n",
    "monitor = ResourceMonitor(max_training_hours=exp_cfg.MAX_TRAINING_HOURS)\n",
    "\n",
    "# Instanciar modelo\n",
    "model = instantiate_model(exp_cfg)\n",
    "\n",
    "# Cargar pesos si hay checkpoint\n",
    "if checkpoint_path:\n",
    "    ckpt_data = load_checkpoint_data(checkpoint_path)\n",
    "    if ckpt_data:\n",
    "        load_weights(model, ckpt_data)\n",
    "\n",
    "# Inicializar trainer\n",
    "trainer = QC_Trainer_v4(\n",
    "    experiment_name=exp_cfg.EXPERIMENT_NAME,\n",
    "    model=model,\n",
    "        model_params=phase_cfg['MODEL_PARAMS'], # Fix: Pass model params\n",
    "    device=device,\n",
    "    lr=exp_cfg.LR_RATE_M,\n",
    "    grid_size=exp_cfg.GRID_SIZE_TRAINING,\n",
    "    qca_steps=exp_cfg.QCA_STEPS_TRAINING,\n",
    "    gamma_decay=exp_cfg.GAMMA_DECAY,\n",
    "    max_checkpoints_to_keep=exp_cfg.MAX_CHECKPOINTS_TO_KEEP\n",
    ")\n",
    "\n",
    "# Tracking de m√©tricas\n",
    "training_log = {\n",
    "    \"experiment_name\": exp_cfg.EXPERIMENT_NAME,\n",
    "    \"config\": EXPERIMENT_CONFIG,\n",
    "    \"episodes\": [],\n",
    "    \"losses\": [],\n",
    "    \"metrics\": [],\n",
    "    \"checkpoints_saved\": []\n",
    "}\n",
    "\n",
    "# Funci√≥n auxiliar para guardar en Drive\n",
    "def sync_checkpoint_to_drive(local_path, episode_num):\n",
    "    \"\"\"Copia checkpoint local a Drive\"\"\"\n",
    "    try:\n",
    "        import shutil\n",
    "        filename = Path(local_path).name\n",
    "        drive_path = EXPERIMENT_CHECKPOINT_DIR / filename\n",
    "        shutil.copy2(local_path, drive_path)\n",
    "        logger.info(f\"üíæ Checkpoint sincronizado a Drive: {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error sincronizando a Drive: {e}\")\n",
    "        return False\n",
    "\n",
    "# ENTRENAMIENTO PROGRESIVO\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ INICIANDO ENTRENAMIENTO PROGRESIVO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    for episode in range(resume_from_episode, exp_cfg.TOTAL_EPISODES):\n",
    "        \n",
    "        # Verificar l√≠mite de tiempo ANTES de empezar episodio\n",
    "        if monitor.should_stop():\n",
    "            print(\"\\n‚è∞ ¬°L√çMITE DE TIEMPO ALCANZADO!\")\n",
    "            print(\"üíæ Guardando checkpoint de emergencia...\")\n",
    "            \n",
    "            # Guardar checkpoint de emergencia\n",
    "            trainer.save_checkpoint(episode, is_best=False)\n",
    "            \n",
    "            # Sincronizar a Drive\n",
    "            last_checkpoint = LOCAL_CHECKPOINT_DIR / \"last_model.pth\"\n",
    "            if last_checkpoint.exists():\n",
    "                sync_checkpoint_to_drive(str(last_checkpoint), episode)\n",
    "            \n",
    "            print(f\"‚úÖ Entrenamiento detenido en episodio {episode}\")\n",
    "            print(f\"üìä Progreso: {episode}/{exp_cfg.TOTAL_EPISODES} episodios ({episode/exp_cfg.TOTAL_EPISODES*100:.1f}%)\")\n",
    "            break\n",
    "        \n",
    "        # Entrenar episodio\n",
    "        loss, metrics = trainer.train_episode(episode)\n",
    "        \n",
    "        # Registrar m√©tricas\n",
    "        training_log[\"episodes\"].append(episode)\n",
    "        training_log[\"losses\"].append(epoch_result.get(\"loss_total\", 0))\n",
    "        training_log[\"metrics\"].append(epoch_result)\n",
    "        \n",
    "        # Guardar checkpoint peri√≥dicamente\n",
    "        if (episode + 1) % exp_cfg.SAVE_EVERY_EPISODES == 0:\n",
    "            is_best = (episode + 1) % (exp_cfg.SAVE_EVERY_EPISODES * 5) == 0  # Cada 50 eps = best candidate\n",
    "            trainer.save_checkpoint(episode, is_best=is_best)\n",
    "            training_log[\"checkpoints_saved\"].append(episode)\n",
    "        \n",
    "        # Sincronizar a Drive peri√≥dicamente\n",
    "        if (episode + 1) % exp_cfg.DRIVE_SYNC_EVERY == 0:\n",
    "            print(f\"\\nüíæ Sincronizando checkpoint a Drive (episodio {episode})...\")\n",
    "            last_checkpoint = LOCAL_CHECKPOINT_DIR / \"last_model.pth\"\n",
    "            if last_checkpoint.exists():\n",
    "                sync_checkpoint_to_drive(str(last_checkpoint), episode)\n",
    "            \n",
    "            # Tambi√©n sincronizar mejores modelos\n",
    "            best_checkpoint = LOCAL_CHECKPOINT_DIR / \"best_model.pth\"\n",
    "            if best_checkpoint.exists():\n",
    "                sync_checkpoint_to_drive(str(best_checkpoint), episode)\n",
    "        \n",
    "        # Visualizaci√≥n cada 10 episodios\n",
    "        if (episode + 1) % 10 == 0:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            print(\"=\" * 70)\n",
    "            print(f\"üìà PROGRESO: Episodio {episode + 1}/{exp_cfg.TOTAL_EPISODES} ({(episode+1)/exp_cfg.TOTAL_EPISODES*100:.1f}%)\")\n",
    "            print(\"=\" * 70)\n",
    "            \n",
    "            # Mostrar recursos\n",
    "            print(monitor.get_status_str())\n",
    "            \n",
    "            # Mostrar √∫ltimas m√©tricas\n",
    "            if len(training_log[\"losses\"]) > 0:\n",
    "                recent_losses = training_log[\"losses\"][-10:]\n",
    "                avg_loss = sum(recent_losses) / len(recent_losses)\n",
    "                print(f\"\\nüìä M√âTRICAS (√∫ltimos 10 episodios):\")\n",
    "                print(f\"  Loss promedio: {avg_loss:.4f}\")\n",
    "                print(f\"  Loss actual: {training_log['losses'][-1]:.4f}\")\n",
    "            \n",
    "            # Gr√°fico de p√©rdida\n",
    "            if len(training_log[\"episodes\"]) > 1:\n",
    "                plt.figure(figsize=(10, 4))\n",
    "                plt.plot(training_log[\"episodes\"], training_log[\"losses\"], 'b-', alpha=0.6)\n",
    "                plt.xlabel('Episodio')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.title(f'{exp_cfg.EXPERIMENT_NAME} - Progreso de Entrenamiento')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úÖ ENTRENAMIENTO COMPLETADO EXITOSAMENTE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è Entrenamiento interrumpido por usuario\")\n",
    "    print(\"üíæ Guardando checkpoint...\")\n",
    "    trainer.save_checkpoint(episode, is_best=False)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERROR DURANTE ENTRENAMIENTO: {e}\")\n",
    "    logger.error(f\"Error: {e}\", exc_info=True)\n",
    "    print(\"üíæ Guardando checkpoint de emergencia...\")\n",
    "    try:\n",
    "        trainer.save_checkpoint(episode, is_best=False)\n",
    "    except:\n",
    "        pass\n",
    "    raise\n",
    "\n",
    "finally:\n",
    "    # Guardar log de entrenamiento en Drive\n",
    "    log_file = EXPERIMENT_LOG_DIR / f\"training_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    with open(log_file, 'w') as f:\n",
    "        json.dump(training_log, f, indent=2)\n",
    "    print(f\"\\nüìÑ Log guardado en: {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Secci√≥n 8: Visualizaci√≥n de Resultados Finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if len(training_log[\"episodes\"]) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. P√©rdida total\n",
    "    axes[0, 0].plot(training_log[\"episodes\"], training_log[\"losses\"], 'b-', alpha=0.6, label='Loss')\n",
    "    axes[0, 0].set_xlabel('Episodio')\n",
    "    axes[0, 0].set_ylabel('Loss Total')\n",
    "    axes[0, 0].set_title('Evoluci√≥n de la P√©rdida')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # 2. M√©tricas individuales (si est√°n disponibles)\n",
    "    if len(training_log[\"metrics\"]) > 0 and \"survival_rate\" in training_log[\"metrics\"][0]:\n",
    "        survival_rates = [m.get(\"survival_rate\", 0) for m in training_log[\"metrics\"]]\n",
    "        axes[0, 1].plot(training_log[\"episodes\"], survival_rates, 'g-', alpha=0.6, label='Survival Rate')\n",
    "        axes[0, 1].set_xlabel('Episodio')\n",
    "        axes[0, 1].set_ylabel('Survival Rate')\n",
    "        axes[0, 1].set_title('Tasa de Supervivencia')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        axes[0, 1].legend()\n",
    "    \n",
    "    # 3. Checkpoints guardados\n",
    "    axes[1, 0].scatter(training_log[\"checkpoints_saved\"], \n",
    "                      [1] * len(training_log[\"checkpoints_saved\"]), \n",
    "                      c='red', marker='|', s=100, label='Checkpoint')\n",
    "    axes[1, 0].set_xlabel('Episodio')\n",
    "    axes[1, 0].set_yticks([])\n",
    "    axes[1, 0].set_title('Checkpoints Guardados')\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # 4. Histograma de p√©rdidas\n",
    "    axes[1, 1].hist(training_log[\"losses\"], bins=30, alpha=0.7, color='purple', edgecolor='black')\n",
    "    axes[1, 1].set_xlabel('Loss')\n",
    "    axes[1, 1].set_ylabel('Frecuencia')\n",
    "    axes[1, 1].set_title('Distribuci√≥n de P√©rdidas')\n",
    "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(EXPERIMENT_LOG_DIR / 'training_summary.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüìä Gr√°ficos guardados en: {EXPERIMENT_LOG_DIR / 'training_summary.png'}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay datos de entrenamiento para visualizar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üì¶ Secci√≥n 9: Exportaci√≥n y Finalizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_loader import load_model\n",
    "import shutil\n",
    "from types import SimpleNamespace\n",
    "\n",
    "print(\"üì§ Exportando modelo final de la √öLTIMA FASE...\\n\")\n",
    "\n",
    "# Obtener configuraci√≥n de la √∫ltima fase\n",
    "last_phase = TRAINING_PHASES[-1]\n",
    "last_phase_name = last_phase[\"PHASE_NAME\"]\n",
    "print(f\"üîπ √öltima fase: {last_phase_name}\")\n",
    "\n",
    "# Directorios de la √∫ltima fase\n",
    "LAST_PHASE_CHECKPOINT_DIR = BASE_CHECKPOINT_DIR / last_phase_name\n",
    "LAST_PHASE_LOG_DIR = BASE_LOG_DIR / last_phase_name\n",
    "\n",
    "# Encontrar mejor checkpoint de la √∫ltima fase\n",
    "best_checkpoint = LAST_PHASE_CHECKPOINT_DIR / \"best_model.pth\"\n",
    "if not best_checkpoint.exists():\n",
    "    best_checkpoint = find_latest_checkpoint(LAST_PHASE_CHECKPOINT_DIR)\n",
    "\n",
    "if best_checkpoint:\n",
    "    print(f\"üì• Cargando modelo desde: {Path(best_checkpoint).name}\")\n",
    "    \n",
    "    # Preparar config para cargar modelo\n",
    "    # Necesitamos reconstruir el objeto config esperado por load_model\n",
    "    export_cfg = SimpleNamespace(**last_phase)\n",
    "    export_cfg.MODEL_PARAMS = SimpleNamespace(**last_phase[\"MODEL_PARAMS\"])\n",
    "    export_cfg.DEVICE = device\n",
    "    export_cfg.EXPERIMENT_NAME = f\"{EXPERIMENT_ROOT_NAME}_{last_phase_name}\"\n",
    "    \n",
    "    # Cargar modelo\n",
    "    model = load_model(export_cfg, str(best_checkpoint))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Exportar a TorchScript\n",
    "    # Usamos dimensiones de la √∫ltima fase\n",
    "    d_state = last_phase[\"MODEL_PARAMS\"][\"d_state\"]\n",
    "    grid_size = last_phase[\"GRID_SIZE_TRAINING\"]\n",
    "    \n",
    "    example_input = torch.randn(1, 2 * d_state, grid_size, grid_size, device=device)\n",
    "    \n",
    "    torchscript_path = DRIVE_EXPORTS_DIR / f\"{EXPERIMENT_ROOT_NAME}_{last_phase_name}_model.pt\"\n",
    "    \n",
    "    try:\n",
    "        traced_model = torch.jit.trace(model, example_input, strict=False)\n",
    "        traced_model.save(str(torchscript_path))\n",
    "        print(f\"‚úÖ Modelo TorchScript exportado: {torchscript_path.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error exportando TorchScript: {e}\")\n",
    "    \n",
    "    # Copiar mejor checkpoint a Drive (Exports)\n",
    "    export_checkpoint_path = DRIVE_EXPORTS_DIR / f\"{EXPERIMENT_ROOT_NAME}_{last_phase_name}_best.pth\"\n",
    "    shutil.copy2(best_checkpoint, export_checkpoint_path)\n",
    "    print(f\"‚úÖ Mejor checkpoint exportado: {export_checkpoint_path.name}\")\n",
    "    \n",
    "    # Generar reporte de entrenamiento\n",
    "    report_path = DRIVE_EXPORTS_DIR / f\"{EXPERIMENT_ROOT_NAME}_REPORT.md\"\n",
    "    \n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(f\"# Reporte de Entrenamiento: {EXPERIMENT_ROOT_NAME}\\n\\n\")\n",
    "        f.write(f\"**Fecha:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        f.write(f\"## Fases Completadas\\n\\n\")\n",
    "        \n",
    "        for i, phase in enumerate(TRAINING_PHASES):\n",
    "             f.write(f\"### Fase {i+1}: {phase['PHASE_NAME']}\\n\")\n",
    "             f.write(f\"- Grid: {phase['GRID_SIZE_TRAINING']}x{phase['GRID_SIZE_TRAINING']}\\n\")\n",
    "             f.write(f\"- Episodes: {phase['TOTAL_EPISODES']}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"## Archivos Exportados\\n\\n\")\n",
    "        f.write(f\"- TorchScript: `{torchscript_path.name}`\\n\")\n",
    "        f.write(f\"- Checkpoint: `{export_checkpoint_path.name}`\\n\")\n",
    "    \n",
    "    print(f\"‚úÖ Reporte generado: {report_path.name}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se encontr√≥ checkpoint para exportar en la √∫ltima fase\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ EXPORTACI√ìN COMPLETADA\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüìÇ Todos los archivos est√°n en Drive: {DRIVE_EXPORTS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Notas Finales\n",
    "\n",
    "### ‚úÖ Checklist de Verificaci√≥n\n",
    "\n",
    "- ‚úì Checkpoints guardados en Drive cada 50 episodios\n",
    "- ‚úì Logs de entrenamiento persistidos\n",
    "- ‚úì Modelo final exportado a TorchScript\n",
    "- ‚úì Reporte de entrenamiento generado\n",
    "- ‚úì Auto-recuperaci√≥n configurada para pr√≥xima sesi√≥n\n",
    "\n",
    "### üîÑ Para Continuar Entrenamiento\n",
    "\n",
    "1. Ejecutar este notebook de nuevo\n",
    "2. Mantener `AUTO_RESUME = True`\n",
    "3. Ajustar `TOTAL_EPISODES` si quieres m√°s episodios\n",
    "4. El notebook detectar√° autom√°ticamente el √∫ltimo checkpoint en Drive\n",
    "\n",
    "### üìä Mejores Pr√°cticas\n",
    "\n",
    "- **Colab Free**: Entrenar en sesiones de 6-8 horas\n",
    "- **Colab Pro**: Sesiones de 12-20 horas\n",
    "- **Kaggle**: Aprovechar las 30 horas semanales\n",
    "- Siempre verificar que Drive est√© sincronizando correctamente\n",
    "- Revisar gr√°ficos cada 50-100 episodios para detectar problemas\n",
    "\n",
    "---\n",
    "\n",
    "**¬°Feliz entrenamiento! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "ath_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
