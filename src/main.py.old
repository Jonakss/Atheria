# main.py
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import imageio.v2 as imageio
import time
import os
import glob
from PIL import Image
import re 
import gc 
import cv2 # Importar OpenCV

# Importar desde nuestros mÃ³dulos
import src.config as cfg
from src.qca_engine import QCA_State, QCA_Operator_Deep, Aetheria_Motor
from src.visualization import (
    downscale_frame, get_density_frame_gpu, get_channel_frame_gpu,
    get_state_magnitude_frame_gpu, get_state_phase_frame_gpu,
    get_state_change_magnitude_frame_gpu
)
from src.utils import load_qca_state, save_qca_state
from src.trainer import QC_Trainer_v3

# ConfiguraciÃ³n inicial del dispositivo y directorios (se ejecuta al importar config.py)
print(f"Usando dispositivo: {cfg.DEVICE}")
print(f"Directorio de Checkpoints de Entrenamiento: {cfg.CHECKPOINT_DIR}")
print(f"Directorio de Checkpoints de SimulaciÃ³n Grande: {cfg.LARGE_SIM_CHECKPOINT_DIR}")

# ==============================================================================
# PHASES 5, 6 & 7: MAIN EXECUTION PIPELINE
# ==============================================================================
def main_pipeline():
    """
    FunciÃ³n principal para ejecutar el pipeline de AETHERIA basado en flags de config.py.
    """
    print("--- INICIANDO EJECUCIÃ“N DEL PIPELINE AETHERIA ---")

    Aetheria_Motor_Train = None
    M_FILENAME = None
    trainer = None
    model_id = "Deep_v3" 

    # --------------------------------------------------------------------------
    # FASE 5: LÃ“GICA PRINCIPAL DE ENTRENAMIENTO
    # --------------------------------------------------------------------------
    if cfg.RUN_TRAINING:
        print("\n" + "="*60)
        print(">>> INICIANDO FASE DE ENTRENAMIENTO (FASE 5) <<<")
        print("="*60)
        
        model_M = QCA_Operator_Deep(cfg.D_STATE, cfg.HIDDEN_CHANNELS)
        Aetheria_Motor_Train = Aetheria_Motor(cfg.GRID_SIZE_TRAINING, cfg.D_STATE, model_M)
        print(f"Motor y Ley-M ({model_id}) inicializados. CuadrÃ­cula de entrenamiento: {cfg.GRID_SIZE_TRAINING}x{cfg.GRID_SIZE_TRAINING}.")

        trainable_params = sum(p.numel() for p in (Aetheria_Motor_Train.operator.module.parameters()
                                                     if isinstance(Aetheria_Motor_Train.operator, nn.DataParallel)
                                                     else Aetheria_Motor_Train.operator.parameters()) if p.requires_grad)
        print(f"ParÃ¡metros Entrenables: {trainable_params}")

        trainer = QC_Trainer_v3(Aetheria_Motor_Train, cfg.LR_RATE_M)

        if cfg.CONTINUE_TRAINING:
            print("Intentando continuar entrenamiento...")
            trainer._load_checkpoint()
        else:
            print("Iniciando nuevo entrenamiento desde cero.")

        print(f"\n--- Entrenamiento (PEF v3 - ParÃ¡metros Optimizados + ReactivaciÃ³n + Nuevas Recompensas) ---")
        print(f"Iniciando desde episodio {trainer.current_episode}. Entrenando por {cfg.EPISODES_TO_ADD} episodios mÃ¡s.")
        # ... (puedes aÃ±adir mÃ¡s print statements de config si lo deseas) ...

        start_time = time.time()
        final_episode = trainer.current_episode + cfg.EPISODES_TO_ADD

        try:
            for episode in range(trainer.current_episode, final_episode):
                avg_loss = trainer.train_episode(final_episode)

                if np.isnan(avg_loss) or np.isinf(avg_loss):
                    print(f"âš ï¸  Episodio {episode:04}: Entrenamiento fallido (NaN/Inf en loss). Procediendo a verificaciÃ³n de estancamiento.")
                
                if episode % 10 == 0 or episode == final_episode - 1 or episode == trainer.current_episode - 1:
                    # ... (lÃ³gica de impresiÃ³n de progreso) ...
                    alpha, gamma = trainer._calculate_annealed_alpha_gamma(final_episode)
                    print(f"Eps {episode:04}: Loss={avg_loss:.3e} | ... | Î±={alpha:.2f}, Î³={gamma:.2f}, LR={trainer.optimizer.param_groups[0]['lr']:.2e}")


                if episode % cfg.SAVE_EVERY_EPISODES == 0 and episode > (trainer.current_episode - cfg.EPISODES_TO_ADD): 
                    trainer._save_checkpoint(episode)
                    if not np.isnan(avg_loss) and not np.isinf(avg_loss) and avg_loss < trainer.best_loss:
                        trainer._save_checkpoint(episode, is_best=True)
                        print(f"ðŸ† Nuevo mejor modelo guardado en episodio {episode}")

                if trainer.check_stagnation_and_reactivate(final_episode):
                    print("Entrenamiento detenido por estancamiento sin reactivaciones restantes.")
                    break

        except KeyboardInterrupt:
            print("\nEntrenamiento interrumpido por el usuario. Guardando checkpoint...")
            if trainer: trainer._save_checkpoint(trainer.current_episode)
        except Exception as e:
            print(f"\nâŒ Error crÃ­tico durante el entrenamiento en episodio {trainer.current_episode if trainer else 'N/A'}: {e}")
            if trainer: trainer._save_checkpoint(trainer.current_episode)
            raise e 

        end_time = time.time()
        print(f"\nEntrenamiento completado en {end_time - start_time:.2f} segundos.")
        if trainer: print(f"Episodio final alcanzado: {trainer.current_episode}")

        # --- GUARDAR MODELO FINAL (Ley M) ---
        print("\n--- GUARDANDO LEY FUNDAMENTAL FINAL (M) ---")
        TIMESTAMP = int(time.time())
        if trainer:
            M_FILENAME = f"{cfg.CHECKPOINT_DIR}/PEF_{model_id}_G{cfg.GRID_SIZE_TRAINING}_Eps{trainer.current_episode}_{TIMESTAMP}_FINAL.pth"
            try:
                if isinstance(trainer.motor.operator, nn.DataParallel):
                    model_state_dict_to_save = trainer.motor.operator.module.state_dict()
                else:
                    model_state_dict_to_save = trainer.motor.operator.state_dict()
                torch.save(model_state_dict_to_save, M_FILENAME)
                print(f"âœ… Ley Fundamental Final (M) guardada: {M_FILENAME}")
            except Exception as e:
                print(f"âŒ Error guardando modelo final: {e}")

    else:
        print("\n>>> FASE DE ENTRENAMIENTO (FASE 5) OMITIDA <<<")
        if cfg.RUN_POST_TRAINING_VIZ or cfg.RUN_LARGE_SIM:
            # ... (LÃ³gica para cargar el modelo si el entrenamiento se omite) ...
            print("Inicializando motor de tamaÃ±o de entrenamiento para cargar modelo...")
            model_M = QCA_Operator_Deep(cfg.D_STATE, cfg.HIDDEN_CHANNELS)
            Aetheria_Motor_Train = Aetheria_Motor(cfg.GRID_SIZE_TRAINING, cfg.D_STATE, model_M)
            
            model_files = glob.glob(f"{cfg.CHECKPOINT_DIR}/PEF_Deep_v3_G{cfg.GRID_SIZE_TRAINING}_Eps*_FINAL.pth")
            M_FILENAME = max(model_files, key=os.path.getctime, default=None) if model_files else None

            if M_FILENAME and os.path.exists(M_FILENAME):
                print(f"ðŸ“¦ Detectado Ãºltimo archivo .pth: {M_FILENAME}. Intentando cargar pesos...")
                try:
                    model_state_dict = torch.load(M_FILENAME, map_location=cfg.DEVICE)
                    # ... (LÃ³gica de carga para DataParallel) ...
                    Aetheria_Motor_Train.operator.load_state_dict(model_state_dict) # Simplificado, aÃ±ade tu lÃ³gica de DP
                    Aetheria_Motor_Train.operator.eval()
                    print(f"âœ… Pesos del modelo cargados exitosamente en Aetheria_Motor_Train.")
                except Exception as e:
                    print(f"âŒ Error cargando pesos del modelo '{M_FILENAME}': {e}")
            else:
                print(f"âŒ No se encontraron archivos .pth en '{cfg.CHECKPOINT_DIR}'.")

    # --------------------------------------------------------------------------
    # FASE 6: VISUALIZACIÃ“N POST-ENTRENAMIENTO (TamaÃ±o de Entrenamiento)
    # --------------------------------------------------------------------------
    if cfg.RUN_POST_TRAINING_VIZ:
        print("\n" + "="*60)
        print(">>> INICIANDO FASE DE VISUALIZACIÃ“N POST-ENTRENAMIENTO (FASE 6) <<<")
        print("="*60)

        if Aetheria_Motor_Train is not None: 
            # ... (Toda tu lÃ³gica para generar y guardar videos de visualizaciÃ³n) ...
            print(f"Generando {cfg.NUM_FRAMES_VIZ} frames en cuadrÃ­cula {cfg.GRID_SIZE_TRAINING}x{cfg.GRID_SIZE_TRAINING}...")
            # ... (cÃ³digo de bucle for t in range(NUM_FRAMES_VIZ_TRAINING)) ...
            print("âœ… Captura de frames de visualizaciÃ³n completada.")
            # ... (cÃ³digo de guardado de imageio.mimsave) ...
        else:
            print("âš ï¸ Aetheria_Motor_Train no fue inicializado. Omitiendo visualizaciÃ³n post-entrenamiento.")

        print("\n>>> FASE DE VISUALIZACIÃ“N POST-ENTRENAMIENTO (FASE 6) COMPLETADA <<<")

    else:
        print("\n>>> FASE DE VISUALIZACIÃ“N POST-ENTRENAMIENTO (FASE 6) OMITIDA <<<")


    # --------------------------------------------------------------------------
    # FASE 7: LÃ“GICA PRINCIPAL DE SIMULACIÃ“N GRANDE PROLONGADA
    # --------------------------------------------------------------------------
    if cfg.RUN_LARGE_SIM:
        print("\n" + "="*60)
        print(">>> INICIANDO FASE DE SIMULACIÃ“N GRANDE PROLONGADA (FASE 7) <<<")
        print("="*60)

        operator_model_inference = QCA_Operator_Deep(
            d_state=cfg.D_STATE,
            hidden_channels=cfg.HIDDEN_CHANNELS
        )
        large_scale_motor = Aetheria_Motor(cfg.GRID_SIZE_INFERENCE, cfg.D_STATE, operator_model_inference)

        # --- Cargar Pesos del Modelo Entrenado ---
        if not M_FILENAME: # Buscar si no se cargÃ³ o entrenÃ³
            model_files = glob.glob(f"{cfg.CHECKPOINT_DIR}/PEF_Deep_v3_G{cfg.GRID_SIZE_TRAINING}_Eps*_FINAL.pth")
            M_FILENAME = max(model_files, key=os.path.getctime, default=None) if model_files else None

        if M_FILENAME and os.path.exists(M_FILENAME):
            print(f"ðŸ“¦ Cargando pesos desde: {M_FILENAME}")
            try:
                model_state_dict = torch.load(M_FILENAME, map_location=cfg.DEVICE)
                # ... (LÃ³gica de carga para DataParallel, igual que antes) ...
                large_scale_motor.operator.load_state_dict(model_state_dict) # Simplificado
                large_scale_motor.operator.eval()
                print(f"âœ… Pesos del modelo cargados exitosamente.")
            except Exception as e:
                print(f"âŒ Error cargando pesos del modelo '{M_FILENAME}': {e}")
        else:
            print(f"âŒ No se encontrÃ³ archivo de modelo entrenado. La simulaciÃ³n se ejecutarÃ¡ con pesos aleatorios.")

        # --- Cargar estado desde checkpoint o empezar de cero ---
        start_step = 0
        if cfg.LOAD_STATE_CHECKPOINT_INFERENCE:
            # ... (Tu lÃ³gica para encontrar latest_checkpoint_filepath) ...
            latest_checkpoint_filepath = None # Placeholder
            if latest_checkpoint_filepath and os.path.exists(latest_checkpoint_filepath):
                loaded_step = load_qca_state(large_scale_motor, latest_checkpoint_filepath)
                if loaded_step != -1:
                    start_step = loaded_step
                    print(f"SimulaciÃ³n reanudada desde el paso {start_step}.")
        
        if start_step == 0:
            print(f"\nIniciando nueva simulaciÃ³n con modo: '{cfg.INITIAL_STATE_MODE_INFERENCE}'.")
            if cfg.INITIAL_STATE_MODE_INFERENCE == 'random':
                large_scale_motor.state._reset_state_random()
            # ... (otros modos de reseteo) ...
            elif cfg.INITIAL_STATE_MODE_INFERENCE == 'complex_noise':
                large_scale_motor.state._reset_state_complex_noise()

        # --- Bucle Principal de SimulaciÃ³n Grande ---
        
        # ... (Tu lÃ³gica de configuraciÃ³n de video writer) ...
        writer_density = None # Placeholder
        
        prev_state_for_change_viz = None
        # ... (Tu lÃ³gica para cargar prev_state_for_change_viz) ...

        t = start_step
        try:
            with torch.no_grad():
                for t in range(start_step, cfg.NUM_INFERENCE_STEPS):
                    
                    current_state_clone_for_change_viz = None
                    if prev_state_for_change_viz is not None:
                        # ... (lÃ³gica de clonaciÃ³n de estado) ...
                        pass

                    large_scale_motor.evolve_step()
                    current_state = large_scale_motor.state

                    if torch.isnan(current_state.x_real).any() or torch.isinf(current_state.x_real).any():
                        print(f"\nâŒ NaN/Inf detectado en el estado de simulaciÃ³n en el paso {t+1}. Deteniendo.")
                        break

                    # -------------------------------------------------
                    # --- VISUALIZACIÃ“N EN TIEMPO REAL (CON CV2) ---
                    # -------------------------------------------------
                    if cfg.REAL_TIME_VIZ_INTERVAL is not None and cfg.REAL_TIME_VIZ_INTERVAL > 0 and (t + 1) % cfg.REAL_TIME_VIZ_INTERVAL == 0:
                        try:
                            frame_to_display = None
                            if cfg.REAL_TIME_VIZ_TYPE == 'density':
                                frame_to_display = get_density_frame_gpu(current_state)
                            elif cfg.REAL_TIME_VIZ_TYPE == 'channels':
                                frame_to_display = get_channel_frame_gpu(current_state, num_channels=min(3, cfg.D_STATE))
                            elif cfg.REAL_TIME_VIZ_TYPE == 'magnitude':
                                frame_to_display = get_state_magnitude_frame_gpu(current_state)
                            elif cfg.REAL_TIME_VIZ_TYPE == 'phase':
                                frame_to_display = get_state_phase_frame_gpu(current_state)
                            elif cfg.REAL_TIME_VIZ_TYPE == 'change':
                                if prev_state_for_change_viz is not None:
                                    frame_to_display = get_state_change_magnitude_frame_gpu(current_state, prev_state_for_change_viz)
                            
                            if frame_to_display is not None:
                                if cfg.REAL_TIME_VIZ_DOWNSCALE > 1:
                                    frame_to_display = downscale_frame(frame_to_display, cfg.REAL_TIME_VIZ_DOWNSCALE)
                                
                                # Convertir frame de RGB a BGR para OpenCV
                                frame_bgr = cv2.cvtColor(frame_to_display, cv2.COLOR_RGB2BGR)
                                
                                # Mostrar el frame en una ventana
                                cv2.imshow("Aetheria Real-Time Visualization", frame_bgr)
                                
                                # Esperar 1ms y registrar si se presiona 'q'
                                if cv2.waitKey(1) & 0xFF == ord('q'):
                                    print("VisualizaciÃ³n en tiempo real detenida por el usuario (presionÃ³ 'q').")
                                    raise KeyboardInterrupt("Ventana de visualizaciÃ³n cerrada con 'q'.")
                            
                        except Exception as e:
                             print(f"âš ï¸  Error generando/mostrando frame en tiempo real en paso {t+1}: {e}")

                    # --- Guardado de Frame de Video ---
                    if cfg.VIDEO_SAVE_INTERVAL_STEPS is not None and cfg.VIDEO_SAVE_INTERVAL_STEPS > 0 and ((t + 1) % cfg.VIDEO_SAVE_INTERVAL_STEPS == 0 or (t == start_step)):
                        # ... (Tu lÃ³gica de guardado de video) ...
                        pass

                    if current_state_clone_for_change_viz is not None:
                        prev_state_for_change_viz = current_state_clone_for_change_viz

                    # --- Guardado de Checkpoint de Estado ---
                    if cfg.LARGE_SIM_CHECKPOINT_INTERVAL is not None and cfg.LARGE_SIM_CHECKPOINT_INTERVAL > 0 and (t + 1) % cfg.LARGE_SIM_CHECKPOINT_INTERVAL == 0:
                        save_qca_state(large_scale_motor, t + 1, cfg.LARGE_SIM_CHECKPOINT_DIR)

                    # --- ImpresiÃ³n de Progreso ---
                    if (t + 1) % max(1, (cfg.NUM_INFERENCE_STEPS // 20)) == 0 or (t + 1) == cfg.NUM_INFERENCE_STEPS:
                        print(f"ðŸ“ˆ Progreso de SimulaciÃ³n: {t+1}/{cfg.NUM_INFERENCE_STEPS} pasos completados.")

                    # ... (lÃ³gica de gc.collect()) ...
                
                print("âœ… Bucle de simulaciÃ³n completado.")

        except KeyboardInterrupt:
            print(f"\nâ¹ï¸ SimulaciÃ³n interrumpida por el usuario en el paso {t+1}.")
            if cfg.LARGE_SIM_CHECKPOINT_INTERVAL is not None and cfg.LARGE_SIM_CHECKPOINT_INTERVAL > 0:
                save_qca_state(large_scale_motor, t + 1, cfg.LARGE_SIM_CHECKPOINT_DIR)
        except Exception as e:
            print(f"\nâŒ Error durante la simulaciÃ³n en el paso {t+1}: {e}")
            if cfg.LARGE_SIM_CHECKPOINT_INTERVAL is not None and cfg.LARGE_SIM_CHECKPOINT_INTERVAL > 0:
                save_qca_state(large_scale_motor, t + 1, cfg.LARGE_SIM_CHECKPOINT_DIR)
            raise e
        finally:
            # ... (Tu lÃ³gica para cerrar video writers) ...
            if writer_density: writer_density.close()
            
            # **CERRAR LA VENTANA DE CV2**
            cv2.destroyAllWindows()
            print("ðŸ“¹ Escritores de video y ventana de visualizaciÃ³n cerrados.")

        # --- Resumen Final ---
        print("\n" + "="*60)
        print("ðŸŽ‰ SIMULACIÃ“N GRANDE PROLONGADA FINALIZADA")
        print("="*60)
        # ... (Tu lÃ³gica de impresiÃ³n de resumen) ...

    else:
        print("\n>>> FASE DE SIMULACIÃ“N GRANDE PROLONGADA (FASE 7) OMITIDA <<<")

    print("\n--- EJECUCIÃ“N DEL PIPELINE AETHERIA FINALIZADA ---")


# ==============================================================================
# PUNTO DE ENTRADA DEL SCRIPT
# ==============================================================================
if __name__ == "__main__":
    main_pipeline()