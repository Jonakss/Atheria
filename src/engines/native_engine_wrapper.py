"""
Wrapper para integrar el motor nativo de C++ (atheria_core.Engine) con el frontend.

Este wrapper proporciona una interfaz compatible con Aetheria_Motor para que
el motor nativo de alto rendimiento pueda usarse como reemplazo directo.
"""

import torch
import torch.nn as nn
import logging
import numpy as np
from typing import Optional
from pathlib import Path
import sys

# Versi√≥n del wrapper
try:
    from .__version__ import __version__ as ENGINE_VERSION
except ImportError:
    ENGINE_VERSION = "4.1.0"  # Fallback

# Intentar importar el m√≥dulo nativo con manejo robusto de errores CUDA
NATIVE_AVAILABLE = False
_native_import_error = None
_native_cuda_issue = (
    False  # Flag para indicar que hay problema de CUDA pero el m√≥dulo existe
)

try:
    # Intentar importar el m√≥dulo nativo
    import atheria_core

    NATIVE_AVAILABLE = True
    logging.info("‚úÖ M√≥dulo nativo atheria_core importado exitosamente")
except (ImportError, OSError, RuntimeError) as e:
    error_str = str(e)
    _native_import_error = error_str

    # Detectar problemas espec√≠ficos de CUDA runtime
    cuda_runtime_keywords = [
        "__nvJitLinkCreate",
        "libnvJitLink",
        "libcusparse.so",
        "undefined symbol",
    ]

    if any(keyword in error_str for keyword in cuda_runtime_keywords):
        # Problema de CUDA runtime - el m√≥dulo est√° compilado pero tiene problemas de CUDA
        _native_cuda_issue = True
        logging.warning(
            f"‚ö†Ô∏è Problema de CUDA runtime detectado al importar atheria_core: {error_str[:100]}"
        )
        logging.info(
            "üí° El motor nativo solo funcionar√° en modo CPU. Usa device='cpu' al inicializar."
        )
        # No marcamos como no disponible - a√∫n puede funcionar en CPU
        # NATIVE_AVAILABLE permanece False, pero el wrapper puede intentar inicializar en CPU
    else:
        # Otro tipo de error - probablemente el m√≥dulo no est√° compilado
        logging.warning(f"atheria_core no disponible: {error_str[:100]}")
        if (
            "No module named" in error_str
            or "cannot open shared object file" in error_str
        ):
            logging.info(
                "üí° El m√≥dulo C++ no est√° compilado. Ejecuta: python setup.py build_ext --inplace"
            )
        else:
            logging.info(
                "üí° Error inesperado al importar m√≥dulo nativo. Usando motor Python como fallback."
            )
except Exception as e:
    # Error inesperado
    _native_import_error = str(e)
    logging.warning(f"Error inesperado importando atheria_core: {e}")
    logging.info(
        "El motor nativo no estar√° disponible, usando motor Python como fallback."
    )

from ..engines.qca_engine import QuantumState


def export_model_to_jit(
    model: nn.Module,
    experiment_name: str,
    example_input_shape: tuple,
    output_dir: Optional[str] = None,
) -> str:
    """
    Exporta un modelo PyTorch a formato TorchScript (JIT).

    Args:
        model: Instancia del modelo PyTorch a exportar.
        experiment_name: Nombre del experimento, usado para generar el nombre del archivo.
        example_input_shape: Shape del tensor de entrada de ejemplo (ej: (1, 8, 256, 256)).
        output_dir: Directorio de salida opcional. Si es None, usa el directorio de checkpoints.

    Returns:
        Ruta al archivo .pt exportado.
    """
    from .. import config as global_cfg
    import os

    if output_dir is None:
        output_dir = os.path.join(global_cfg.TRAINING_CHECKPOINTS_DIR, experiment_name)

    os.makedirs(output_dir, exist_ok=True)

    # Usar un timestamp para nombre de archivo √∫nico para evitar problemas de cach√©
    timestamp = int(torch.randint(0, 100000, (1,)).item())
    output_path = os.path.join(output_dir, f"model_jit_{timestamp}.pt")

    try:
        logging.info(f"üì¶ Exportando modelo a TorchScript: {output_path}")
        model.eval()
        device = next(model.parameters()).device
        example_input = torch.randn(example_input_shape, device=device)

        with torch.no_grad():
            traced_model = torch.jit.trace(model, example_input, strict=False)

        traced_model.save(output_path)
        logging.info(f"‚úÖ Modelo exportado exitosamente a: {output_path}")

        # Verificaci√≥n
        logging.info("   Verificando modelo exportado...")
        loaded_model = torch.jit.load(output_path, map_location=device)
        test_output = loaded_model(example_input)
        logging.info(f"‚úÖ Modelo verificado. Salida de prueba: {test_output.shape}")

        return output_path

    except Exception as e:
        logging.error(f"‚ùå Error al exportar modelo a JIT: {e}", exc_info=True)
        raise


class NativeEngineWrapper:
    """
    Wrapper que envuelve atheria_core.Engine para mantener compatibilidad
    con el c√≥digo existente que usa Aetheria_Motor.

    Convierte entre el formato disperso del motor nativo y el formato
    denso (grid) usado por el frontend.
    """

    # Versi√≥n del wrapper Python
    VERSION = ENGINE_VERSION

    def __init__(self, grid_size: int, d_state: int, device: str = None, cfg=None):
        """
        Inicializa el wrapper del motor nativo.

        Args:
            grid_size: Tama√±o del grid para visualizaci√≥n (debe coincidir con inference_grid_size)
            d_state: Dimensi√≥n del estado cu√°ntico
            device: Dispositivo ('cpu', 'cuda', o None para auto-detecci√≥n)
            cfg: Configuraci√≥n del experimento (opcional)
        """
        # Si device es None, usar auto-detecci√≥n desde config
        if device is None:
            from src import config as global_cfg

            device = global_cfg.get_native_device()
        # Verificar disponibilidad del m√≥dulo
        # Intentar importar el m√≥dulo si no est√° disponible pero hay problema de CUDA
        if not NATIVE_AVAILABLE and _native_cuda_issue and device == "cpu":
            logging.info("Intentando importar m√≥dulo nativo forzando CPU mode...")
            try:
                import os

                # Forzar CPU deshabilitando CUDA temporalmente
                original_cuda = os.environ.get("CUDA_VISIBLE_DEVICES", None)
                os.environ["CUDA_VISIBLE_DEVICES"] = ""
                try:
                    # Reimportar el m√≥dulo si ya se import√≥ antes
                    import sys

                    if "atheria_core" in sys.modules:
                        del sys.modules["atheria_core"]
                    import atheria_core  # Reintentar importaci√≥n

                    # Importar exitoso - no necesitamos hacer nada m√°s
                    logging.info("‚úÖ M√≥dulo nativo importado exitosamente en CPU mode")
                finally:
                    # Restaurar valor original
                    if original_cuda is not None:
                        os.environ["CUDA_VISIBLE_DEVICES"] = original_cuda
                    elif "CUDA_VISIBLE_DEVICES" in os.environ:
                        del os.environ["CUDA_VISIBLE_DEVICES"]

                # Verificar que ahora est√° disponible
                import atheria_core
            except Exception as e2:
                # A√∫n falla - no disponible
                error_msg = f"atheria_core no est√° disponible. Error original: {_native_import_error[:100] if _native_import_error else str(e2)}"
                if _native_cuda_issue:
                    error_msg += " (Problema de CUDA runtime - solo CPU mode disponible, pero tambi√©n fall√≥)"
                raise ImportError(error_msg + " Usa el motor Python como fallback.")

        # Verificar una vez m√°s despu√©s del intento - asegurar que atheria_core est√© disponible
        # Importar atheria_core para usarlo en el resto del m√©todo
        import atheria_core as atheria_core_module

        # Verificar una vez m√°s si no estaba disponible antes
        if not NATIVE_AVAILABLE:
            # Intentar verificar que funciona
            try:
                # Probar crear un Engine temporal para verificar
                test_engine = atheria_core_module.Engine(d_state=1, device="cpu")
                del test_engine
            except (ImportError, OSError, RuntimeError) as e:
                # No disponible para nada
                error_msg = "atheria_core no est√° disponible."
                if _native_import_error:
                    error_msg += f" Error: {_native_import_error[:100]}"
                elif str(e):
                    error_msg += f" Error: {str(e)[:100]}"
                if _native_cuda_issue:
                    error_msg += (
                        " (Problema de CUDA runtime - intenta usar device='cpu')"
                    )
                raise ImportError(error_msg + " Usa el motor Python como fallback.")

        # Si hay problema de CUDA runtime, verificar si se puede usar CPU mode
        if _native_cuda_issue:
            if device == "cuda":
                logging.warning(
                    "‚ö†Ô∏è Problema de CUDA runtime detectado al importar atheria_core."
                )
                logging.info("üí° Intentando usar CPU mode para motor nativo...")
                # Intentar CPU mode en lugar de fallar
                device = "cpu"
                # Asegurar que CUDA_VISIBLE_DEVICES est√© deshabilitado para evitar conflictos
                import os

                original_cuda_visible = os.environ.get("CUDA_VISIBLE_DEVICES", None)
                os.environ["CUDA_VISIBLE_DEVICES"] = ""
                try:
                    # Verificar que el motor funciona en CPU mode
                    test_engine = atheria_core_module.Engine(d_state=1, device="cpu")
                    del test_engine
                    logging.info("‚úÖ Motor nativo funciona en CPU mode")
                except Exception as e:
                    logging.error(f"‚ùå Motor nativo tambi√©n falla en CPU mode: {e}")
                    raise ImportError(
                        f"Motor nativo no disponible (ni CUDA ni CPU): {e}"
                    )
                finally:
                    # Restaurar CUDA_VISIBLE_DEVICES
                    if original_cuda_visible is not None:
                        os.environ["CUDA_VISIBLE_DEVICES"] = original_cuda_visible
                    elif "CUDA_VISIBLE_DEVICES" in os.environ:
                        del os.environ["CUDA_VISIBLE_DEVICES"]

        # Verificar que device es v√°lido antes de inicializar
        if device not in ("cpu", "cuda"):
            logging.warning(f"‚ö†Ô∏è Device '{device}' no v√°lido. Usando 'cpu'.")
            device = "cpu"

        self.grid_size = int(grid_size)
        self.d_state = int(d_state)
        self.device_str = device
        self.device = torch.device(device)
        self.cfg = cfg

        # Intentar inicializar motor nativo con manejo robusto de errores
        try:
            # Inicializar motor nativo con el tama√±o del grid
            # El grid_size se usa para construir inputs del modelo con el tama√±o correcto
            self.native_engine = atheria_core_module.Engine(
                d_state=d_state, device=device, grid_size=grid_size
            )

            # Obtener versi√≥n del motor nativo C++ despu√©s de inicializarlo
            try:
                if hasattr(atheria_core_module, "get_version"):
                    self.native_version = atheria_core_module.get_version()
                elif hasattr(atheria_core_module, "__version__"):
                    self.native_version = atheria_core_module.__version__
                else:
                    self.native_version = "unknown"
            except Exception as e:
                logging.debug(f"No se pudo obtener versi√≥n del motor nativo: {e}")
                self.native_version = "unknown"

            logging.info(
                f"‚úÖ Motor nativo C++ inicializado (device={device}, grid_size={grid_size}, version={self.native_version})"
            )
        except RuntimeError as e:
            error_str = str(e)
            if device == "cuda" and ("cuda" in error_str.lower() or "101" in error_str):
                logging.warning(f"‚ö†Ô∏è Error inicializando motor nativo en CUDA: {e}")
                logging.info("üí° Intentando fallback a CPU...")
                # Intentar CPU mode como fallback
                device = "cpu"
                self.device_str = device
                self.device = torch.device(device)
                self.native_engine = atheria_core_module.Engine(
                    d_state=d_state, device="cpu", grid_size=grid_size
                )

                # Obtener versi√≥n del motor nativo C++ despu√©s de inicializarlo
                try:
                    if hasattr(atheria_core_module, "get_version"):
                        self.native_version = atheria_core_module.get_version()
                    elif hasattr(atheria_core_module, "__version__"):
                        self.native_version = atheria_core_module.__version__
                    else:
                        self.native_version = "unknown"
                except Exception as e:
                    logging.debug(f"No se pudo obtener versi√≥n del motor nativo: {e}")
                    self.native_version = "unknown"

                logging.info(
                    f"‚úÖ Motor nativo inicializado en CPU mode (fallback desde CUDA, version={self.native_version})"
                )
            else:
                raise

        # CR√çTICO: Generar estado inicial seg√∫n INITIAL_STATE_MODE_INFERENCE (como motor Python)
        # El motor nativo usa formato disperso, pero generamos estado denso primero
        # y luego lo convertimos al formato disperso del motor nativo
        initial_mode = "complex_noise"  # Default
        if cfg is not None:
            initial_mode = getattr(cfg, "INITIAL_STATE_MODE_INFERENCE", "complex_noise")

        # Soporte para grid scaling: si training_grid_size < inference_grid_size, replicar estado
        base_state = None
        base_grid_size = None
        if cfg is not None:
            training_grid_size = getattr(cfg, "GRID_SIZE_TRAINING", None)
            if training_grid_size and training_grid_size < grid_size:
                # Crear estado base del tama√±o de entrenamiento y replicarlo
                base_state_temp = QuantumState(
                    training_grid_size, d_state, device, initial_mode=initial_mode
                )
                base_state = base_state_temp.psi
                base_grid_size = training_grid_size
                logging.info(
                    f"üîÑ Grid escalado: Creando estado base {training_grid_size}x{training_grid_size} para replicar en {grid_size}x{grid_size}"
                )

        # Estado cu√°ntico para compatibilidad (denso)
        # El motor nativo usa formato disperso, pero necesitamos denso para visualizaci√≥n
        self.state = QuantumState(
            grid_size,
            d_state,
            device,
            initial_mode=initial_mode,
            base_state=base_state,
            base_grid_size=base_grid_size,
        )

        # CR√çTICO: Convertir estado denso inicial al formato disperso del motor nativo
        # Esto genera las part√≠culas iniciales desde el estado denso (ley M respetada)
        self._initialize_native_state_from_dense(self.state.psi)

        # Configuraci√≥n
        self.grid_size = grid_size
        self.d_state = d_state
        self.cfg = cfg  # Guardar cfg para regenerar estado inicial si es necesario

        # Estado interno
        self.model_loaded = False
        self.step_count = 0

        # Para compatibilidad con c√≥digo existente
        self.operator = None  # El modelo est√° cargado en el motor nativo
        self.original_model = None
        self.optimizer = None
        self.has_memory = False
        self.is_compiled = False

        # Para visualizaciones (delta_psi)
        self.last_delta_psi = None
        self.last_psi_input = None
        self.last_delta_psi_decay = None

        # OPTIMIZACI√ìN: Lazy conversion - solo convertir cuando se necesita
        self._dense_state_stale = (
            True  # Estado denso est√° desactualizado despu√©s de evolve
        )
        self._last_conversion_roi = None  # √öltima ROI usada para conversi√≥n

        logging.info(
            f"NativeEngineWrapper inicializado (grid_size={grid_size}, d_state={d_state}, device={device}, initial_mode={initial_mode})"
        )

    def _initialize_native_state_from_dense(self, dense_psi: torch.Tensor):
        """
        Convierte estado denso inicial al formato disperso del motor nativo.

        Esto respeta INITIAL_STATE_MODE_INFERENCE y genera part√≠culas desde el estado denso,
        en lugar de agregar part√≠culas manualmente. Las part√≠culas emergen del estado inicial
        generado seg√∫n la ley M (modelo cu√°ntico).

        Args:
            dense_psi: Tensor complejo [1, H, W, d_state] con estado inicial denso
        """
        if dense_psi is None or dense_psi.numel() == 0:
            logging.warning(
                "‚ö†Ô∏è Estado denso inicial vac√≠o. No se inicializar√° motor nativo."
            )
            return

        # Obtener valores absolutos para determinar qu√© c√©lulas tienen estado significativo
        psi_abs = dense_psi.abs()
        psi_abs_sq = psi_abs.pow(2)

        # Umbral para considerar una c√©lula como "activa" (tiene part√≠cula)
        # Usar un umbral din√°mico basado en la distribuci√≥n de valores
        # CR√çTICO: complex_noise genera valores peque√±os (~0.1), necesitamos umbral m√°s permisivo
        psi_abs_sq_max = psi_abs_sq.max().item()

        # Para complex_noise, valores t√≠picos est√°n en [-1, 1] pero normalizados
        # Usar umbral m√°s permisivo: 0.01% del m√°ximo (antes 0.1%), m√≠nimo 1e-9
        # Reducido de 0.001 a 0.0001 para capturar mejor la "cola" de la distribuci√≥n
        threshold = max(psi_abs_sq_max * 0.0001, 1e-9)

        # Si todos los valores son muy peque√±os (estado vac√≠o real), usar umbral m√≠nimo
        if psi_abs_sq_max < 1e-9:
            threshold = 1e-9  # Umbral m√≠nimo para detectar cualquier actividad

        # Agregar part√≠culas solo donde hay estado significativo
        particle_count = 0
        grid_size = dense_psi.shape[1]  # H == W

        # OPTIMIZACI√ìN: Muestrear grid si es muy grande (>256x256)
        # Para grids grandes, no agregar part√≠culas en cada c√©lula (ser√≠a muy lento)
        sample_step = 1 if grid_size <= 256 else max(1, grid_size // 256)

        # Funci√≥n interna para agregar part√≠culas
        def add_particles_with_threshold(thresh):
            count = 0
            verified_count = 0
            for y in range(0, grid_size, sample_step):
                for x in range(0, grid_size, sample_step):
                    # Obtener estado en esta posici√≥n
                    cell_state = dense_psi[0, y, x, :]  # [d_state]
                    cell_density = psi_abs_sq[0, y, x, :].sum().item()

                    # Solo agregar part√≠cula si tiene densidad significativa
                    if cell_density > thresh:
                        try:
                            # CR√çTICO: Verificar que cell_state no es cero antes de agregar
                            cell_state_abs_max = cell_state.abs().max().item()
                            if cell_state_abs_max < 1e-10:
                                continue

                            coord = atheria_core.Coord3D(x, y, 0)
                            # Asegurar que el tensor est√° en el dispositivo correcto
                            if cell_state.device != self.device:
                                cell_state = cell_state.to(self.device)

                            self.native_engine.add_particle(coord, cell_state)
                            count += 1

                            # VERIFICACI√ìN INMEDIATA (muestreo): Verificar 1 de cada 100 para no impactar rendimiento
                            if count % 100 == 0 or count < 5:
                                check_state = self.native_engine.get_state_at(coord)
                                if check_state is not None:
                                    verified_count += 1
                        except Exception as e:
                            logging.warning(
                                f"‚ö†Ô∏è Error agregando part√≠cula en ({x}, {y}): {e}"
                            )

            if count > 0 and verified_count == 0 and count < 5:
                logging.warning(
                    f"‚ö†Ô∏è Se intentaron agregar {count} part√≠culas pero la verificaci√≥n inmediata fall√≥."
                )

            return count

        # Intentar agregar part√≠culas
        particle_count = add_particles_with_threshold(threshold)

        # RETRY: Si no se agregaron part√≠culas, intentar con umbral m√°s bajo
        if particle_count == 0 and psi_abs_sq_max > 1e-10:
            logging.warning(
                f"‚ö†Ô∏è No se agregaron part√≠culas con umbral {threshold:.6e}. Reintentando con umbral m√≠nimo..."
            )
            threshold = 1e-10
            particle_count = add_particles_with_threshold(threshold)

        logging.info(
            f"‚úÖ Estado inicial generado seg√∫n INITIAL_STATE_MODE_INFERENCE: {particle_count} part√≠culas activas agregadas al motor nativo (umbral={threshold:.6e})"
        )

        # CR√çTICO: Despu√©s de agregar part√≠culas, verificar que realmente se agregaron
        # y se pueden recuperar antes de continuar
        try:
            # Verificar algunas part√≠culas aleatorias que agregamos
            import random

            sample_size = min(10, particle_count)
            recovered_count = 0

            if particle_count > 0:
                # Tomar muestra de coordenadas donde agregamos part√≠culas
                sample_coords = []
                for y in range(0, grid_size, sample_step):
                    for x in range(0, grid_size, sample_step):
                        if len(sample_coords) >= sample_size:
                            break
                        cell_state = dense_psi[0, y, x, :]
                        cell_density = psi_abs_sq[0, y, x, :].sum().item()
                        if cell_density > threshold:
                            sample_coords.append((x, y))
                    if len(sample_coords) >= sample_size:
                        break

                # Verificar que estas part√≠culas se pueden recuperar
                for x, y in sample_coords[:sample_size]:
                    test_coord = atheria_core.Coord3D(x, y, 0)
                    test_state = self.native_engine.get_state_at(test_coord)
                    if test_state is not None:
                        test_abs = test_state.abs().max().item()
                        if test_abs > 1e-10:
                            recovered_count += 1
                            logging.info(
                                f"‚úÖ Part√≠cula recuperada en ({x}, {y}): max abs={test_abs:.6e}"
                            )
                        else:
                            logging.warning(
                                f"‚ö†Ô∏è Part√≠cula en ({x}, {y}) tiene valores muy peque√±os: max abs={test_abs:.6e} - probablemente vac√≠o cu√°ntico"
                            )
                    else:
                        logging.warning(
                            f"‚ö†Ô∏è No se pudo recuperar part√≠cula en ({x}, {y}): get_state_at retorn√≥ None"
                        )

                # CR√çTICO: Si ninguna part√≠cula es recuperable, hay un problema grave
                if recovered_count == 0 and particle_count > 0:
                    logging.error(
                        f"‚ùå CR√çTICO: Se agregaron {particle_count} part√≠culas pero NINGUNA es recuperable."
                    )
                    logging.error(
                        f"‚ùå Esto indica que add_particle() en C++ NO est√° almacenando correctamente en matter_map_."
                    )

                    # FALLBACK ROBUSTO: Si fall√≥ la recuperaci√≥n, intentar regenerar con m√©todo diferente
                    # En este caso, regenerate_initial_state volver√≠a aqu√≠ (recursi√≥n infinita),
                    # as√≠ que simplemente reportamos el error y permitimos que el motor Python tome el control si es necesario
                    # o intentamos el m√©todo "deprecated" add_initial_particles que usa l√≥gica m√°s simple
                    logging.warning(
                        "‚ö†Ô∏è Intentando fallback a add_initial_particles (m√©todo simple)..."
                    )
                    try:
                        self.native_engine.clear()
                        # Generar part√≠culas simples manualmente para asegurar que algo funciona
                        for _ in range(10):
                            fx = np.random.randint(0, grid_size)
                            fy = np.random.randint(0, grid_size)
                            fz = 0
                            f_state = torch.randn(
                                self.d_state, dtype=torch.complex64, device=self.device
                            )
                            f_coord = atheria_core.Coord3D(fx, fy, fz)
                            self.native_engine.add_particle(f_coord, f_state)

                        # Verificar fallback
                        f_count = self.native_engine.get_matter_count()
                        logging.info(
                            f"üìä Fallback status: {f_count} part√≠culas agregadas"
                        )
                    except Exception as fb_err:
                        logging.error(f"‚ùå Fallback tambi√©n fall√≥: {fb_err}")

            # Verificar coordenadas activas del motor nativo
            if hasattr(self.native_engine, "get_active_coords"):
                try:
                    active_coords = self.native_engine.get_active_coords()
                    if active_coords and len(active_coords) > 0:
                        logging.info(
                            f"‚úÖ Motor nativo tiene {len(active_coords)} coordenadas activas verificadas"
                        )
                    else:
                        logging.warning(
                            f"‚ö†Ô∏è Motor nativo no tiene coordenadas activas recuperables despu√©s de agregar {particle_count} part√≠culas"
                        )
                except Exception as e:
                    logging.debug(f"‚ö†Ô∏è No se pudo obtener coordenadas activas: {e}")
        except Exception as verify_error:
            logging.warning(f"‚ö†Ô∏è Error verificando part√≠culas agregadas: {verify_error}")

        # Marcar estado denso como stale para que se reconvierta cuando se necesite
        self._dense_state_stale = True

    def load_model(self, model_path: str) -> bool:
        """
        Carga un modelo TorchScript (.pt) en el motor nativo.

        Args:
            model_path: Ruta al archivo .pt de TorchScript

        Returns:
            True si se carg√≥ exitosamente
        """
        success = self.native_engine.load_model(model_path)
        self.model_loaded = success
        if success:
            logging.info(f"‚úÖ Modelo TorchScript cargado en motor nativo: {model_path}")
        else:
            # Obtener mensaje de error espec√≠fico desde C++
            error_msg = self.native_engine.get_last_error()
            if error_msg:
                logging.error(f"‚ùå Error al cargar modelo TorchScript: {model_path}")
                logging.error(f"   Detalle del error: {error_msg}")
            else:
                logging.error(
                    f"‚ùå Error al cargar modelo TorchScript: {model_path} (error desconocido)"
                )
        return success

    def evolve_internal_state(self, step=None):
        """Evoluciona el estado interno usando el motor nativo."""
        if not self.model_loaded:
            logging.warning("Modelo no cargado. No se puede evolucionar el estado.")
            return

        # Ejecutar paso nativo (todo en C++)
        particle_count = self.native_engine.step_native()
        self.step_count += 1

        # OPTIMIZACI√ìN CR√çTICA: NO convertir aqu√≠ - solo marcar como "stale"
        # La conversi√≥n se har√° solo cuando se necesite (lazy conversion)
        # Esto evita convertir 65,536 coordenadas en cada paso
        self._dense_state_stale = True

    def get_dense_state(self, roi=None, check_pause_callback=None):
        """
        Obtiene el estado denso, convirtiendo solo si es necesario.

        Args:
            roi: Region of Interest (x_min, y_min, x_max, y_max) opcional. Si se proporciona,
                 solo convierte esa regi√≥n. Si None, convierte todo el grid.
            check_pause_callback: Funci√≥n callback opcional para verificar pausa.
                                 Debe retornar True si est√° pausado.

        Returns:
            Tensor complejo con el estado denso [1, H, W, d_state]
        """
        # Convertir solo si el estado est√° desactualizado o no existe
        # O si la ROI cambi√≥ (necesitamos convertir m√°s/menos del grid)
        roi_changed = (roi is not None and roi != self._last_conversion_roi) or (
            roi is None and self._last_conversion_roi is not None
        )

        if self._dense_state_stale or self.state.psi is None or roi_changed:
            self._update_dense_state_from_sparse(
                roi=roi, check_pause_callback=check_pause_callback
            )
            self._dense_state_stale = False
            self._last_conversion_roi = roi

        return self.state.psi

    def _update_dense_state_from_sparse(self, roi=None, check_pause_callback=None):
        """
        Convierte el estado disperso del motor nativo a formato denso (grid)
        para compatibilidad con el frontend.

        OPTIMIZACIONES CR√çTICAS:
        - Lazy conversion: solo se llama cuando se necesita
        - ROI support: solo convierte regi√≥n visible si se proporciona
        - Pause check: verifica pausa peri√≥dicamente durante conversi√≥n
        - Duplicate filtering: filtra coordenadas duplicadas del motor nativo

        Args:
            roi: Region of Interest (x_min, y_min, x_max, y_max) opcional.
                 Si se proporciona, solo convierte esa regi√≥n.
            check_pause_callback: Funci√≥n callback para verificar pausa.
                                 Debe retornar True si est√° pausado.
        """
        # Inicializar grid denso si no existe
        if self.state.psi is None:
            self.state.psi = torch.zeros(
                1,
                self.grid_size,
                self.grid_size,
                self.d_state,
                dtype=torch.complex64,
                device=self.device,
            )

        # OPTIMIZACI√ìN: Determinar regi√≥n a convertir (ROI o todo el grid)
        if roi is not None:
            x_min, y_min, x_max, y_max = roi
            # Asegurar que ROI est√© dentro del grid
            x_min = max(0, min(x_min, self.grid_size))
            y_min = max(0, min(y_min, self.grid_size))
            x_max = max(x_min, min(x_max, self.grid_size))
            y_max = max(y_min, min(y_max, self.grid_size))

            # Crear lista de coordenadas solo para ROI
            coords_list = [
                atheria_core.Coord3D(x, y, 0)
                for y in range(y_min, y_max)
                for x in range(x_min, x_max)
            ]
            logging.debug(
                f"Convirtiendo solo ROI: ({x_min}, {y_min}) - ({x_max}, {y_max}), {len(coords_list)} coordenadas"
            )
        else:
            # Sin ROI: convertir todo el grid (fallback)
            coords_list = [
                atheria_core.Coord3D(x, y, 0)
                for y in range(self.grid_size)
                for x in range(self.grid_size)
            ]
            logging.debug(f"Convirtiendo todo el grid: {len(coords_list)} coordenadas")

        # OPTIMIZACI√ìN: Usar batching y verificaci√≥n de pausa
        try:
            # Obtener lista de coordenadas activas del motor nativo si est√° disponible
            # Si no est√° disponible, usar la lista completa (ROI o todo el grid)
            active_coords = None
            try:
                # Intentar obtener coordenadas activas (si el motor nativo lo expone)
                if hasattr(self.native_engine, "get_active_coords"):
                    logging.debug(
                        "üîç Solicitando coordenadas activas al motor nativo..."
                    )
                    active_coords_list = self.native_engine.get_active_coords()
                    logging.debug(
                        f"‚úÖ Coordenadas activas recibidas: {len(active_coords_list) if active_coords_list else 0}"
                    )
                    if active_coords_list and len(active_coords_list) > 0:
                        # CR√çTICO: Filtrar duplicados Y coordenadas fuera del plano Z=0
                        # El motor nativo es 3D y puede propagar a Z!=0, pero la visualizaci√≥n es 2D
                        # Filtramos para quedarnos solo con el slice Z=0 y evitar "duplicados" en la proyecci√≥n 2D
                        unique_coords_set = set()
                        unique_active_coords = []
                        z_filtered_count = 0

                        for coord in active_coords_list:
                            # Solo procesar slice Z=0
                            if coord.z != 0:
                                z_filtered_count += 1
                                continue

                            coord_tuple = (coord.x, coord.y, coord.z)
                            if coord_tuple not in unique_coords_set:
                                unique_coords_set.add(coord_tuple)
                                unique_active_coords.append(coord)

                        if z_filtered_count > 0:
                            logging.debug(
                                f"üîÑ Filtrados {z_filtered_count} part√≠culas fuera del plano Z=0"
                            )

                        if (
                            len(unique_active_coords)
                            < len(active_coords_list) - z_filtered_count
                        ):
                            logging.debug(
                                f"üîÑ Filtrados {len(active_coords_list) - z_filtered_count - len(unique_active_coords)} duplicados reales en Z=0"
                            )

                        active_coords_list = unique_active_coords

                        # Filtrar coordenadas activas por ROI si aplica
                        if roi is not None:
                            x_min, y_min, x_max, y_max = roi
                            active_coords = [
                                coord
                                for coord in active_coords_list
                                if x_min <= coord.x < x_max and y_min <= coord.y < y_max
                            ]
                        else:
                            active_coords = active_coords_list
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è Error obteniendo coordenadas activas: {e}")
                pass

            # Si tenemos coordenadas activas, usar solo esas (mucho m√°s r√°pido)
            if active_coords is not None and len(active_coords) > 0:
                coords_to_process = active_coords
                BATCH_SIZE = 1000  # Batch m√°s grande para coordenadas activas
                logging.debug(
                    f"Usando {len(active_coords)} coordenadas activas (ROI aplicado)"
                )
            else:
                # Sin coordenadas activas: usar lista completa (ROI o todo el grid)
                # OPTIMIZACI√ìN: Sampling tambi√©n para lista completa si es muy grande
                total_coords = len(coords_list)
                if total_coords > 100000:  # Para grids muy grandes
                    sample_rate = max(
                        1, total_coords // 50000
                    )  # M√°ximo 50k coordenadas
                    coords_to_process = coords_list[::sample_rate]
                    logging.info(
                        f"üîÑ Sampling para lista completa: {len(coords_to_process)} de {total_coords} coordenadas (rate={sample_rate})"
                    )
                else:
                    coords_to_process = coords_list
                BATCH_SIZE = 1000  # Batch m√°s grande para mejor rendimiento
                logging.debug(
                    f"Usando lista completa: {len(coords_to_process)} coordenadas"
                )

            # Procesar en batches con verificaci√≥n de pausa
            non_zero_count = 0
            total_processed = 0
            max_abs_value = 0.0

            total_batches = (len(coords_to_process) + BATCH_SIZE - 1) // BATCH_SIZE
            # Solo loguear inicio si son muchos batches
            if total_batches > 5:
                logging.info(
                    f"üîÑ Iniciando conversi√≥n: {len(coords_to_process)} coordenadas en {total_batches} batches (tama√±o={BATCH_SIZE})"
                )

            import time

            start_time = time.time()
            TIMEOUT = 30.0  # Timeout expl√≠cito para conversi√≥n (30s)

            for batch_idx, i in enumerate(range(0, len(coords_to_process), BATCH_SIZE)):
                # CR√çTICO: Verificar pausa cada batch para permitir pausa inmediata
                if check_pause_callback and check_pause_callback():
                    logging.debug("Conversi√≥n interrumpida por pausa")
                    return  # Salir temprano si est√° pausado

                # CR√çTICO: Verificar timeout global
                if time.time() - start_time > TIMEOUT:
                    logging.error(
                        f"‚ùå Timeout en conversi√≥n denso-disperso (> {TIMEOUT}s). Retornando estado parcial."
                    )
                    # Si falla, intentar al menos devolver lo que tenemos o un estado v√°lido m√≠nimo
                    break

                # Logging peri√≥dico para evitar bloqueos silenciosos (menos frecuente)
                if total_batches > 10 and (
                    batch_idx % 20 == 0 or batch_idx == total_batches - 1
                ):
                    logging.info(
                        f"üìä Conversi√≥n progreso: batch {batch_idx+1}/{total_batches} ({total_processed} procesadas)"
                    )

                batch_coords = coords_to_process[i : i + BATCH_SIZE]
                for coord_idx, coord in enumerate(batch_coords):
                    try:
                        state_tensor = self.native_engine.get_state_at(coord)

                        # Verificar que get_state_at retorn√≥ algo
                        if state_tensor is None:
                            continue

                        # Verificar shape antes de copiar
                        if state_tensor.shape == (self.d_state,):
                            # Verificar si el estado tiene datos v√°lidos (no todo ceros)
                            abs_value = state_tensor.abs().max().item()
                            if abs_value > 1e-10:
                                non_zero_count += 1
                                max_abs_value = max(max_abs_value, abs_value)

                            # Mover a dispositivo correcto si es necesario
                            if state_tensor.device != self.device:
                                state_tensor = state_tensor.to(self.device)

                            # Copiar al estado denso (batch, H, W, d_state)
                            # CR√çTICO: Verificar que las coordenadas est√©n dentro del rango v√°lido
                            if (
                                0 <= coord.x < self.grid_size
                                and 0 <= coord.y < self.grid_size
                            ):
                                self.state.psi[0, coord.y, coord.x] = state_tensor

                            total_processed += 1
                        else:
                            # Silencioso para no saturar logs
                            pass
                    except Exception as e:
                        # Silencioso para no saturar logs
                        pass

            # DEBUG: Logging de estad√≠sticas de conversi√≥n (solo si hubo algo procesado)
            if total_processed > 0 and non_zero_count == 0:
                logging.warning(
                    f"‚ö†Ô∏è Conversi√≥n completada pero 0/{total_processed} coordenadas tienen estado no-cero. El motor nativo podr√≠a estar vac√≠o."
                )

        except Exception as e:
            logging.error(
                f"‚ùå Error convirtiendo estado disperso a denso: {e}", exc_info=True
            )
            # En caso de error, mantener grid actual o inicializar vac√≠o
            if self.state.psi is None:
                self.state.psi = torch.zeros(
                    1,
                    self.grid_size,
                    self.grid_size,
                    self.d_state,
                    dtype=torch.complex64,
                    device=self.device,
                )

    def get_visualization_data(self, viz_type: str = "density"):
        """
        Obtiene datos de visualizaci√≥n directamente del motor nativo.

        Args:
            viz_type: Tipo de visualizaci√≥n ("density", "phase", "energy")

        Returns:
            Tensor denso [H, W] con los valores calculados, o None si falla.
        """
        try:
            if hasattr(self.native_engine, "compute_visualization"):
                # Llamada directa a C++
                viz_tensor = self.native_engine.compute_visualization(viz_type)

                # Asegurar que est√© en el mismo dispositivo que self.device
                if viz_tensor.device != self.device:
                    viz_tensor = viz_tensor.to(self.device)

                return viz_tensor
            else:
                logging.warning(
                    "Motor nativo no soporta compute_visualization. Usando fallback Python."
                )
                return None
        except Exception as e:
            logging.error(f"Error en compute_visualization nativo: {e}")
            return None

    def get_model_for_params(self):
        """Retorna el modelo para acceso a par√°metros (compatibilidad)."""
        return self.original_model if self.original_model else self

    def compile_model(self):
        """M√©todo de compatibilidad - el modelo nativo ya est√° compilado."""
        self.is_compiled = True
        logging.info("Modelo nativo: ya est√° optimizado (compilado en C++)")

    def regenerate_initial_state(self, cfg=None):
        """
        Regenera el estado inicial denso seg√∫n INITIAL_STATE_MODE_INFERENCE y lo convierte
        al formato disperso del motor nativo. Esto respeta la ley M - las part√≠culas emergen
        del estado inicial, no se agregan manualmente.

        Args:
            cfg: Configuraci√≥n del experimento (opcional, usa self.cfg si no se proporciona)
        """
        from .. import config as global_cfg

        logging.info(
            "üîÑ Regenerando estado inicial seg√∫n INITIAL_STATE_MODE_INFERENCE..."
        )

        # Obtener modo de inicializaci√≥n
        config = cfg if cfg is not None else getattr(self, "cfg", None)
        initial_mode = "complex_noise"  # Default
        if config is not None:
            initial_mode = getattr(
                config, "INITIAL_STATE_MODE_INFERENCE", "complex_noise"
            )
        else:
            initial_mode = getattr(
                global_cfg, "INITIAL_STATE_MODE_INFERENCE", "complex_noise"
            )

        # Limpiar motor nativo existente si es posible
        if hasattr(self, "native_engine") and self.native_engine is not None:
            try:
                # El motor nativo tiene m√©todo clear() seg√∫n sparse_engine.h
                self.native_engine.clear()
                logging.debug("üßπ Motor nativo limpiado antes de regenerar estado")
            except Exception as e:
                logging.debug(
                    f"‚ö†Ô∏è Error limpiando motor nativo: {e}, continuando sin limpiar"
                )

        # Obtener configuraci√≥n de grid scaling si est√° disponible
        base_state = None
        base_grid_size = None
        if config is not None:
            training_grid_size = getattr(config, "GRID_SIZE_TRAINING", None)
            if training_grid_size and training_grid_size < self.grid_size:
                # Crear estado base del tama√±o de entrenamiento y replicarlo
                base_state_temp = QuantumState(
                    training_grid_size,
                    self.d_state,
                    self.device,
                    initial_mode=initial_mode,
                )
                base_state = base_state_temp.psi
                base_grid_size = training_grid_size
                logging.info(
                    f"üîÑ Grid escalado: Creando estado base {training_grid_size}x{training_grid_size} para replicar en {self.grid_size}x{self.grid_size}"
                )

        # Regenerar estado cu√°ntico denso seg√∫n INITIAL_STATE_MODE_INFERENCE
        self.state = QuantumState(
            self.grid_size,
            self.d_state,
            self.device,
            initial_mode=initial_mode,
            base_state=base_state,
            base_grid_size=base_grid_size,
        )

        # CR√çTICO: Convertir estado denso inicial al formato disperso del motor nativo
        # Esto genera las part√≠culas desde el estado denso (ley M respetada)
        self._initialize_native_state_from_dense(self.state.psi)

        # Marcar estado denso como stale para forzar reconversi√≥n si se necesita
        self._dense_state_stale = True

        logging.info(
            f"‚úÖ Estado inicial regenerado seg√∫n INITIAL_STATE_MODE_INFERENCE ({initial_mode})"
        )

    def add_initial_particles(self, num_particles: int = 10):
        """
        DEPRECADO: Este m√©todo es un hack temporal y NO respeta la ley M.

        Use regenerate_initial_state() en su lugar, que genera part√≠culas desde el estado
        inicial denso seg√∫n INITIAL_STATE_MODE_INFERENCE (las part√≠culas emergen naturalmente).

        Este m√©todo solo se mantiene como fallback temporal para compatibilidad.

        Args:
            num_particles: N√∫mero de part√≠culas a agregar (ignorado, se usa para logging)
        """
        import numpy as np

        logging.warning(
            f"‚ö†Ô∏è add_initial_particles() es DEPRECADO y NO respeta la ley M."
        )
        logging.warning(
            f"‚ö†Ô∏è Las part√≠culas deber√≠an emerger del estado inicial seg√∫n INITIAL_STATE_MODE_INFERENCE."
        )
        logging.info(f"üí° Usando regenerate_initial_state() en su lugar...")

        # Usar el m√©todo correcto que respeta la ley M
        try:
            self.regenerate_initial_state()
        except Exception as e:
            logging.error(f"‚ùå Error regenerando estado inicial: {e}")
            logging.warning(f"‚ö†Ô∏è Fallback a add_initial_particles() (NO RECOMENDADO)")

            # Fallback solo si regenerate_initial_state falla
            logging.info(
                f"üõ†Ô∏è Fallback: Agregando {num_particles} part√≠culas aleatorias al motor nativo..."
            )

            # Generar part√≠culas aleatorias en el grid
            for _ in range(
                min(num_particles, 100)
            ):  # Limitar a 100 para evitar bloqueos
                x = np.random.randint(0, self.grid_size)
                y = np.random.randint(0, self.grid_size)
                z = 0  # Para 2D, z=0

                # Estado inicial con valores significativos
                initial_state = (
                    torch.randn(self.d_state, dtype=torch.complex64, device=self.device)
                    * 0.5
                )

                # Agregar al motor nativo
                coord = atheria_core.Coord3D(x, y, z)
                self.native_engine.add_particle(coord, initial_state)

            logging.info(
                f"‚úÖ {min(num_particles, 100)} part√≠culas aleatorias agregadas al motor nativo (fallback)"
            )

            # Marcar estado denso como stale
            self._dense_state_stale = True
            if self.state and self.state.psi is not None:
                self.state.psi = None

    def cleanup(self):
        """
        Limpia recursos del motor nativo de forma expl√≠cita.
        Debe llamarse antes de destruir el wrapper para evitar segfaults.
        """
        try:
            # Limpiar estado denso primero
            try:
                if hasattr(self, "state") and self.state is not None:
                    if hasattr(self.state, "psi") and self.state.psi is not None:
                        try:
                            self.state.psi = None
                        except Exception as psi_error:
                            logging.debug(f"Error limpiando state.psi: {psi_error}")
                    try:
                        self.state = None
                    except Exception as state_error:
                        logging.debug(f"Error limpiando state: {state_error}")
            except Exception as state_cleanup_error:
                logging.debug(f"Error durante limpieza de state: {state_cleanup_error}")

            # Limpiar referencias al motor nativo
            # El destructor de C++ se llamar√° autom√°ticamente cuando no haya m√°s referencias
            try:
                if hasattr(self, "native_engine") and self.native_engine is not None:
                    # Liberar referencias expl√≠citamente
                    # CR√çTICO: Capturar cualquier error durante la liberaci√≥n del motor C++
                    try:
                        self.native_engine = None
                    except Exception as native_cleanup_error:
                        logging.warning(
                            f"Error liberando native_engine: {native_cleanup_error}"
                        )
            except Exception as native_error:
                logging.warning(
                    f"Error durante limpieza de native_engine: {native_error}"
                )

            # Limpiar otras referencias de forma segura
            try:
                if hasattr(self, "dense_state_cache"):
                    self.dense_state_cache = None
            except Exception:
                pass  # Ignorar errores en limpieza de cache

            try:
                self.model_loaded = False
                self.step_count = 0
                self.last_delta_psi = None
                self.last_psi_input = None
                self.last_delta_psi_decay = None
            except Exception:
                pass  # Ignorar errores en limpieza de atributos simples

            logging.debug("NativeEngineWrapper limpiado correctamente")
        except Exception as e:
            logging.warning(
                f"Error durante cleanup de NativeEngineWrapper: {e}", exc_info=True
            )

    def __del__(self):
        """Destructor - llama a cleanup para asegurar limpieza correcta."""
        try:
            self.cleanup()
        except Exception:
            # Ignorar errores en destructor para evitar problemas durante garbage collection
            pass

    @property
    def _state_psi_property(self):
        """
        Property helper para acceder a state.psi con lazy conversion.
        Usado internamente para compatibilidad con c√≥digo existente.
        """
        return self.get_dense_state(check_pause_callback=lambda: False)

    def _ensure_state_psi(self):
        """
        Asegura que state.psi est√© disponible (para compatibilidad).
        Internamente usa lazy conversion.
        """
        if self.state.psi is None or self._dense_state_stale:
            self.get_dense_state(check_pause_callback=lambda: False)
