"""
Wrapper para integrar el motor nativo de C++ (atheria_core.Engine) con el frontend.

Este wrapper proporciona una interfaz compatible con Aetheria_Motor para que
el motor nativo de alto rendimiento pueda usarse como reemplazo directo.
"""
import torch
import logging
import numpy as np
from typing import Optional

# Intentar importar el m√≥dulo nativo con manejo robusto de errores CUDA
NATIVE_AVAILABLE = False
_native_import_error = None
_native_cuda_issue = False  # Flag para indicar que hay problema de CUDA pero el m√≥dulo existe

try:
    # Intentar importar el m√≥dulo nativo
    import atheria_core
    NATIVE_AVAILABLE = True
    logging.info("‚úÖ M√≥dulo nativo atheria_core importado exitosamente")
except (ImportError, OSError, RuntimeError) as e:
    error_str = str(e)
    _native_import_error = error_str
    
    # Detectar problemas espec√≠ficos de CUDA runtime
    cuda_runtime_keywords = [
        '__nvJitLinkCreate',
        'libnvJitLink',
        'libcusparse.so',
        'undefined symbol'
    ]
    
    if any(keyword in error_str for keyword in cuda_runtime_keywords):
        # Problema de CUDA runtime - el m√≥dulo est√° compilado pero tiene problemas de CUDA
        _native_cuda_issue = True
        logging.warning(f"‚ö†Ô∏è Problema de CUDA runtime detectado al importar atheria_core: {error_str[:100]}")
        logging.info("üí° El motor nativo solo funcionar√° en modo CPU. Usa device='cpu' al inicializar.")
        # No marcamos como no disponible - a√∫n puede funcionar en CPU
        # NATIVE_AVAILABLE permanece False, pero el wrapper puede intentar inicializar en CPU
    else:
        # Otro tipo de error - probablemente el m√≥dulo no est√° compilado
        logging.warning(f"atheria_core no disponible: {error_str[:100]}")
        if "No module named" in error_str or "cannot open shared object file" in error_str:
            logging.info("üí° El m√≥dulo C++ no est√° compilado. Ejecuta: python setup.py build_ext --inplace")
        else:
            logging.info("üí° Error inesperado al importar m√≥dulo nativo. Usando motor Python como fallback.")
except Exception as e:
    # Error inesperado
    _native_import_error = str(e)
    logging.warning(f"Error inesperado importando atheria_core: {e}")
    logging.info("El motor nativo no estar√° disponible, usando motor Python como fallback.")

from ..engines.qca_engine import QuantumState


class NativeEngineWrapper:
    """
    Wrapper que envuelve atheria_core.Engine para mantener compatibilidad
    con el c√≥digo existente que usa Aetheria_Motor.
    
    Convierte entre el formato disperso del motor nativo y el formato
    denso (grid) usado por el frontend.
    """
    
    def __init__(self, grid_size: int, d_state: int, device: str = "cpu", cfg=None):
        """
        Inicializa el wrapper del motor nativo.
        
        Args:
            grid_size: Tama√±o del grid para visualizaci√≥n (debe coincidir con inference_grid_size)
            d_state: Dimensi√≥n del estado cu√°ntico
            device: Dispositivo ('cpu' o 'cuda')
            cfg: Configuraci√≥n del experimento (opcional)
        """
        # Verificar disponibilidad del m√≥dulo
        module_available = NATIVE_AVAILABLE
        
        # Si hay problema de CUDA pero intentamos usar CPU, intentar importar forzando CPU
        if not NATIVE_AVAILABLE and _native_cuda_issue and device == "cpu":
            logging.info("Intentando importar m√≥dulo nativo forzando CPU mode...")
            try:
                import os
                # Forzar CPU deshabilitando CUDA temporalmente
                original_cuda = os.environ.get('CUDA_VISIBLE_DEVICES', None)
                os.environ['CUDA_VISIBLE_DEVICES'] = ''
                try:
                    import atheria_core  # Reintentar importaci√≥n
                    module_available = True
                    logging.info("‚úÖ M√≥dulo nativo importado exitosamente en CPU mode")
                finally:
                    # Restaurar valor original
                    if original_cuda is not None:
                        os.environ['CUDA_VISIBLE_DEVICES'] = original_cuda
                    elif 'CUDA_VISIBLE_DEVICES' in os.environ:
                        del os.environ['CUDA_VISIBLE_DEVICES']
            except Exception as e2:
                # A√∫n falla - no disponible
                error_msg = f"atheria_core no est√° disponible. Error original: {_native_import_error[:100] if _native_import_error else str(e2)}"
                if _native_cuda_issue:
                    error_msg += " (Problema de CUDA runtime - solo CPU mode disponible, pero tambi√©n fall√≥)"
                raise ImportError(error_msg + " Usa el motor Python como fallback.")
        
        if not module_available:
            # No disponible para nada
            error_msg = "atheria_core no est√° disponible."
            if _native_import_error:
                error_msg += f" Error: {_native_import_error[:100]}"
            if _native_cuda_issue:
                error_msg += " (Problema de CUDA runtime - intenta usar device='cpu')"
            raise ImportError(error_msg + " Usa el motor Python como fallback.")
        
        # Si hay problema de CUDA runtime y se intenta usar CUDA, forzar CPU mode
        if device == "cuda" and _native_cuda_issue:
            logging.warning("‚ö†Ô∏è Problema de CUDA runtime detectado. Forzando CPU mode para motor nativo.")
            device = "cpu"
        
        self.grid_size = int(grid_size)
        self.d_state = int(d_state)
        self.device_str = device
        self.device = torch.device(device)
        self.cfg = cfg
        
        # Inicializar motor nativo
        self.native_engine = atheria_core.Engine(d_state=d_state, device=device)
        
        # Estado cu√°ntico para compatibilidad (denso)
        # El motor nativo usa formato disperso, pero necesitamos denso para visualizaci√≥n
        self.state = QuantumState(grid_size, d_state, device)
        
        # Configuraci√≥n
        self.grid_size = grid_size
        self.d_state = d_state
        
        # Estado interno
        self.model_loaded = False
        self.step_count = 0
        
        # Para compatibilidad con c√≥digo existente
        self.operator = None  # El modelo est√° cargado en el motor nativo
        self.original_model = None
        self.optimizer = None
        self.has_memory = False
        self.is_compiled = False
        
        # Para visualizaciones (delta_psi)
        self.last_delta_psi = None
        self.last_psi_input = None
        self.last_delta_psi_decay = None
        
        logging.info(f"NativeEngineWrapper inicializado (grid_size={grid_size}, d_state={d_state}, device={device})")
    
    def load_model(self, model_path: str) -> bool:
        """
        Carga un modelo TorchScript (.pt) en el motor nativo.
        
        Args:
            model_path: Ruta al archivo .pt de TorchScript
            
        Returns:
            True si se carg√≥ exitosamente
        """
        success = self.native_engine.load_model(model_path)
        self.model_loaded = success
        if success:
            logging.info(f"‚úÖ Modelo TorchScript cargado en motor nativo: {model_path}")
        else:
            logging.error(f"‚ùå Error al cargar modelo TorchScript: {model_path}")
        return success
    
    def evolve_internal_state(self):
        """Evoluciona el estado interno usando el motor nativo."""
        if not self.model_loaded:
            logging.warning("Modelo no cargado. No se puede evolucionar el estado.")
            return
        
        # Ejecutar paso nativo (todo en C++)
        particle_count = self.native_engine.step_native()
        self.step_count += 1
        
        # Convertir estado disperso a denso para visualizaci√≥n
        # Esto es necesario porque el frontend espera un grid denso
        self._update_dense_state_from_sparse()
    
    def _update_dense_state_from_sparse(self):
        """
        Convierte el estado disperso del motor nativo a formato denso (grid)
        para compatibilidad con el frontend.
        
        El motor nativo almacena part√≠culas dispersas, pero el frontend necesita
        un grid denso. Iteramos sobre todo el grid y obtenemos el estado desde
        el motor nativo (que genera vac√≠o autom√°ticamente si no hay part√≠cula).
        """
        # Inicializar grid denso
        if self.state.psi is None:
            self.state.psi = torch.zeros(
                1, self.grid_size, self.grid_size, self.d_state,
                dtype=torch.complex64, device=self.device
            )
        
        # Iterar sobre todo el grid y obtener estado desde motor nativo
        # El motor nativo genera vac√≠o autom√°ticamente con HarmonicVacuum
        try:
            # Para optimizar, podr√≠amos iterar solo sobre coordenadas activas
            # pero por simplicidad, iteramos sobre todo el grid
            # (puede optimizarse despu√©s si es necesario)
            BATCH_SIZE = 100  # Procesar en batches para mejor rendimiento
            
            coords_list = []
            for y in range(self.grid_size):
                for x in range(self.grid_size):
                    coords_list.append(atheria_core.Coord3D(x, y, 0))
            
            # Obtener estados en batch
            for i in range(0, len(coords_list), BATCH_SIZE):
                batch_coords = coords_list[i:i+BATCH_SIZE]
                for coord in batch_coords:
                    try:
                        state_tensor = self.native_engine.get_state_at(coord)
                        
                        # Si el tensor tiene la forma correcta, copiarlo al grid denso
                        if state_tensor.shape == (self.d_state,):
                            # Mover a dispositivo correcto
                            if state_tensor.is_cuda and self.device.type == 'cpu':
                                state_tensor = state_tensor.cpu()
                            elif not state_tensor.is_cuda and self.device.type == 'cuda':
                                state_tensor = state_tensor.cuda()
                            
                            # Copiar al estado denso (batch, H, W, d_state)
                            self.state.psi[0, coord.y, coord.x] = state_tensor
                    except Exception as e:
                        logging.debug(f"Error obteniendo estado en ({coord.x}, {coord.y}): {e}")
                        
        except Exception as e:
            logging.warning(f"Error convirtiendo estado disperso a denso: {e}")
            # En caso de error, mantener grid vac√≠o (ya inicializado)
    
    def get_model_for_params(self):
        """Retorna el modelo para acceso a par√°metros (compatibilidad)."""
        return self.original_model if self.original_model else self
    
    def compile_model(self):
        """M√©todo de compatibilidad - el modelo nativo ya est√° compilado."""
        self.is_compiled = True
        logging.info("Modelo nativo: ya est√° optimizado (compilado en C++)")
    
    def add_initial_particles(self, num_particles: int = 10):
        """
        Agrega part√≠culas iniciales aleatorias al motor nativo.
        
        Args:
            num_particles: N√∫mero de part√≠culas a agregar
        """
        # Generar part√≠culas aleatorias en el grid
        for _ in range(num_particles):
            x = np.random.randint(0, self.grid_size)
            y = np.random.randint(0, self.grid_size)
            z = 0  # Para 2D, z=0
            
            # Estado inicial peque√±o (energ√≠a baja)
            initial_state = torch.randn(self.d_state, dtype=torch.complex64) * 0.1
            
            # Agregar al motor nativo
            coord = atheria_core.Coord3D(x, y, z)
            self.native_engine.add_particle(coord, initial_state)
        
        logging.info(f"‚úÖ {num_particles} part√≠culas iniciales agregadas al motor nativo")
        
        # Actualizar estado denso
        self._update_dense_state_from_sparse()

