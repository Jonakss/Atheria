import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import logging
import matplotlib.pyplot as plt
from qiskit import QuantumCircuit

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src import config

# Configure Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class StronglyEntanglingConv2d(nn.Module):
    """
    Capa Convolucional Cu치ntica con Ansatz 'Strongly Entangling'.
    Basado en Schuld et al. (2018).
    
    Arquitectura por Capa:
    1. Rotaciones U3(theta, phi, lambda) en cada qubit.
    2. CNOTs circulares (Entrelazamiento).
       - Rango r: Qubit i -> Qubit (i+r)%N
    """
    def __init__(self, grid_size=32, n_layers=5, device='cpu'):
        super().__init__()
        self.grid_size = grid_size
        self.n_qubits = int(np.log2(grid_size * grid_size))
        self.n_layers = n_layers
        self.device = device
        
        # Par치metros entrenables: [Layers, Qubits, 3]
        # 3 치ngulos por U3: theta, phi, lambda
        self.weights = nn.Parameter(torch.randn(n_layers, self.n_qubits, 3) * 0.1)
        
        self.to(device)

    def forward_pqc(self, x_freq):
        """
        Simulaci칩n matem치tica del PQC.
        Nota: Simular U3 general y CNOTs en PyTorch para 10+ qubits es costoso si usamos matrices densas (2^N x 2^N).
        Para este experimento, usaremos una aproximaci칩n diagonal simplificada para entrenamiento r치pido,
        O si queremos fidelidad real, necesitamos simular la matriz unitaria completa.
        
        LIMITACI칍N: Simular CNOTs arbitrarias rompe la estructura diagonal pura.
        Si el operador objetivo es diagonal (fases), un ansatz que genera no-diagonalidad (mezcla amplitudes)
        podr칤a no converger bien si solo miramos la fase.
        
        PERO: EXP-007 extrajo un operador diagonal.
        Si usamos CNOTs, estamos creando entrelazamiento que afecta la fase global.
        
        Para mantener la simulaci칩n tratable en PyTorch sin un simulador de estados completo (que es lento),
        usaremos la propiedad de que si la entrada es un estado base (o superposici칩n de bases),
        podemos rastrear la fase acumulada.
        
        SIN EMBARGO: CNOT |x, y> -> |x, x XOR y>. Esto permuta los estados base.
        No es solo una fase. Es una permutaci칩n.
        
        Si el target es puramente diagonal (solo fases), entonces el PQC ideal deber칤a ser diagonal.
        Un PQC con CNOTs genera no-diagonalidad.
        쯇uede un circuito con CNOTs aproximar una diagonal? S칤, si las CNOTs se cancelan o interfieren constructivamente.
        
        Para este script, dado que queremos entrenar r치pido, implementaremos la simulaci칩n de fase
        asumiendo que estamos actuando sobre la base computacional y sumando fases, 
        PERO las CNOTs cambiar치n el 칤ndice del estado.
        
        Vamos a implementar una simulaci칩n de vector de estado completa (Statevector Simulation) en PyTorch.
        Para 10 qubits (1024 estados), es muy r치pido.
        """
        B, C, H, W = x_freq.shape
        N = 2**self.n_qubits
        
        # Aplanar input a vector de estado [B, C, N]
        # Asumimos que x_freq son las amplitudes diagonales (si es diagonal)
        # Ojo: x_freq en EXP-007 era el espectro.
        # Si el operador es diagonal, output = input * diagonal.
        # Aqu칤 queremos aprender 'diagonal'.
        
        # Vamos a simular el circuito actuando sobre el estado |+> (superposici칩n uniforme)
        # y ver qu칠 fases genera.
        # O mejor: Simular la unitaria completa actuando sobre la identidad.
        
        # Para aprender una DIAGONAL, necesitamos que el circuito sea diagonal.
        # Si metemos CNOTs, la matriz deja de ser diagonal.
        # A MENOS que usemos CNOTs conjugadas o bloques diagonales.
        
        # ESTRATEGIA:
        # Vamos a simular el estado completo.
        # Input: x_flat.
        # Aplicar U3 y CNOTs.
        
        state = x_freq.view(B, C, -1) # [B, C, N]
        
        # Pre-computar matrices de compuertas para vectorizaci칩n
        # Esto es complejo en PyTorch puro para N qubits.
        # Usaremos una aproximaci칩n:
        # Entrenaremos para que U|k> = e^{i phi_k} |k>
        # Es decir, queremos que el circuito act칰e como una diagonal.
        # Si el circuito genera amplitud fuera de la diagonal, eso es penalizado (Loss de fidelidad).
        
        # Simulaci칩n lenta pero exacta (Tensor product)
        # Para 10 qubits, matriz 1024x1024. Es manejable.
        
        # Construir la Unitaria de la Capa
        # U_layer = U_entangle @ U_rot
        
        # 1. Rotaciones Locales (Producto Tensorial de U3s)
        # U3 = [[cos(th/2), -e^{il}sin(th/2)], [e^{ip}sin(th/2), e^{i(l+p)}cos(th/2)]]
        
        # Esta simulaci칩n completa es dif칤cil de vectorizar eficientemente en PyTorch simple.
        # Vamos a usar una librer칤a de simulaci칩n diferenciable si fuera posible, pero no tenemos PennyLane instalado/configurado.
        # Haremos una implementaci칩n customizada para N peque침o.
        
        # TRUCO: Solo nos importa la DIAGONAL del operador resultante si queremos hacer Fast Forward diagonal.
        # Pero si el circuito tiene CNOTs, tendr치 elementos fuera de la diagonal.
        # Vamos a calcular la acci칩n sobre los estados base uno por uno (o en batch).
        
        # Batch de estados base: Identidad [N, N]
        # Si aplicamos el circuito a I, obtenemos la matriz Unitaria U.
        # U[:, k] es la columna k (imagen del estado base k).
        
        current_U = torch.eye(N, dtype=torch.cfloat, device=self.device)
        
        for l in range(self.n_layers):
            # A. Rotaciones U3
            # Aplicar a cada qubit.
            # Para eficiencia, aplicamos U3 a cada columna de current_U como si fuera un estado.
            # Reshape current_U a [N, 2, 2, ..., 2] (N qubits)
            shape = [N] + [2]*self.n_qubits
            current_U = current_U.view(shape)
            
            for q in range(self.n_qubits):
                # Extraer params
                th = self.weights[l, q, 0]
                ph = self.weights[l, q, 1]
                lm = self.weights[l, q, 2]
                
                # Matriz U3 (2x2)
                cos = torch.cos(th/2)
                sin = torch.sin(th/2)
                exp_p = torch.exp(1j * ph)
                exp_l = torch.exp(1j * lm)
                exp_pl = torch.exp(1j * (ph + lm))
                
                u00 = cos
                u01 = -exp_l * sin
                u10 = exp_p * sin
                u11 = exp_pl * cos
                
                # Aplicar tensordot en la dimensi칩n q+1 (la dimensi칩n 0 es el batch de columnas)
                # current_U es [Batch, q0, q1, ..., q_target, ..., qN]
                # Queremos multiplicar la dimensi칩n q_target por U3.
                
                # Mover dimensi칩n q al final para multiplicar
                # Dim 0 es batch. Dims 1..N son qubits. Qubit q es dim q+1.
                perm = list(range(len(shape)))
                target_dim = q + 1
                perm.append(perm.pop(target_dim)) # Mover q al final
                
                current_U = current_U.permute(perm)
                
                # Ahora [..., 2]
                # Multiplicar por U3 [2, 2]
                # U3 acts on the last dimension
                # New_state_0 = u00 * state_0 + u01 * state_1
                # New_state_1 = u10 * state_0 + u11 * state_1
                
                s0 = current_U[..., 0]
                s1 = current_U[..., 1]
                
                n0 = u00 * s0 + u01 * s1
                n1 = u10 * s0 + u11 * s1
                
                current_U = torch.stack([n0, n1], dim=-1)
                
                # Restaurar permutaci칩n
                # La dimensi칩n q estaba al final. Hay que devolverla a q+1.
                inv_perm = [0] * len(perm)
                for i, p in enumerate(perm):
                    inv_perm[p] = i
                current_U = current_U.permute(inv_perm)

            # B. CNOTs Circulares
            # CNOT(Control=i, Target=(i+1)%N)
            # Permuta 칤ndices.
            # En tensor [Batch, q0, q1, ..., qN], CNOT(c, t) intercambia amplitudes donde q_c=1.
            # Espec칤ficamente, si q_c=1, swap q_t=0 y q_t=1.
            
            for q in range(self.n_qubits):
                control = q
                target = (q + 1) % self.n_qubits
                
                # Identificar 칤ndices donde control=1
                # Usamos index_select o slicing.
                
                # Mover control a dim -2 y target a dim -1
                perm = list(range(len(shape)))
                c_dim = control + 1
                t_dim = target + 1
                
                # Queremos (..., c, t) al final
                remaining = [x for x in perm if x != c_dim and x != t_dim]
                new_perm = remaining + [c_dim, t_dim]
                
                current_U = current_U.permute(new_perm)
                
                # Ahora es [..., 2, 2] donde los 칰ltimos son (control, target)
                # CNOT:
                # 00 -> 00
                # 01 -> 01
                # 10 -> 11
                # 11 -> 10
                
                # Copia para no modificar in-place mal
                clone = current_U.clone()
                # Si control (pen칰ltimo) es 1, swap target (칰ltimo)
                # clone[..., 1, 0] = current_U[..., 1, 1]
                # clone[..., 1, 1] = current_U[..., 1, 0]
                
                # Swap slices
                s10 = current_U[..., 1, 0]
                s11 = current_U[..., 1, 1]
                clone[..., 1, 0] = s11
                clone[..., 1, 1] = s10
                
                current_U = clone
                
                # Restaurar permutaci칩n
                inv_perm = [0] * len(new_perm)
                for i, p in enumerate(new_perm):
                    inv_perm[p] = i
                current_U = current_U.permute(inv_perm)
                
        # Al final, aplanar a matriz [N, N]
        U_matrix = current_U.view(N, N)
        
        # Aplicar al input x_flat [B, C, N]
        # Output = U @ x
        # x_flat es [B, C, N]. Transponemos a [B, C, N, 1]
        # Queremos [B, C, N]
        
        # U es [N, N].
        # x es [B, C, N].
        # einsum 'ij, bcj -> bci'
        output = torch.einsum('ij,bcj->bci', U_matrix, state)
        
        return output.view(B, C, H, W)

    def export_circuit(self):
        qc = QuantumCircuit(self.n_qubits)
        for l in range(self.n_layers):
            # U3
            for q in range(self.n_qubits):
                th = self.weights[l, q, 0].item()
                ph = self.weights[l, q, 1].item()
                lm = self.weights[l, q, 2].item()
                qc.u(th, ph, lm, q)
            # CNOTs
            for q in range(self.n_qubits):
                qc.cx(q, (q+1)%self.n_qubits)
        return qc

def main():
    print("游 Iniciando EXP-009: Advanced Ansatz (Strongly Entangling)")
    device = torch.device('cpu') # CPU es m치s r치pido para bucles peque침os de tensores complejos custom
    
    # 1. Cargar Target
    checkpoint_path = "output/checkpoints/quantum_native_model.pt" # Usamos el mismo target que EXP-008
    # O mejor, cargamos el target original de EXP-007
    cp_path_007 = "output/checkpoints/fastforward_1M.pt"
    
    if os.path.exists(cp_path_007):
        cp = torch.load(cp_path_007, map_location=device)
        raw_transfer = cp['transfer_function'].to(device)
        target_phases = raw_transfer / (raw_transfer.abs() + 1e-8)
        grid_size = target_phases.shape[-1]
    else:
        logging.warning("丘멆잺 No checkpoint found. Using dummy.")
        grid_size = 4 # Reduced for speed in demo
        target_phases = torch.ones(1, 1, grid_size, grid_size, dtype=torch.cfloat, device=device)
        
    # FORCE 4x4 for fast proof of concept if 32x32 is too slow
    if grid_size > 4:
        logging.warning(f"丘멆잺 Reducing grid from {grid_size} to 4 for fast training demo.")
        grid_size = 4
        # Downsample target if possible, or just slice
        target_phases = target_phases[..., :4, :4]
        
    logging.info(f"   Target Grid: {grid_size}x{grid_size}")
    
    # 2. Inicializar Modelo
    model = StronglyEntanglingConv2d(grid_size=grid_size, n_layers=5, device=device)
    optimizer = optim.Adam(model.parameters(), lr=0.01)
    
    # 3. Entrenamiento
    logging.info("游 Entrenando Strongly Entangling PQC...")
    losses = []
    
    # Input constante (1s) para aprender la acci칩n sobre el estado plano
    dummy_input = torch.ones(1, 1, grid_size, grid_size, dtype=torch.cfloat, device=device)
    dummy_input = dummy_input / dummy_input.norm()
    
    # Target Output = Target Operator * Input
    target_output = target_phases * dummy_input
    
    for epoch in range(100):
        optimizer.zero_grad()
        
        generated = model.forward_pqc(dummy_input)
        
        # Loss: 1 - Fidelity
        # Fidelity = |<gen|target>|^2
        overlap = torch.abs(torch.vdot(generated.flatten(), target_output.flatten()))**2
        loss = 1.0 - overlap
        
        loss.backward()
        optimizer.step()
        
        losses.append(loss.item())
        if epoch % 10 == 0:
            logging.info(f"   Epoch {epoch}: Fidelity = {overlap.item():.6f}, Loss = {loss.item():.6f}")
            
    # 4. Exportar
    qc = model.export_circuit()
    try:
        import qiskit.qasm2
        qasm_str = qiskit.qasm2.export(qc)
    except:
        qasm_str = "Export failed"
        
    logging.info(f"游 Fidelidad Final: {1.0 - losses[-1]:.6f}")
    logging.info(f"游늵 Gate Count: {sum(qc.count_ops().values())}")
    
    torch.save({
        'model_state_dict': model.state_dict(),
        'circuit_qasm': qasm_str,
        'losses': losses,
        'final_fidelity': 1.0 - losses[-1]
    }, "output/checkpoints/advanced_ansatz_model.pt")

if __name__ == "__main__":
    main()
