# AETHERIA: Simulaci√≥n de Complejidad Emergente con QCA

Bienvenido a AETHERIA, una aplicaci√≥n para simular la emergencia de estructuras complejas a partir de reglas f√≠sicas fundamentales.

Este proyecto modela un universo discreto como una cuadr√≠cula de Aut√≥matas Celulares Cu√°nticos (QCA). La evoluci√≥n de este universo no est√° pre-programada, sino que es gobernada por una **"Ley M" (Ley Fundamental)**: un modelo de Deep Learning (como un MLP o una U-Net) que se entrena desde cero.

El objetivo es descubrir, mediante un proceso de "evoluci√≥n artificial" (Aprendizaje por Refuerzo), una Ley M que opere en el **"Borde del Caos"**: el r√©gimen cr√≠tico donde la informaci√≥n puede propagarse, la estabilidad se mantiene y la complejidad estructural emerge espont√°neamente.

Esta aplicaci√≥n est√° construida como una **App de Lightning AI**, permitiendo un entrenamiento pesado en GPU y un despliegue de simulaci√≥n en tiempo real a trav√©s de un servidor WebSocket.

-----

## üöÄ Arquitectura del Proyecto

El proyecto est√° separado en un lanzador de aplicaci√≥n (`app.py`), una interfaz de usuario (`ui.py`), un lanzador de script local (`main.py`) y un paquete de c√≥digo fuente (`src/`).

```
aetheria/
‚îú‚îÄ‚îÄ app.py              <-- üöÄ El lanzador de la App Lightning (Frontend + Backend)
‚îú‚îÄ‚îÄ ui.py               <-- üñ•Ô∏è El visor web (Streamlit UI)
‚îú‚îÄ‚îÄ main.py             <-- üî¨ El lanzador para ejecuci√≥n local (entrenamiento/scripts)
‚îú‚îÄ‚îÄ requirements.txt    <-- üìã Dependencias del proyecto
‚îÇ
‚îú‚îÄ‚îÄ src/                <-- üß† Todo el c√≥digo fuente
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py         <-- ‚öôÔ∏è ¬°Par√°metros globales y flags de ejecuci√≥n aqu√≠!
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ qca_engine.py     <-- üåå Clases Aetheria_Motor y QCA_State
‚îÇ   ‚îú‚îÄ‚îÄ qca_operator_mlp.py  <-- üß¨ Ley M v1: MLP 1x1 (Visi√≥n local, "m√≠ope")
‚îÇ   ‚îú‚îÄ‚îÄ qca_operator_unet.py <-- üß¨ Ley M v2: U-Net (Visi√≥n regional, "consciente")
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ trainer.py        <-- üèãÔ∏è Clase de entrenamiento (QC_Trainer_v3)
‚îÇ   ‚îú‚îÄ‚îÄ visualization.py  <-- üé® Funciones get_frame_gpu()
‚îÇ   ‚îú‚îÄ‚îÄ utils.py          <-- üì¶ Funciones de ayuda (load/save_state)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ pipeline_train.py   <-- üè≠ Script: FASE 5 (Entrenamiento)
‚îÇ   ‚îú‚îÄ‚îÄ pipeline_viz.py     <-- üé¨ Script: FASE 6 (Generar V√≠deos)
‚îÇ   ‚îî‚îÄ‚îÄ pipeline_server.py  <-- üì° Script: FASE 7 (Servidor WebSocket)
‚îÇ
‚îî‚îÄ‚îÄ output/             <-- üìä Todos los resultados (v√≠deos y checkpoints)
    ‚îú‚îÄ‚îÄ training_checkpoints/
    ‚îî‚îÄ‚îÄ simulation_checkpoints/
```

-----

## ‚öôÔ∏è C√≥mo Empezar

### 1\. Instalaci√≥n

Aseg√∫rate de tener todas las dependencias instaladas en tu entorno.

```bash
pip install -r requirements.txt
```

### 2\. Configuraci√≥n

**Casi todo se controla desde `src/config.py`**. Antes de ejecutar, revisa este archivo para:

  * Ajustar los *flags* de ejecuci√≥n (`RUN_TRAINING`, `RUN_LARGE_SIM`, etc.).
  * Configurar los par√°metros de entrenamiento (`GRID_SIZE_TRAINING`, `EPISODES_TO_ADD`).
  * Configurar los par√°metros de la simulaci√≥n (`GRID_SIZE_INFERENCE`).

### 3\. Elegir tu "Ley M" (El Cerebro)

Puedes cambiar f√°cilmente qu√© modelo de f√≠sica quieres entrenar o ejecutar. Abre `src/pipeline_train.py` y `src/pipeline_server.py` y edita el "Selector de Modelo" en la parte superior:

```python
# --- Elige tu "Ley M" (Cerebro) aqu√≠ ---

# Opci√≥n 1: El MLP 1x1 original (R√°pido, pero "m√≠ope")
from .qca_operator_mlp import QCA_Operator_MLP as ActiveModel

# Opci√≥n 2: La U-Net (M√°s lenta, pero con "conciencia regional")
# from .qca_operator_unet import QCA_Operator_UNet as ActiveModel
```

-----

## üèÉ C√≥mo Ejecutar

Este proyecto tiene **dos modos de ejecuci√≥n principales**:

### Modo 1: Entrenamiento y Scripting (Local)

Usa `main.py` para tareas de "un solo uso" como entrenar un nuevo modelo o generar un lote de videos.

1.  **Configura:** Abre `src/config.py` y pon:
      * `RUN_TRAINING = True`
      * `RUN_POST_TRAINING_VIZ = True`
      * `RUN_LARGE_SIM = False` (¬°Importante\!)
2.  **Ejecuta:**
    ```bash
    python main.py
    ```
3.  **Resultado:** El script ejecutar√° el `pipeline_train.py` y luego el `pipeline_viz.py`. Todos los modelos (`.pth`) y videos (`.mp4`) se guardar√°n en la carpeta `output/`.

### Modo 2: Servidor de Simulaci√≥n (Producci√≥n)

Usa `app.py` para lanzar la simulaci√≥n persistente como un servicio en la nube (o localmente) con un visor web en tiempo real.

1.  **Configura:** Abre `src/config.py` y pon:
      * `RUN_TRAINING = False`
      * `RUN_POST_TRAINING_VIZ = False`
      * `RUN_LARGE_SIM = True`
2.  **Ejecuta (Localmente):**
    ```bash
    lightning run app app.py
    ```
3.  **Ejecuta (En la Nube de Lightning AI):**
    ```bash
    lightning run app app.py --cloud
    ```
4.  **Resultado:** Esto lanzar√° el backend de simulaci√≥n (`SimulationServer`) en una GPU y el frontend (`ui.py`) en un servidor web. Abre la URL que te da la terminal para ver la simulaci√≥n en tiempo real.

-----

## üìä Interpretaci√≥n de Resultados

El visor te permite observar la din√°mica emergente del QCA en tiempo real:

  * **Densidad:** Mapa de calor que muestra la concentraci√≥n de "energ√≠a" o "materia".
  * **Canales Internos:** Mapeo a RGB de los primeros canales del estado. Ayuda a ver la actividad de los componentes del campo.
  * **Magnitud de Estado:** Intensidad total del vector de estado en cada celda.
  * **Fase de Estado:** Coherencia de fase, crucial para el comportamiento tipo onda.
  * **Cambio de Estado / Actividad:** Resalta las regiones activas o "vivas" del universo.

-----

## üíæ Checkpointing y Reanudaci√≥n

El proyecto guarda el progreso autom√°ticamente en la carpeta `output/`.

  * **Checkpoints de Entrenamiento (`output/training_checkpoints/`):**
      * Contienen el estado del modelo, optimizador e historial.
      * Para reanudar el entrenamiento, pon `CONTINUE_TRAINING = True` en `src/config.py`.
  * **Checkpoints de Simulaci√≥n (`output/simulation_checkpoints/`):**
      * Contienen el estado crudo (`x_real`, `x_imag`) de la simulaci√≥n grande.
      * Para reanudar una simulaci√≥n, pon `LOAD_STATE_CHECKPOINT_INFERENCE = True` en `src/config.py`.

-----

## üß¨ Par√°metros Clave en `src/config.py`

### Arquitectura y Entrenamiento

  * `GRID_SIZE_TRAINING`: Tama√±o de la cuadr√≠cula para entrenar (ej. 256).
  * `D_STATE`: Canales/dimensiones de cada celda (ej. 21).
  * `HIDDEN_CHANNELS`: Ancho de la Ley M (ej. 64 para U-Net, 256 para MLP).
  * `EPISODES_TO_ADD`: Cu√°ntos episodios de entrenamiento ejecutar.
  * `PERSISTENCE_COUNT`: Pasos de BPTT (memoria del entrenamiento).

### Recompensas (El "Objetivo" de la F√≠sica)

  * `ALPHA_START`/`ALPHA_END`: Peso de la recompensa de **complejidad** (`R_Density_Target`).
  * `GAMMA_START`/`GAMMA_END`: Peso de la recompensa de **estabilidad** (`R_Stability`).
  * `BETA_CAUSALITY`: Peso de la recompensa de **actividad** (`R_Causality`).
  * `LAMBDA_ACTIVITY_VAR`: Recompensa por varianza de actividad (crea "vida" interesante).
  * `LAMBDA_VELOCIDAD`: Recompensa por la varianza de la densidad (crea "movimiento").

### Simulaci√≥n y Servidor

  * `GRID_SIZE_INFERENCE`: Tama√±o de la cuadr√≠cula de producci√≥n (ej. 468, 1024).
  * `REAL_TIME_VIZ_INTERVAL`: Cada cu√°ntos pasos se env√≠a un frame al visor (ej. 5).
  * `REAL_TIME_VIZ_TYPE`: Qu√© tipo de frame enviar (`density`, `change`, `phase`, etc.).
  * `REAL_TIME_VIZ_DOWNSCALE`: Factor de reducci√≥n de la imagen para el visor (ej. 2).