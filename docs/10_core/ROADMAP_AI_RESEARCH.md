#  Roadmap Investigaci贸n IA: The Brain (Ley M)

**Objetivo:** Desarrollar y evolucionar "Ley M", la red neuronal que act煤a como las leyes fundamentales de la f铆sica en Atheria, buscando arquitecturas que favorezcan la emergencia de complejidad.

---

## 1. Arquitecturas de Modelos

**Referencia:** [[MASSIVE_INFERENCE_ARCHITECTURE|Arquitectura de Inferencia]]

### A. Redes Neuronales de Pulsos (SNN)
Explorar redes que operan con eventos discretos (spikes) para mayor eficiencia y realismo biol贸gico/f铆sico.
- **Spiking U-Net:** Adaptar la arquitectura U-Net para usar neuronas LIF (Leaky Integrate-and-Fire).
- **Eficiencia Energ茅tica:** Aprovechar la escasez (sparsity) de los spikes.

### B. Transformers & Attention
- **Vision Transformers (ViT):** Aplicar mecanismos de atenci贸n para capturar dependencias de largo alcance en el grid.
- **Physics-Informed Attention:** Restringir la atenci贸n a conos de luz causales.

### C. Variantes de U-Net
- **Unitary U-Net:** Garantizar la preservaci贸n de norma (energ铆a) mediante matrices ortogonales.
- **3D U-Net:** (Para Fase 4/5) Adaptar convoluciones para vol煤menes.

---

## 2. Curriculum Learning (Evoluci贸n)

**Referencia:** [[PROGRESSIVE_LEARNING|Aprendizaje Progresivo]]

### A. Definici贸n de pocas
Formalizar las etapas de entrenamiento para guiar la complejidad.
1.  **Vac铆o:** Aprender a mantener el vac铆o estable (eliminar ruido).
2.  **Part铆culas:** Aprender a formar excitaciones estables (solitones).
3.  **Interacci贸n:** Aprender reglas de colisi贸n y dispersi贸n.
4.  **Estructura:** Formaci贸n de agregados complejos.

### B. Epoch Detector
- **M茅tricas de Complejidad:** Desarrollar m茅tricas robustas para detectar cambios de fase (ej. Dimensi贸n Fractal, Entrop铆a de Shannon).
- **Trigger Autom谩tico:** El sistema debe cambiar los hiperpar谩metros (ruido, learning rate) autom谩ticamente al detectar estancamiento o hitos.

---

## 3. Funciones de P茅rdida (The Laws)

### A. Physics Loss
Incorporar restricciones f铆sicas directamente en la funci贸n de p茅rdida.
- **Hamiltonian Loss:** Penalizar violaciones de conservaci贸n de energ铆a.
- **Symmetry Loss:** Penalizar violaciones de simetr铆as (rotaci贸n, traslaci贸n, CPT).

### B. Information Loss
- **Variational Information Bottleneck:** Forzar al modelo a comprimir informaci贸n, qued谩ndose solo con lo relevante (causalidad).

---

## 4. Meta-Learning & Auto-ML

- **Neural Architecture Search (NAS):** Dejar que la IA evolucione su propia arquitectura.
- **Hyperparameter Optimization:** B煤squeda autom谩tica de los mejores par谩metros de entrenamiento.

---

**Estado:** En Progreso (Investigaci贸n Continua)
**Relaci贸n:** Transversal a todas las fases (el "Cerebro" del sistema).
