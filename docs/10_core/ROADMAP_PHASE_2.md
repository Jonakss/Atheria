# ‚ö° Roadmap Fase 2: Modo Nativo (C++/CUDA Runtime)

**Objetivo:** Escalar la simulaci√≥n de miles a millones de part√≠culas activas eliminando el overhead del int√©rprete de Python.

**Estado General:** üü° **~85% Completado** - Motor funcional, optimizaciones pendientes (Actualizado: 2025-12-05)

---

## 1. Estrategia de Implementaci√≥n: Modos de Ejecuci√≥n

> [!IMPORTANT]
> **"Nativo" NO es un engine separado - es un MODO DE EJECUCI√ìN.**
> 
> Los engines reales son: **Lattice**, **Holographic**, **Cartesian**, **Polar**, **Harmonic**, etc.
> Cada engine puede correr en dos modos:
> - **Python:** Desarrollo r√°pido, debugging, nube, cuando C++/CUDA no funciona
> - **Nativo (C++/CUDA):** Producci√≥n, m√°ximo rendimiento

### ¬øCu√°ndo usar cada modo?

| Modo | Cu√°ndo Usar |
|------|-------------|
| **Python** | Desarrollo, pruebas r√°pidas, entornos cloud, fallback cuando C++/CUDA falla |
| **Nativo** | Producci√≥n, simulaciones largas, cuando se necesita m√°ximo rendimiento |

### Enfoque H√≠brido Embebido (PyBind11)

- **Python:** Orquestaci√≥n, Servidor Web, Entrenamiento (PyTorch), Visualizaci√≥n, Desarrollo r√°pido
- **C++:** Estructuras de datos espaciales (Sparse Octree), Bucle principal de f√≠sica, Gesti√≥n de memoria

### Tabla de Implementaci√≥n por Engine

| Engine | Modo Python | Modo Nativo (C++) | Estado |
|--------|-------------|-------------------|--------|
| LatticeEngine | ‚úÖ | ‚è≥ Pendiente | Solo Python |
| HolographicEngine | ‚úÖ | ‚è≥ Pendiente | Solo Python |
| CartesianEngine | ‚úÖ | ‚è≥ Parcial | Wrapper disponible |
| PolarEngine | ‚úÖ | ‚è≥ Pendiente | Solo Python |
| SparseHarmonicEngine | ‚úÖ | ‚è≥ Parcial | SparseMap C++ listo |

### Requisitos de Interfaz (TODOS los engines)

> [!WARNING]
> **Todos los engines DEBEN implementar `get_visualization_data()`** para que el frontend pueda mostrar visualizaciones consistentes.

```python
def get_visualization_data(self, viz_type: str = "density") -> dict:
    """Retorna datos para visualizaci√≥n frontend."""
    # viz_types: density, phase, energy, gradient, real, imag, fields
    ...
```

**Wrapper existente:** `NativeEngineWrapper` en `src/engines/native_engine_wrapper.py` envuelve la l√≥gica C++ y expone la misma interfaz que los engines Python.

- Reemplazo del diccionario de Python
- Estructura: `std::unordered_map<Coord3D, QuantumState>`
- **Implementado:** `src/cpp_core/src/sparse_map.h`
- Soporte para valores num√©ricos y tensores PyTorch
- Custom Hashing implementado

**Pendiente:** Memory Pools para evitar fragmentaci√≥n de RAM

---

### B. OctreeIndex (El Acelerador) ‚è≥
**Estado:** Pendiente (Mencionado pero no implementado)

- √çndice espacial para b√∫squedas r√°pidas
- Permite consultas como `get_particles_in_radius(r)` en tiempo $O(\log N)$ en lugar de $O(N)$
- Vital para calcular gravedad y colisiones entre chunks
- **Prioridad:** Media (optimizaci√≥n adicional)

---

### C. Binding (La Interfaz) ‚úÖ
**Estado:** Completado

C√≥digo de PyBind11 que expone las clases C++ a Python.

// Ejemplo conceptual
PYBIND11_MODULE(atheria_native, m) {
    pybind11::class_<Universe>(m, "Universe")
        .def("step", &Universe::step)
        .def("get_state", &Universe::get_state);
}


## 3. Interoperabilidad con PyTorch ‚úÖ
**Estado:** Completado

Para que la "Ley M" (entrenada en Python) corra en el motor C++ sin salir de la GPU:

- ‚úÖ **Exportar Modelo:** Usar `torch.jit.trace` para guardar el modelo como `model.pt`
- ‚úÖ **Cargar en C++:** Usar LibTorch (API C++ de PyTorch) dentro del motor nativo
- ‚úÖ **Implementado:** Carga de modelos TorchScript en `Engine` C++
- **Ventaja:** Los tensores nunca viajan a la CPU. C++ le dice a la GPU "ejecuta esto" y recibe el resultado en VRAM

---

4. Pasos de Migraci√≥n

‚úÖ Setup del Entorno: Configurar CMake y setup.py para compilar extensiones. - **COMPLETADO (2024-12)**

‚úÖ Hello World: Crear una funci√≥n add(a, b) en C++ y llamarla desde Python. - **COMPLETADO (2024-12)**
   - Funci√≥n `add()` implementada y probada
   - Estructura `Coord3D` implementada
   - Clase `SparseMap` b√°sica implementada y funcionando

üîÑ Migraci√≥n de Datos: Mover la estructura de datos self.matter de Python a C++.
   - `SparseMap` con soporte para valores num√©ricos: ‚úÖ
   - `SparseMap` con soporte para tensores PyTorch: ‚úÖ (implementado, pendiente pruebas completas)

üîÑ Migraci√≥n de L√≥gica: Mover la funci√≥n step() a C++.
   - `Engine` clase implementada con `step_native()`: ‚úÖ (estructura lista, pendiente pruebas)

üîÑ Integraci√≥n de LibTorch: Conectar la U-Net.
   - Soporte para LibTorch detectado: ‚úÖ
   - Carga de modelos TorchScript: ‚úÖ (implementado en Engine)
   - Pendiente: Pruebas con modelo real

‚è≥ Optimizaciones de Rendimiento (Alta Prioridad):
   
   **A. Paralelismo (OpenMP/std::thread)**
   - Paralelizar iteraci√≥n sobre part√≠culas activas en `step_native()`
   - Usar OpenMP para loops paralelos (`#pragma omp parallel for`)
   - Thread pool para operaciones independientes
   - Paralelizar conversi√≥n disperso‚Üídenso cuando sea necesario
   - **Impacto**: 2-4x mejora en simulaci√≥n multi-core
   
   **B. Optimizaciones SIMD (Vectorizaci√≥n)**
   - Usar instrucciones SIMD (SSE/AVX) para operaciones vectoriales
   - Optimizar c√°lculos de f√≠sica con vectorizaci√≥n autom√°tica
   - Mejorar rendimiento de operaciones matem√°ticas (suma, producto, etc.)
   - Vectorizar operaciones sobre tensores LibTorch
   - **Impacto**: 2-3x mejora en operaciones matem√°ticas
   
   **C. Visualizaci√≥n en C++ (Motor Nativo)**
   - Implementar `compute_visualization()` en Engine C++
   - C√°lculos b√°sicos (density, phase, energy) directamente en GPU
   - Reducir overhead Python en pipeline de visualizaci√≥n
   - Env√≠o directo desde GPU cuando sea posible (zero-copy)
   - **Impacto**: Reducci√≥n de ~2-5ms ‚Üí ~0.5-1ms por frame
   
   **D. Env√≠o de Datos Optimizado**
   - Evaluar env√≠o directo desde GPU (evitar CPU)
   - Considerar shaders en frontend para procesamiento
   - Optimizar serializaci√≥n para datos raw
   - **Impacto**: Reducci√≥n adicional de ~1-2ms por frame
   
   **Impacto Total Esperado**: 10-50x mejora en rendimiento de simulaci√≥n
   
   **Referencias**: 
   - [[40_Experiments/ARCHITECTURE_EVALUATION_GO_VS_PYTHON|Evaluaci√≥n Go vs Python]] - An√°lisis de optimizaciones
   - [[40_Experiments/VISUALIZATION_OPTIMIZATION_ANALYSIS|An√°lisis de Optimizaci√≥n de Visualizaci√≥n]] - Opciones de optimizaci√≥n

**Nota para Agentes:** Al implementar optimizaciones, prioriza la seguridad de memoria (Smart Pointers) y el paralelismo (OpenMP/std::thread) para el bucle de f√≠sica.

---

## 5. Resumen Ejecutivo

### ‚úÖ Completado (~70%)
- Setup del entorno (CMake, setup.py)
- Hello World y funciones b√°sicas
- SparseMap con soporte para tensores PyTorch
- Engine con `step_native()` implementado
- HarmonicVacuum (generador de vac√≠o cu√°ntico)
- Integraci√≥n LibTorch y carga de modelos TorchScript
- PyBind11 bindings (`atheria_core` m√≥dulo)

### ‚è≥ Pendiente - Alta Prioridad
- **Paralelismo (OpenMP/std::thread)** - Impacto 2-4x
- **Optimizaciones SIMD** - Impacto 2-3x
- **Visualizaci√≥n en C++** - ‚úÖ Implementado (compute_visualization)
- **Env√≠o de Datos Optimizado** - Reducci√≥n adicional ~1-2ms

### ‚è≥ Pendiente - Media Prioridad
- OctreeIndex (√≠ndice espacial)
- Memory Pools (optimizaci√≥n de memoria)
- Benchmark completo Python vs C++

**Impacto Total Esperado:** 10-50x mejora en rendimiento de simulaci√≥n

---

## Referencias

- [[PHASE_STATUS_REPORT]] - Estado de todas las fases
- [[Native_Engine_Core]] - Documentaci√≥n del motor nativo
- [[ARCHITECTURE_EVALUATION_GO_VS_PYTHON]] - An√°lisis de optimizaciones
- [[VISUALIZATION_OPTIMIZATION_ANALYSIS]] - Opciones de optimizaci√≥n
- [[ROADMAP_PHASE_1]] - Fase anterior
- [[ROADMAP_PHASE_3]] - Siguiente fase

---

**√öltima actualizaci√≥n:** 2025-11-26
**Pr√≥ximos pasos:** Implementar optimizaciones de paralelismo y SIMD para alcanzar objetivo de 10-50x mejora