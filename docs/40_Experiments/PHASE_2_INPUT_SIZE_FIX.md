# Phase 2: Correcci√≥n de Tama√±o de Input en Motor Nativo

**Fecha:** 2025-01-20  
**Estado:** En progreso

## Problema Identificado

El motor nativo C++ estaba construyendo inputs de tama√±o incorrecto para los modelos UNet. El error espec√≠fico era:

```
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 4 but got size 5 for tensor number 1 in the list.
```

### Causa Ra√≠z

1. **Modelo entrenado con grid completo:** Los modelos UNet fueron entrenados con inputs de tama√±o completo del grid (t√≠picamente 64x64 o 128x128), no con patches peque√±os.

2. **Skip connections:** La arquitectura U-Net tiene skip connections (`torch.cat([u2, x1], dim=1)`) que requieren que las dimensiones espaciales coincidan exactamente en diferentes niveles. Si el modelo fue entrenado con 64x64, espera ese tama√±o exacto.

3. **Parches peque√±os:** El c√≥digo C++ estaba intentando usar patches de 3x3 o 5x5 alrededor de cada part√≠cula, lo cual es ineficiente pero conceptualmente correcto para un motor disperso. Sin embargo, esto causa incompatibilidad con los skip connections.

## Cambios Implementados

### 1. Aumento de tama√±o de patch

- **Antes:** Patch de 3x3 (insuficiente para MaxPool2d dos veces)
- **Intermedio:** Patch de 5x5 (funciona con MaxPool2d pero falla con skip connections)
- **Actual:** Preparado para usar tama√±o completo del grid (64x64 por defecto)

### 2. Manejo de modelos ConvLSTM

Se a√±adi√≥ manejo de argumentos opcionales `h_t` y `c_t` para modelos que requieren memoria temporal:

```cpp
try {
    batch_output = model_.forward(inputs).toTensor();
} catch (const std::exception& e) {
    // Si falla, el modelo puede requerir h_t y c_t expl√≠citos
    inputs.push_back(torch::IValue());  // h_t = None
    inputs.push_back(torch::IValue());  // c_t = None
    auto output_tuple = model_.forward(inputs).toTuple();
    batch_output = output_tuple->elements()[0].toTensor();
}
```

### 3. Mejora del manejo de CUDA Runtime

Se mejor√≥ la detecci√≥n y manejo de problemas de CUDA runtime en `native_engine_wrapper.py`:

- Detecci√≥n autom√°tica de problemas de librer√≠as CUDA
- Forzar CPU mode cuando hay problemas
- Configurar `CUDA_VISIBLE_DEVICES=''` autom√°ticamente

## Problema Pendiente

**El modelo requiere el tama√±o completo del grid:** Para que los skip connections funcionen correctamente, necesitamos usar el tama√±o completo del grid (64x64 o el tama√±o con el que fue entrenado), no patches peque√±os.

### Opciones de Soluci√≥n

1. **Usar grid completo (ineficiente pero funciona):**
   - Construir un input del tama√±o completo del grid para cada part√≠cula
   - Centrar el input en la posici√≥n de la part√≠cula
   - Funciona pero es muy ineficiente en memoria

2. **Re-entrenar modelo con patches (√≥ptimo a largo plazo):**
   - Modificar la arquitectura para que funcione con patches de tama√±o fijo
   - Requiere re-entrenamiento pero es la soluci√≥n m√°s eficiente

3. **Padding din√°mico (complejo):**
   - Usar padding para ajustar tama√±os en los skip connections
   - Requiere modificar el modelo o hacer post-procesamiento

## Pr√≥ximos Pasos

1. ‚úÖ Corregir tama√±o de input m√≠nimo (5x5 ‚Üí tama√±o completo del grid)
2. ‚úÖ Implementar uso de tama√±o completo del grid desde configuraci√≥n (agregar grid_size al constructor)
3. ‚úÖ Usar grid_size_ en build_batch_input() para construir inputs del tama√±o correcto
4. ‚è≥ Optimizar para reducir uso de memoria cuando se usa grid completo
5. üîÑ Considerar re-entrenamiento con arquitectura compatible con patches (futuro)
6. ‚è≥ Probar con modelos reales en CPU y GPU

## Referencias

- `src/cpp_core/src/sparse_engine.cpp::build_batch_input()`
- `src/models/unet_convlstm.py::forward()` - Skip connections en l√≠neas 166, 170
- `docs/40_Experiments/PHASE_2_MIGRATION_TO_NATIVE.md`

