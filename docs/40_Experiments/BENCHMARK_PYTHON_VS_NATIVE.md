# Benchmark: Motor Python vs Motor C++ Nativo

## üìä Resumen

Este documento describe el proceso y los resultados del benchmark comparativo entre el motor Python (`Aetheria_Motor`) y el motor C++ nativo (`NativeEngineWrapper`).

## üéØ Objetivo

Comparar el rendimiento de ambos motores ejecutando el mismo experimento y midiendo:
- **Throughput**: Pasos por segundo (SPS)
- **Latencia**: Tiempo de ejecuci√≥n total
- **Memoria**: Uso de RAM
- **Precisi√≥n**: Verificar que ambos motores producen resultados similares

## üîß Uso del Script

El script de benchmark est√° disponible en `scripts/benchmark_python_vs_native.py`:

```bash
# Usar con un experimento espec√≠fico
python3 scripts/benchmark_python_vs_native.py \
    --experiment EXPERIMENT_NAME \
    --steps 100 \
    --device cpu

# Ejemplo con m√°s pasos y GPU
python3 scripts/benchmark_python_vs_native.py \
    --experiment UNET_32ch_D5_LR2e-5 \
    --steps 500 \
    --device cuda \
    --output benchmark_report_unet.md
```

### Opciones

- `--experiment`: Nombre del experimento (requerido)
- `--steps`: N√∫mero de pasos a ejecutar (default: 100)
- `--warmup`: Pasos de warm-up (default: 10)
- `--device`: Device (`cpu`/`cuda`) - default: auto-detecci√≥n
- `--output`: Ruta del reporte (default: `benchmark_report_EXPERIMENT.md`)

### Requisitos

1. **Experimento con checkpoint**: El experimento debe tener al menos un checkpoint guardado en `output/checkpoints/EXPERIMENT_NAME/`
2. **Configuraci√≥n del experimento**: Debe existir `output/experiments/EXPERIMENT_NAME/config.json`
3. **Motor nativo compilado**: El m√≥dulo `atheria_core` debe estar compilado (ver `docs/40_Experiments/PHASE_2_SETUP_LOG.md`)
4. **Modelo TorchScript**: El motor nativo requiere un modelo exportado a TorchScript (se exporta autom√°ticamente si no existe usando la funci√≥n mejorada)

### Notas Importantes

- **Exportaci√≥n autom√°tica mejorada**: Si no existe un modelo TorchScript, el benchmark lo exportar√° autom√°ticamente usando el tama√±o completo del grid de inferencia (no patches peque√±os), crucial para modelos UNet.
- **Manejo de memoria**: El script limpia memoria entre benchmarks para obtener mediciones precisas.
- **Warm-up**: Los pasos de warm-up permiten que el motor "se caliente" antes de medir rendimiento real.

## üìã M√©tricas Medidas

### Motor Python

- **Tiempo de carga**: Tiempo para cargar el modelo desde checkpoint
- **Tiempo de inicializaci√≥n**: Tiempo para crear motor y estado cu√°ntico
- **Tiempo de pasos**: Tiempo para ejecutar N pasos de simulaci√≥n
- **Pasos/segundo**: Throughput calculado
- **Memoria**: Uso de RAM antes/durante/despu√©s

### Motor C++ Nativo

- **Tiempo de carga**: Tiempo para exportar/cargar modelo TorchScript
- **Tiempo de inicializaci√≥n**: Tiempo para inicializar wrapper y motor nativo
- **Tiempo de pasos**: Tiempo para ejecutar N pasos (todo en C++)
- **Pasos/segundo**: Throughput calculado
- **Memoria**: Uso de RAM antes/durante/despu√©s

### Comparaci√≥n

- **Speedup**: Mejora de velocidad (nativo vs Python)
- **Overhead de memoria**: Diferencia en uso de RAM
- **Precisi√≥n**: Diferencia en energ√≠a final (para verificar consistencia)

## üìä Resultados Esperados

### Escenarios de Benchmark

1. **CPU Mode**:
   - El motor nativo deber√≠a ser m√°s r√°pido al ejecutar la l√≥gica core en C++
   - Overhead de bindings puede afectar para operaciones peque√±as
   - Ventajas m√°s claras en operaciones intensivas

2. **GPU Mode**:
   - Ambos motores usan CUDA para el modelo
   - El motor nativo puede optimizar mejor las operaciones dispersas
   - Diferencia de rendimiento depende de la complejidad del modelo

3. **Modelos Peque√±os**:
   - Overhead de bindings puede dominar
   - Diferencia de rendimiento menor

4. **Modelos Grandes**:
   - Ventajas del motor nativo m√°s claras
   - Mejor escalabilidad

## üîç Interpretaci√≥n de Resultados

### Speedup < 1.0x
- El motor Python es m√°s r√°pido
- Posible overhead de bindings C++/Python
- Normal para operaciones peque√±as o modelos simples

### Speedup ~1.0x
- Rendimiento similar
- El overhead de bindings compensa las optimizaciones
- Considerar otros factores (memoria, escalabilidad)

### Speedup > 1.0x
- El motor nativo es m√°s r√°pido
- Ventajas del c√≥digo C++ optimizado
- Escalabilidad mejor con modelos grandes

### Precisi√≥n (Diferencia de Energ√≠a)

- **< 1%**: ‚úÖ Excelente precisi√≥n
- **1-5%**: ‚ö†Ô∏è Aceptable (puede ser por diferencias num√©ricas)
- **> 5%**: ‚ùå Problema de precisi√≥n (investigar diferencias de implementaci√≥n)

## üìù Reporte Generado

El script genera un reporte en Markdown con:

1. **Resumen ejecutivo**: Speedup, tiempo total, memoria
2. **Tabla comparativa**: M√©tricas lado a lado
3. **An√°lisis detallado**: Interpretaci√≥n de resultados
4. **Detalles t√©cnicos**: Tiempos de carga, inicializaci√≥n, etc.

## üöÄ Pr√≥ximos Pasos

1. **Ejecutar benchmark con diferentes experimentos**:
   - Modelos peque√±os (MLP)
   - Modelos medianos (UNet 32ch)
   - Modelos grandes (UNet 64ch, ConvLSTM)

2. **Comparar en diferentes devices**:
   - CPU mode
   - GPU mode (si disponible)

3. **Optimizaciones adicionales**:
   - Optimizar conversi√≥n disperso ‚Üî denso
   - Reducir overhead de bindings
   - Optimizaciones espec√≠ficas del modelo

## üîó Referencias

- `scripts/benchmark_python_vs_native.py`: Script de benchmark
- `src/engines/qca_engine.py`: Motor Python
- `src/engines/native_engine_wrapper.py`: Wrapper del motor nativo
- `src/cpp_core/`: Implementaci√≥n C++ del motor nativo
- [[PHASE_2_MIGRATION_TO_NATIVE]]: Gu√≠a de migraci√≥n al motor nativo

---

## üö® Estado Actual

**Estado:** ‚è≥ Benchmark creado, pendiente de ejecuci√≥n con experimento v√°lido

### Estado Actual del Benchmark

**Script creado:** ‚úÖ `scripts/benchmark_python_vs_native.py`  
**Documentaci√≥n:** ‚úÖ Completa  
**Ejecuci√≥n:** ‚è≥ Pendiente - requiere experimento con:
- `config.json` en `output/experiments/EXPERIMENT_NAME/`
- Checkpoint en `output/checkpoints/EXPERIMENT_NAME/*.pth`

### Ejecutar Benchmark

Para ejecutar el benchmark cuando haya un experimento v√°lido:

```bash
# CPU mode (m√°s r√°pido para pruebas)
python3 scripts/benchmark_python_vs_native.py \
    --experiment EXPERIMENT_NAME \
    --steps 100 \
    --device cpu

# GPU mode (si CUDA est√° disponible)
python3 scripts/benchmark_python_vs_native.py \
    --experiment EXPERIMENT_NAME \
    --steps 100 \
    --device cuda
```

El script generar√° un reporte en Markdown: `benchmark_report_EXPERIMENT_NAME.md`

### Por Qu√© el Motor Nativo No Se Usa Autom√°ticamente

El motor nativo C++ est√° **disponible** (`NATIVE_AVAILABLE = True`), pero requiere:

1. **Modelo TorchScript exportado**: El motor nativo necesita un modelo exportado a `.pt` (TorchScript)
2. **Exportaci√≥n autom√°tica**: El servidor intenta exportar autom√°ticamente cuando carga un experimento, pero puede fallar si:
   - No hay checkpoint disponible
   - El modelo no es compatible con TorchScript
   - Hay errores en la exportaci√≥n

### C√≥mo Forzar el Uso del Motor Nativo

1. **Exportar modelo manualmente**:
   ```bash
   python scripts/test_native_engine.py --experiment EXPERIMENT_NAME --export-only
   ```

2. **Verificar si hay modelo JIT**:
   ```bash
   ls output/torchscript_models/EXPERIMENT_NAME/model.pt
   ```

3. **Revisar logs del servidor** cuando cargas un experimento para ver si exporta el modelo autom√°ticamente.

---

**√öltima actualizaci√≥n:** 2024-11-20  
**Pr√≥ximo paso:** Ejecutar benchmark cuando haya modelos disponibles

