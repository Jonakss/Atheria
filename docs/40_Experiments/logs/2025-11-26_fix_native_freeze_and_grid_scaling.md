---
type: fix
date: 2025-11-26
component: Backend (Simulation Loop, Inference Handlers)
author: AI Assistant
status: implemented
---

# Fix: Native Engine Freeze & Grid Scaling

## Contexto

El usuario report√≥ dos problemas cr√≠ticos:

1.  **Grid Scaling:** Al intentar establecer el tama√±o del grid a 32 (tama√±o original de entrenamiento), el sistema lo forzaba a 256 (tama√±o por defecto de inferencia). El comando para cambiar la configuraci√≥n no recargaba el motor, por lo que el cambio no surt√≠a efecto.
2.  **Native Engine Freeze:** El motor nativo (C++) se bloqueaba ("se traca") al iniciar la simulaci√≥n, causando que el servidor dejara de responder. Esto ocurr√≠a espec√≠ficamente en la llamada a `step_native()`.

## Problemas Detectados

1.  **Inference Handlers:** `handle_set_inference_config` actualizaba `g_state` y `global_cfg` pero no reinicializaba el motor (`NativeEngineWrapper` o `Aetheria_Motor`). Como el tama√±o del grid se define al construir el motor, el cambio no se aplicaba hasta un reinicio manual o recarga del experimento.
2.  **Simulation Loop:** La llamada a `motor.evolve_internal_state` (que llama a C++) se hac√≠a de forma s√≠ncrona dentro de un `run_in_executor` pero sin timeout. Si el c√≥digo C++ entraba en un bucle infinito o deadlock, el thread quedaba bloqueado indefinidamente, y aunque el event loop principal segu√≠a vivo, la simulaci√≥n se deten√≠a y no se pod√≠a pausar ni detener limpiamente.

## Soluci√≥n Implementada

### 1. Recarga Autom√°tica al Cambiar Grid Size

Se modific√≥ `src/pipelines/handlers/inference_handlers.py` para detectar cambios en `grid_size`. Si se detecta un cambio y hay un experimento activo, se invoca autom√°ticamente `handle_load_experiment` para recargar el motor con la nueva configuraci√≥n.

```python
# src/pipelines/handlers/inference_handlers.py
if grid_size is not None and g_state.get('active_experiment'):
    logging.info(f"üîÑ Recargando experimento... para aplicar nuevo grid size: {new_size}")
    # ...
    await handle_load_experiment(...)
```

### 2. Timeout en Simulation Loop

Se envolvi√≥ la llamada a `motor.evolve_internal_state` en `src/pipelines/core/simulation_loop.py` con `asyncio.wait_for` y un timeout de 5 segundos.

```python
# src/pipelines/core/simulation_loop.py
try:
    await asyncio.wait_for(
        asyncio.get_event_loop().run_in_executor(None, motor.evolve_internal_state),
        timeout=5.0
    )
except asyncio.TimeoutError:
    logging.error("‚ùå Timeout cr√≠tico en motor.evolve_internal_state (5s)...")
    g_state['is_paused'] = True
    # ...
```

Esto asegura que si el motor nativo se bloquea, el backend recupera el control, pausa la simulaci√≥n y notifica al usuario en lugar de quedarse congelado.

## Archivos Modificados

- `src/pipelines/handlers/inference_handlers.py`: Agregada l√≥gica de recarga.
- `src/pipelines/core/simulation_loop.py`: Agregado timeout de seguridad.

## Verificaci√≥n

- **Grid Size:** Al enviar un comando `set_inference_config` con `grid_size=32`, el sistema ahora recarga el modelo y el log deber√≠a mostrar `Grid escalado` (o la ausencia del mensaje si coincide con training size) y el motor inicializado con el nuevo tama√±o.
- **Freeze:** Si el motor nativo se bloquea, despu√©s de 5 segundos la simulaci√≥n se pausar√° autom√°ticamente y aparecer√° un mensaje de error en el frontend, permitiendo al usuario cambiar a motor Python o reiniciar.
