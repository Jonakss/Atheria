## 2025-11-21 - Fix: Carga de Modelos en Servidor de Inferencia

### Problema
El servidor fallaba al cargar modelos desde el frontend con dos errores:
1. `AttributeError: module 'src.config' has no attribute 'D_STATE'`
2. `TypeError: load_model() got an unexpected keyword argument 'device'`

### Causa Ra√≠z
- **Error 1**: El c√≥digo usaba `global_cfg.D_STATE` que no existe. El atributo correcto es `MODEL_PARAMS['d_state']` desde la configuraci√≥n del experimento.
- **Error 2**: La firma de `load_model()` cambi√≥ de `load_model(exp_name, device=device)` a `load_model(exp_cfg, checkpoint_path)`.

### Soluci√≥n
**Archivo Modificado:** `src/pipelines/handlers/inference_handlers.py`

1. **Motor Nativo (C++)**:
   - Cargar configuraci√≥n del experimento con `load_experiment_config(exp_name)`
   - Usar `exp_cfg.MODEL_PARAMS.d_state` en lugar de `global_cfg.D_STATE`
   - Llamar `load_model(exp_cfg, checkpoint_path)` con la firma correcta

2. **Motor Python**:
   - Cargar configuraci√≥n del experimento
   - Crear modelo con `load_model(exp_cfg, checkpoint_path)`
   - Envolver en `Aetheria_Motor` con par√°metros correctos

### Resultado
- ‚úÖ Carga de modelos funciona correctamente
- ‚úÖ Compatibilidad con motor nativo y Python
- ‚úÖ Configuraci√≥n del experimento se carga din√°micamente

---



---
[[AI_DEV_LOG|üîô Volver al √çndice]]
