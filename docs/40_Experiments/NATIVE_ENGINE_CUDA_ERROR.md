---
title: Error CUDA Motor Nativo - undefined symbol __nvJitLinkCreate
type: issue
status: open
tags: [cuda, native-engine, troubleshooting]
created: 2025-11-20
updated: 2025-11-20
related: [[NATIVE_ENGINE_PERFORMANCE_ISSUES|Problemas Motor Nativo]], [[Native_Engine_Core|Motor Nativo]]
---

# Error CUDA Motor Nativo: undefined symbol __nvJitLinkCreate

**Fecha**: 2025-11-20  
**Estado**: üî¥ **ABIERTO** - Problema de configuraci√≥n de sistema  
**Prioridad**: üü° Media (el motor Python funciona como fallback)

---

## üêõ Error Observado

```
ImportError: /home/jonathan.correa/Projects/Atheria/ath_venv/lib/python3.10/site-packages/torch/lib/../../nvidia/cusparse/lib/libcusparse.so.12: undefined symbol: __nvJitLinkCreate_12_8, version libnvJitLink.so.12
```

**Cu√°ndo ocurre:**
- Al intentar importar `atheria_core` desde Python
- Espec√≠ficamente cuando PyTorch intenta cargar las librer√≠as de CUDA
- El motor nativo C++ depende de LibTorch, que a su vez depende de librer√≠as CUDA

---

## üîç Causa Ra√≠z

Este error indica que hay un **conflicto de versiones entre las librer√≠as de CUDA**:

1. **PyTorch** compilado con una versi√≥n de CUDA (ej: CUDA 12.8)
2. **Sistema** tiene instaladas librer√≠as de CUDA de una versi√≥n diferente
3. La librer√≠a `libnvJitLink.so.12` no puede encontrar el s√≠mbolo `__nvJitLinkCreate_12_8`

**S√≠mbolo faltante:**
- `__nvJitLinkCreate_12_8`: Parte de CUDA JIT Linker API (versi√≥n 12.8)
- Indica que PyTorch espera CUDA 12.8, pero el sistema puede tener otra versi√≥n

---

## üõ†Ô∏è Soluciones Propuestas

### Soluci√≥n 1: Verificar Versi√≥n de CUDA

```bash
# Verificar versi√≥n de CUDA instalada en el sistema
nvcc --version

# Verificar versi√≥n que PyTorch espera
python3 -c "import torch; print(torch.version.cuda)"

# Si no coinciden, actualizar PyTorch o CUDA
```

### Soluci√≥n 2: Usar Motor Python (Temporal)

El motor Python funciona correctamente como fallback:

```python
# En pipeline_server.py, el motor Python se usa autom√°ticamente
# cuando el motor nativo no est√° disponible
use_native_engine = False  # Forzar uso de motor Python
```

### Soluci√≥n 3: Compilar Motor Nativo Solo para CPU

Si CUDA tiene problemas, compilar el motor nativo para CPU mode:

```bash
# En CMakeLists.txt, forzar CPU mode
cmake -DTORCH_CUDA=OFF ...

# O usar device='cpu' al inicializar
motor = NativeEngineWrapper(..., device='cpu')
```

### Soluci√≥n 4: Actualizar PyTorch/CUDA Toolkit

```bash
# Reinstalar PyTorch con la versi√≥n correcta de CUDA
pip uninstall torch torchvision
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# O usar CUDA toolkit compatible
conda install cudatoolkit=12.1 -c pytorch
```

---

## üìä Impacto

**Funcionalidad:**
- ‚úÖ Motor Python: **Funciona correctamente** (fallback autom√°tico)
- ‚ùå Motor Nativo: **No disponible** hasta resolver problema CUDA

**Rendimiento:**
- Motor Python: ~100-500 steps/segundo (depende del modelo)
- Motor Nativo: ~10,000 steps/segundo (cuando funciona)

**Trabajo Actual:**
- Las optimizaciones de tiempo real (lazy conversion, ROI) ya implementadas
- El motor Python se beneficia de estas optimizaciones tambi√©n
- **No bloquea desarrollo** de optimizaciones adicionales

---

## üîó Referencias

- [[NATIVE_ENGINE_PERFORMANCE_ISSUES|Problemas Motor Nativo]] - Optimizaciones ya implementadas
- [[Native_Engine_Core|Motor Nativo]] - Documentaci√≥n del motor nativo
- [PyTorch CUDA Compatibility](https://pytorch.org/get-started/locally/) - Gu√≠a de compatibilidad

---

## üìù Notas Adicionales

**Workaround Actual:**
El sistema detecta autom√°ticamente cuando el motor nativo no est√° disponible y usa el motor Python como fallback. Esto permite que el desarrollo contin√∫e sin bloqueos.

**Pr√≥ximos Pasos:**
1. Verificar versi√≥n de CUDA en el sistema
2. Actualizar PyTorch o CUDA toolkit si es necesario
3. Compilar motor nativo con la versi√≥n correcta de CUDA
4. Probar importaci√≥n de `atheria_core`

**Optimizaciones Futuras:**
- Las optimizaciones de tiempo real (paralelismo, SIMD, visualizaci√≥n C++) se pueden implementar independientemente
- El motor Python tambi√©n se beneficiar√° de estas optimizaciones cuando se implementen

---

**√öltima actualizaci√≥n:** 2025-11-20

