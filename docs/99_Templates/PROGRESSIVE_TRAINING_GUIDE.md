# Gu√≠a: Entrenamiento Progresivo en Atheria 4

Esta gu√≠a explica c√≥mo usar el notebook `Atheria_Progressive_Training.ipynb` para entrenamientos largos en Google Colab o Kaggle, optimizando el uso de cuota de GPU.

---

## üéØ Casos de Uso

Este notebook es ideal para:
- Entrenamientos de **muchas horas** (6-24h)
- Aprovechar **cuota de GPU completa** (Colab/Kaggle)
- Experimentaci√≥n sin supervisi√≥n
- Entrenamientos que necesitan **auto-recuperaci√≥n** si se desconecta

---

## üìã Preparaci√≥n

### 1. Google Drive (solo Colab)

**Primera vez:**
1. El notebook montar√° autom√°ticamente tu Drive
2. Crear√° estructura de carpetas en `/MyDrive/Atheria/`
3. Checkpoints se guardar√°n en `/MyDrive/Atheria/checkpoints/{experiment_name}/`

**Importante:**
- Los checkpoints en Drive permiten continuar si la sesi√≥n muere
- Aseg√∫rate de tener **suficiente espacio** (~1-5GB por experimento)
- Drive sync puede tardar unos segundos, es normal

### 2. Entorno (Colab o Kaggle)

#### Google Colab
- **Free**: ~12 horas/d√≠a (variable seg√∫n uso)
- **Pro**: ~24 horas continuas
- **GPU recomendada**: T4 (15GB VRAM)

#### Kaggle
- **Cuota**: 30 horas/semana
- **GPU disponibles**: T4, P100
- **Nota**: Checkpoints se guardan localmente, descargar al finalizar

---

## ‚öôÔ∏è Configuraci√≥n del Experimento

### Par√°metros Clave (Secci√≥n 5 del notebook)

```python
EXPERIMENT_CONFIG = {
    # Identificaci√≥n
    "EXPERIMENT_NAME": "UNET_64ch_D8_Progressive",
    
    # Arquitectura
    "MODEL_ARCHITECTURE": "UNET",  # UNET, SNN_UNET, MLP, DEEP_QCA
    "MODEL_PARAMS": {
        "d_state": 8,           # Dimensi√≥n estado cu√°ntico (4, 8, 16, 32)
        "hidden_channels": 64,  # Canales ocultos (16, 32, 64, 128)
    },
    
    # Entrenamiento
    "GRID_SIZE_TRAINING": 64,     # 32, 64, 128
    "QCA_STEPS_TRAINING": 100,
    "LR_RATE_M": 1e-4,
    
    # Progresivo
    "TOTAL_EPISODES": 1000,       # Total a entrenar
    "SAVE_EVERY_EPISODES": 10,    # Checkpoint local cada N
    "DRIVE_SYNC_EVERY": 50,       # Sync a Drive cada N
    "MAX_TRAINING_HOURS": 10,     # L√≠mite de tiempo
    
    # Auto-recuperaci√≥n
    "AUTO_RESUME": True,          # Continuar desde Drive
}
```

### Estrategias de Configuraci√≥n

#### üêá R√°pido (pruebas, 1-2 horas)
```python
"TOTAL_EPISODES": 100,
"GRID_SIZE_TRAINING": 32,
"SAVE_EVERY_EPISODES": 5,
"DRIVE_SYNC_EVERY": 20,
"MAX_TRAINING_HOURS": 2,
```

#### üê¢ Est√°ndar (entrenamiento normal, 6-8 horas)
```python
"TOTAL_EPISODES": 500,
"GRID_SIZE_TRAINING": 64,
"SAVE_EVERY_EPISODES": 10,
"DRIVE_SYNC_EVERY": 50,
"MAX_TRAINING_HOURS": 8,
```

#### üêå Largo (m√°xima calidad, 12-24 horas)
```python
"TOTAL_EPISODES": 2000,
"GRID_SIZE_TRAINING": 128,
"SAVE_EVERY_EPISODES": 20,
"DRIVE_SYNC_EVERY": 100,
"MAX_TRAINING_HOURS": 20,
```

---

## üöÄ Workflow Recomendado

### Primera Sesi√≥n (Desde Cero)

1. **Configurar experimento** (Secci√≥n 5)
   - Definir nombre √∫nico
   - Elegir arquitectura y par√°metros
   - Configurar `AUTO_RESUME = True`

2. **Ejecutar todas las celdas**
   - Runtime ‚Üí Run all (Colab)
   - Cell ‚Üí Run All (Kaggle)

3. **Dejar corriendo sin supervisi√≥n**
   - El notebook se auto-guarda en Drive
   - Monitorea recursos autom√°ticamente
   - Se detiene antes de timeout

4. **Verificar progreso** (opcional)
   - Cada 10 episodios: gr√°fico de p√©rdida
   - Cada 50 episodios: sync a Drive confirmado
   - Monitor de recursos actualizado

### Sesiones Posteriores (Continuar)

1. **Verificar `AUTO_RESUME = True`**
   - El notebook detecta autom√°ticamente √∫ltimo checkpoint en Drive

2. **Ajustar `TOTAL_EPISODES` si necesario**
   - Ejemplo: Si ya complet√≥ 500, aumentar a 1000

3. **Ejecutar todas las celdas de nuevo**
   - Contin√∫a autom√°ticamente desde episodio guardado
   - No reinicia desde cero

4. **Repetir hasta convergencia**

---

## üìä Monitoreo de Recursos

El notebook muestra autom√°ticamente cada 10 episodios:

```
üìä RECURSOS:
  GPU Utilization: 85.3%
  GPU Memory: 8.42GB / 15.00GB
  RAM: 12.51GB / 25.50GB (49.1%)
  
‚è∞ TIEMPO:
  Transcurrido: 2:34:18
  Restante: 7:25:42 (de 10h m√°ximo)
```

### Interpretaci√≥n

- **GPU Utilization 80-100%**: ‚úÖ √ìptimo, GPU bien aprovechada
- **GPU Utilization 50-80%**: ‚ö†Ô∏è Puede mejorar, revisar grid size
- **GPU Utilization <50%**: ‚ùå Subutilizaci√≥n, aumentar complejidad

- **RAM >90%**: ‚ö†Ô∏è Cerca del l√≠mite, reducir batch/grid
- **Tiempo restante <10%**: üî¥ Se acerca al l√≠mite, guardar√° autom√°ticamente

---

## üíæ Pol√≠tica de Checkpoints

### Smart Save (autom√°tico)

El notebook usa `QC_Trainer_v4` con sistema inteligente:

1. **Mejores N modelos** (default: 5)
   - Solo guarda si mejora m√©tricas
   - Borra autom√°ticamente checkpoints antiguos peores

2. **√öltimo modelo** (siempre)
   - `last_model.pth` - checkpoint m√°s reciente
   - Permite continuar entrenamiento

3. **Checkpoints peri√≥dicos**
   - Local: Cada `SAVE_EVERY_EPISODES` (default: 10)
   - Drive: Cada `DRIVE_SYNC_EVERY` (default: 50)

### Estructura de Archivos

```
/MyDrive/Atheria/
‚îú‚îÄ‚îÄ checkpoints/
‚îÇ   ‚îî‚îÄ‚îÄ {EXPERIMENT_NAME}/
‚îÇ       ‚îú‚îÄ‚îÄ best_model.pth          # Mejor modelo
‚îÇ       ‚îú‚îÄ‚îÄ best_model_FINAL.pth    # Copia al finalizar
‚îÇ       ‚îú‚îÄ‚îÄ last_model.pth          # √öltimo checkpoint
‚îÇ       ‚îî‚îÄ‚îÄ checkpoint_ep*.pth      # Checkpoints hist√≥ricos
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îî‚îÄ‚îÄ {EXPERIMENT_NAME}/
‚îÇ       ‚îú‚îÄ‚îÄ training_log_*.json     # Log de entrenamiento
‚îÇ       ‚îú‚îÄ‚îÄ training_summary.png    # Gr√°ficos
‚îÇ       ‚îî‚îÄ‚îÄ {EXPERIMENT_NAME}_REPORT.md  # Reporte final
‚îî‚îÄ‚îÄ exports/
    ‚îî‚îÄ‚îÄ {EXPERIMENT_NAME}_model.pt  # TorchScript exportado
```

---

## üîß Troubleshooting

### Problema: "Drive sync muy lento"

**Soluci√≥n:**
- Aumentar `DRIVE_SYNC_EVERY` a 100 o m√°s
- Checkpoints locales siguen funcionando
- Sincronizar manualmente cada 2-3 horas

### Problema: "Se qued√≥ sin RAM"

**S√≠ntomas:** Kernel crashed, OOM error

**Soluci√≥n:**
```python
"GRID_SIZE_TRAINING": 32,  # Reducir de 64 a 32
"hidden_channels": 32,     # Reducir de 64 a 32
```

### Problema: "GPU utilization muy baja (<50%)"

**Soluci√≥n:**
```python
"GRID_SIZE_TRAINING": 128,  # Aumentar complejidad
"hidden_channels": 128,
```

### Problema: "Checkpoint no se encontr√≥ en Drive"

**Verificar:**
1. Drive est√° montado correctamente
2. Carpeta `/MyDrive/Atheria/checkpoints/` existe
3. Nombre del experimento coincide exactamente

**Soluci√≥n manual:**
```python
# Buscar manualmente
!ls "/content/drive/MyDrive/Atheria/checkpoints/{EXPERIMENT_NAME}/"
```

### Problema: "Timeout antes de completar"

**Prevenci√≥n:**
- `MAX_TRAINING_HOURS` debe ser **menor** que l√≠mite de Colab/Kaggle
- Colab Free: usar `MAX_TRAINING_HOURS=10`
- Colab Pro: usar `MAX_TRAINING_HOURS=20`
- El notebook guarda autom√°ticamente antes de timeout

---

## üí° Mejores Pr√°cticas

### 1. Sesiones M√∫ltiples (Colab Free)

Si tienes l√≠mite de 12h/d√≠a:
- **Sesi√≥n 1**: 10h (ej: 9am - 7pm)
- **Sesi√≥n 2**: 10h (ej: 9am - 7pm siguiente d√≠a)
- Auto-resume conecta ambas sesiones

### 2. Monitoring Externo (opcional)

Para saber cu√°ndo termina sin estar pendiente:

**Opci√≥n A: Email con Colab**
```python
# Agregar al final del training loop
from google.colab import auth
# Configurar para enviar email al completar
```

**Opci√≥n B: Revisar Drive**
- Revisar carpeta de Drive cada 2-3 horas
- Verificar timestamp de `last_model.pth`

### 3. Validaci√≥n Peri√≥dica

Cada 200-300 episodios:
1. Pausar entrenamiento (Ctrl+C)
2. Cargar mejor modelo
3. Ejecutar inferencia de prueba
4. Si resultados buenos ‚Üí continuar
5. Si no mejora ‚Üí ajustar learning rate

### 4. Cuota de GPU

**Colab Free:**
- Usar en horarios de baja demanda (madrugada)
- No abusar: respetar l√≠mites de uso justo

**Kaggle:**
- Aprovechar 30h/semana completas
- Planificar 3 sesiones de 10h

---

## üìà Estimar Tiempo de Entrenamiento

**F√≥rmula aproximada:**
```
Tiempo (horas) = (TOTAL_EPISODES √ó QCA_STEPS √ó GRID_SIZE¬≤) / (GPU_SPEED √ó 3600)
```

Donde:
- `GPU_SPEED` (T4) ‚âà 50,000,000 c√©lulas/segundo

**Ejemplos:**

| Grid | Episodes | QCA Steps | Tiempo (T4) |
|------|----------|-----------|-------------|
| 32   | 500      | 100       | ~1h         |
| 64   | 500      | 100       | ~4h         |
| 64   | 1000     | 100       | ~8h         |
| 128  | 1000     | 100       | ~32h        |

---

## üéì Ejemplos Completos

### Ejemplo 1: Primera Prueba (2 horas)

```python
EXPERIMENT_CONFIG = {
    "EXPERIMENT_NAME": "Test_UNET_First",
    "MODEL_ARCHITECTURE": "UNET",
    "MODEL_PARAMS": {"d_state": 4, "hidden_channels": 16},
    "GRID_SIZE_TRAINING": 32,
    "QCA_STEPS_TRAINING": 50,
    "TOTAL_EPISODES": 100,
    "SAVE_EVERY_EPISODES": 5,
    "DRIVE_SYNC_EVERY": 20,
    "MAX_TRAINING_HOURS": 2,
    "AUTO_RESUME": False,  # Primera vez
}
```

### Ejemplo 2: Experimento Serio (12 horas)

```python
EXPERIMENT_CONFIG = {
    "EXPERIMENT_NAME": "UNET_Production_v1",
    "MODEL_ARCHITECTURE": "UNET",
    "MODEL_PARAMS": {"d_state": 8, "hidden_channels": 64},
    "GRID_SIZE_TRAINING": 64,
    "QCA_STEPS_TRAINING": 100,
    "TOTAL_EPISODES": 800,
    "SAVE_EVERY_EPISODES": 10,
    "DRIVE_SYNC_EVERY": 50,
    "MAX_TRAINING_HOURS": 11,  # Margen de seguridad
    "AUTO_RESUME": True,
}
```

### Ejemplo 3: Continuar Entrenamiento

```python
# Mismo EXPERIMENT_NAME que antes
EXPERIMENT_CONFIG = {
    "EXPERIMENT_NAME": "UNET_Production_v1",  # ‚ö†Ô∏è Mismo nombre
    "MODEL_ARCHITECTURE": "UNET",
    "MODEL_PARAMS": {"d_state": 8, "hidden_channels": 64},
    "GRID_SIZE_TRAINING": 64,
    "QCA_STEPS_TRAINING": 100,
    "TOTAL_EPISODES": 1500,  # Aumentado de 800 a 1500
    "SAVE_EVERY_EPISODES": 10,
    "DRIVE_SYNC_EVERY": 50,
    "MAX_TRAINING_HOURS": 11,
    "AUTO_RESUME": True,  # ‚úÖ Clave: auto-resume activado
}
```

---

## üéØ Conclusi√≥n

El notebook `Atheria_Progressive_Training.ipynb` est√° optimizado para:
- ‚úÖ Entrenamientos largos sin supervisi√≥n
- ‚úÖ Aprovechamiento m√°ximo de cuota de GPU
- ‚úÖ Auto-recuperaci√≥n robusta
- ‚úÖ Monitoreo de recursos en tiempo real
- ‚úÖ Gesti√≥n inteligente de checkpoints

**Workflow simple:**
1. Configurar experimento
2. Ejecutar todas las celdas
3. Dejar corriendo
4. Repetir si necesario (auto-resume)

**¬°Feliz entrenamiento! üöÄ**
